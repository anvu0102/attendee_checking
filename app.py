import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io
import requests
import os
import zipfile # Th√™m th∆∞ vi·ªán ƒë·ªÉ gi·∫£i n√©n
from deepface import DeepFace

# --- 1. Thi·∫øt l·∫≠p trang Streamlit ---
st.set_page_config(
    page_title="H·ªá th·ªëng ƒêi·ªÉm danh Khu√¥n m·∫∑t DeepFace (GDrive)",
    page_icon="üì∏",
    layout="centered"
)

st.title("üì∏ H·ªá th·ªëng ƒêi·ªÉm danh Khu√¥n m·∫∑t DeepFace")
st.caption("Dataset ƒë∆∞·ª£c t·∫£i t·ª´ Google Drive c√¥ng khai.")

# --- 2. T·∫£i v√† Thi·∫øt l·∫≠p Haar Cascade (D√πng cho ph√°t hi·ªán khung) ---
HAAR_CASCADE_URL = "https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml"
CASCADE_FILENAME = 'haarcascade_frontalface_default.xml'
face_cascade = None
TEMP_IMAGE_PATH = "captured_face.jpg" # ƒê∆∞·ªùng d·∫´n t·∫°m ƒë·ªÉ l∆∞u ·∫£nh ch·ª•p

# --- C·∫•u h√¨nh Google Drive Dataset ---
# Vui l√≤ng thay th·∫ø chu·ªói n√†y b·∫±ng File ID c·ªßa file ZIP dataset c√¥ng khai c·ªßa b·∫°n.
GDRIVE_FILE_ID = "1qX4I983WrBYMWdQals3g_ijbeepf8BtG" 
ZIP_FILENAME = "dataset.zip" 
DATASET_FOLDER = "dataset" 

@st.cache_resource
def load_face_cascade(url, filename):
    """ T·∫£i Haar Cascade (gi·ªëng code c≈©). """
    try:
        r = requests.get(url)
        if r.status_code == 200:
            with open(filename, 'wb') as f:
                f.write(r.content)
            
            classifier = cv2.CascadeClassifier(filename)
            if not classifier.empty():
                st.success("T·∫£i Haar Cascade th√†nh c√¥ng.")
                return classifier
            
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i ho·∫∑c kh·ªüi t·∫°o Haar Cascade: {e}")
        return None

# Kh·ªüi t·∫°o b·ªô ph√¢n lo·∫°i
face_cascade = load_face_cascade(HAAR_CASCADE_URL, CASCADE_FILENAME)


@st.cache_resource(show_spinner="ƒêang t·∫£i v√† gi·∫£i n√©n Dataset t·ª´ Google Drive (Ch·ªâ ch·∫°y l·∫ßn ƒë·∫ßu)...")
def download_and_extract_dataset(file_id, zip_name, target_folder):
    """
    T·∫£i file ZIP c√¥ng khai t·ª´ Google Drive v√† gi·∫£i n√©n v√†o th∆∞ m·ª•c DeepFace dataset.
    S·ª≠ d·ª•ng @st.cache_resource ƒë·ªÉ ch·ªâ ch·∫°y m·ªôt l·∫ßn.
    """
    if not file_id or file_id == "YOUR_GDRIVE_FILE_ID_HERE":
        st.error("‚ùå Vui l√≤ng thay th·∫ø 'YOUR_GDRIVE_FILE_ID_HERE' b·∫±ng File ID th·ª±c t·∫ø.")
        return False
        
    # Ki·ªÉm tra n·∫øu dataset ƒë√£ ƒë∆∞·ª£c gi·∫£i n√©n th√†nh c√¥ng (ƒë·ªÉ tr√°nh t·∫£i l·∫°i)
    if os.path.exists(target_folder) and os.path.isdir(target_folder) and len(os.listdir(target_folder)) > 0:
        # Ki·ªÉm tra nhanh: N·∫øu file `representations_arcface.pkl` c·ªßa DeepFace ƒë√£ t·ªìn t·∫°i
        # th√¨ dataset ƒë√£ s·∫µn s√†ng.
        deepface_cache = os.path.join(target_folder, 'representations_arcface.pkl')
        if os.path.exists(deepface_cache):
             st.success(f"Dataset ƒë√£ s·∫µn s√†ng t·∫°i '{target_folder}'. B·ªè qua t·∫£i xu·ªëng.")
             return True
        st.info("Dataset folder t·ªìn t·∫°i nh∆∞ng thi·∫øu cache DeepFace, ƒëang th·ª≠ t·∫£i l·∫°i...")


    st.info(f"ƒêang t·∫£i dataset t·ª´ Google Drive File ID: {file_id}...")
    
    # URL t·∫£i file t·ª´ Google Drive
    DOWNLOAD_URL = f"https://drive.google.com/uc?export=download&id={file_id}"
    
    try:
        response = requests.get(DOWNLOAD_URL, stream=True)
        response.raise_for_status() 
        
        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p Google Drive c·∫£nh b√°o v·ªÅ dung l∆∞·ª£ng l·ªõn (cookies)
        if "confirm" in response.headers.get("Content-Disposition", ""):
            st.warning("Google Drive ƒëang y√™u c·∫ßu x√°c nh·∫≠n t·∫£i file l·ªõn. ƒêang th·ª≠ t·∫£i l·∫°i.")
            
            # L·∫•y confirm token
            for key, value in response.cookies.items():
                if key.startswith('download_warning'):
                    params = {'id': file_id, 'confirm': value}
                    response = requests.get(DOWNLOAD_URL, params=params, stream=True)
                    response.raise_for_status()
                    break

        # L∆∞u file zip
        with open(zip_name, "wb") as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)

        st.success(f"T·∫£i xu·ªëng {zip_name} th√†nh c√¥ng.")
        
        # Gi·∫£i n√©n
        with zipfile.ZipFile(zip_name, 'r') as zip_ref:
            if not os.path.exists(target_folder):
                os.makedirs(target_folder)
            zip_ref.extractall(target_folder)
            
        st.success(f"Gi·∫£i n√©n th√†nh c√¥ng v√†o th∆∞ m·ª•c '{target_folder}'.")
        
        # X√≥a file zip t·∫°m
        os.remove(zip_name)
        
        return True

    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫£i xu·ªëng ho·∫∑c gi·∫£i n√©n dataset t·ª´ Drive: {e}")
        if os.path.exists(zip_name):
            os.remove(zip_name)
        return False


# --- 3. H√†m Ph√°t hi·ªán Khu√¥n m·∫∑t (Gi·ªØ nguy√™n) ---
def detect_and_draw_face(image_bytes, cascade):
    """
    Nh·∫≠n di·ªán khu√¥n m·∫∑t tr√™n ·∫£nh ƒë·∫ßu v√†o, v·∫Ω khung, v√† tr·∫£ v·ªÅ ·∫£nh ƒë√£ x·ª≠ l√Ω 
    c√πng v·ªõi c·ªù (flag) cho bi·∫øt c√≥ khu√¥n m·∫∑t hay kh√¥ng.
    """
    image_pil = Image.open(io.BytesIO(image_bytes)).convert('RGB')
    image_np = np.array(image_pil)
    image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
    
    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
    
    faces = []
    if cascade is not None:
        faces = cascade.detectMultiScale(
            gray, 
            scaleFactor=1.1, 
            minNeighbors=5, 
            minSize=(30, 30)
        )

    for (x, y, w, h) in faces:
        cv2.rectangle(image_bgr, (x, y), (x + w, y + h), (255, 0, 0), 2)
    
    processed_image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)

    return processed_image_rgb, len(faces) > 0, len(faces), image_bgr # Th√™m len(faces) v√† image_bgr


# --- 4. H√†m DeepFace Recognition ---
def verify_face_against_dataset(target_image_path, dataset_folder):
    try:
        df_list = DeepFace.find(
            img_path=target_image_path, 
            db_path=dataset_folder, 
            model_name="ArcFace",
            distance_metric="cosine",
            enforce_detection=True, 
            # TH√äM THAM S·ªê N√ÄY ƒë·ªÉ tr√°nh RetinaFace g√¢y l·ªói
            detector_backend="opencv" 
        )
        
        if isinstance(df_list, list) and len(df_list) > 0 and not df_list[0].empty:
            best_match = df_list[0].iloc[0]
            identity_path = best_match['identity']
            person_name = os.path.splitext(os.path.basename(identity_path))[0]
            distance = best_match['ArcFace_cosine'] 
            return person_name, distance
        
        return None, None
    
    except ValueError as e:
        if "Face could not be detected" in str(e):
             st.error("‚ùå Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t trong ·∫£nh ch·ª•p. Vui l√≤ng th·ª≠ l·∫°i.")
        else:
            st.error(f"‚ùå L·ªói DeepFace: {e}")
        return None, None
    except Exception as e:
        st.error(f"‚ùå L·ªói trong qu√° tr√¨nh so kh·ªõp DeepFace: {e}")
        return None, None


# --- 5. Giao di·ªán v√† Lu·ªìng ·ª®ng d·ª•ng ---
st.info(f"ƒê·∫£m b·∫£o ƒë√£ thay th·∫ø **'YOUR_GDRIVE_FILE_ID_HERE'** b·∫±ng File ID c·ªßa file ZIP dataset c√¥ng khai tr√™n Google Drive.")

# 5.1 KH·ªûI T·∫†O V√Ä T·∫¢I DATASET
dataset_ready = download_and_extract_dataset(GDRIVE_FILE_ID, ZIP_FILENAME, DATASET_FOLDER)

st.markdown("---")

# 5.2 CH·ª§P ·∫¢NH V√Ä X·ª¨ L√ù
captured_file = st.camera_input("Ch·ª•p ·∫£nh ƒëi·ªÉm danh:")

if captured_file is not None:
    if not dataset_ready: # Ki·ªÉm tra dataset ƒë√£ s·∫µn s√†ng ch∆∞a
        st.error("Kh√¥ng th·ªÉ x·ª≠ l√Ω do l·ªói t·∫£i dataset t·ª´ Google Drive.")
    elif face_cascade is None:
        st.error("Kh√¥ng th·ªÉ ti·∫øp t·ª•c do l·ªói t·∫£i b·ªô ph√¢n lo·∫°i khu√¥n m·∫∑t.")
    else:
        image_bytes = captured_file.getvalue()
        
        with st.spinner('ƒêang x·ª≠ l√Ω ·∫£nh v√† nh·∫≠n di·ªán khu√¥n m·∫∑t...'):
            # 1. Ph√°t hi·ªán khu√¥n m·∫∑t v√† v·∫Ω khung
            processed_image_np, face_detected, num_faces, image_bgr = detect_and_draw_face(image_bytes, face_cascade)
            
            processed_image = Image.fromarray(processed_image_np)
            
            # 2. L∆∞u ·∫£nh t·∫°m th·ªùi ƒë·ªÉ DeepFace s·ª≠ d·ª•ng
            cv2.imwrite(TEMP_IMAGE_PATH, image_bgr)
            
            # 3. Th·ª±c hi·ªán so kh·ªõp DeepFace
            match_name, distance = verify_face_against_dataset(TEMP_IMAGE_PATH, DATASET_FOLDER)

        # X√≥a file t·∫°m sau khi ƒë√£ x·ª≠ l√Ω
        if os.path.exists(TEMP_IMAGE_PATH):
            os.remove(TEMP_IMAGE_PATH)
            
        st.subheader("üñºÔ∏è ·∫¢nh ƒë√£ ch·ª•p v√† Nh·∫≠n di·ªán")
        st.image(processed_image, caption="Khu√¥n m·∫∑t ƒë√£ ph√°t hi·ªán ƒë∆∞·ª£c ƒë√°nh d·∫•u b·∫±ng khung m√†u xanh d∆∞∆°ng.", use_column_width=True)

        st.markdown("---")
        st.subheader("üí° K·∫øt qu·∫£ ƒêi·ªÉm danh")
        
        if match_name:
            st.success(f"‚úÖ **ƒêI·ªÇM DANH TH√ÄNH C√îNG!**")
            st.markdown(f"""
            * **Ng∆∞·ªùi tr√πng kh·ªõp:** **{match_name}**
            * **Kho·∫£ng c√°ch Cosine (ArcFace):** {distance:.4f}
            """)
            
        elif face_detected:
            st.warning(f"‚ö†Ô∏è **Ph√°t hi·ªán {num_faces} khu√¥n m·∫∑t, nh∆∞ng kh√¥ng kh·ªõp v·ªõi dataset.**")
            st.markdown("""
            * Vui l√≤ng ki·ªÉm tra l·∫°i √°nh s√°ng ho·∫∑c ƒë·ªô r√µ c·ªßa khu√¥n m·∫∑t.
            * ƒê·∫£m b·∫£o t√™n file ·∫£nh trong dataset kh·ªõp v·ªõi t√™n ng∆∞·ªùi ƒëƒÉng k√Ω.
            """)
            
        else:
            st.warning("‚ö†Ô∏è **Kh√¥ng ph√°t hi·ªán th·∫•y khu√¥n m·∫∑t.**")
            st.markdown("Vui l√≤ng th·ª≠ l·∫°i. ƒê·∫£m b·∫£o khu√¥n m·∫∑t c·ªßa b·∫°n n·∫±m g·ªçn v√† r√µ r√†ng trong khung h√¨nh.")
