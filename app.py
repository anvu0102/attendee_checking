import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io
import requests
import os
import zipfile
from deepface import DeepFace
import tempfile
import time 
import pandas as pd
# --- TH∆Ø VI·ªÜN GOOGLE DRIVE API V√Ä OAUTH ---
from google.oauth2.credentials import Credentials
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload
# ----------------------------------------

# --- 1. Thi·∫øt l·∫≠p trang Streamlit ---
st.set_page_config(
    page_title="H·ªá th·ªëng ƒêi·ªÉm danh Khu√¥n m·∫∑t DeepFace (GDrive)",
    page_icon="üì∏",
    layout="centered"
)

st.title("üì∏ H·ªá th·ªëng ƒêi·ªÉm danh Khu√¥n m·∫∑t DeepFace")
st.caption("S·ª≠ d·ª•ng ID Drive v√† OAuth Credentials t·ª´ st.secrets.")

# --- 2. C·∫•u h√¨nh & H·∫±ng s·ªë (T·∫¢I T·ª™ ST.SECRETS) ---
HAAR_CASCADE_URL = "https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml"
CASCADE_FILENAME = 'haarcascade_frontalface_default.xml'

# PH·∫†M VI (SCOPES) CHO GOOGLE DRIVE API
SCOPES = ['https://www.googleapis.com/auth/drive.readonly', 'https://www.googleapis.com/auth/drive.file']

# T·∫¢I C√ÅC TH√îNG TIN T·ª™ ST.SECRETS
try:
    GDRIVE_CLIENT_ID = st.secrets["GDRIVE_CLIENT_ID"]
    GDRIVE_CLIENT_SECRET = st.secrets["GDRIVE_CLIENT_SECRET"]
    GDRIVE_DATASET_FOLDER_ID = st.secrets["GDRIVE_DATASET_ID"] 
    GDRIVE_CHECKLIST_ID = st.secrets["GDRIVE_CHECKLIST_ID"]
    GDRIVE_NEW_DATA_FOLDER_ID = st.secrets["GDRIVE_NEW_DATA_ID"]
    # Kh√≥a m·ªõi th√™m v√†o ƒë·ªÉ x√°c th·ª±c non-interactive
    GDRIVE_REFRESH_TOKEN = st.secrets["GDRIVE_REFRESH_TOKEN"] 
except KeyError as e:
    st.error(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y kh√≥a {e} trong st.secrets.")
    st.info("Vui l√≤ng ƒë·∫£m b·∫£o b·∫°n ƒë√£ ƒë·ªãnh nghƒ©a t·∫•t c·∫£ c√°c kh√≥a (CLIENT_ID, CLIENT_SECRET, DATASET_ID, CHECKLIST_ID, NEW_DATA_ID, REFRESH_TOKEN) trong file .streamlit/secrets.toml ho·∫∑c trong giao di·ªán Secrets c·ªßa Streamlit Cloud.")
    st.stop()

# C√°c h·∫±ng s·ªë kh√°c
DATASET_FOLDER = "dataset" 
CHECKLIST_FILENAME = "checklist.xlsx" 
CHECKLIST_SESSION_KEY = "attendance_df" 
DETECTOR_BACKEND = "opencv"

# ----------------------------------------------------------------------
#                             C√ÅC H√ÄM TH·ª∞C T·∫æ
# ----------------------------------------------------------------------

# --- 1. H√ÄM X√ÅC TH·ª∞C OAUTH (REAL - Non-interactive cho Streamlit Cloud) ---
@st.cache_resource(show_spinner="ƒêang t·∫£i v√† l√†m m·ªõi Access Token t·ª´ st.secrets...")
def get_valid_access_token_real(client_id, client_secret):
    """ 
    TH·ª∞C T·∫æ: L·∫•y Credentials t·ª´ st.secrets (d·∫°ng non-interactive) v√† l√†m m·ªõi token.
    """
    
    # 1. T·∫°o ƒë·ªëi t∆∞·ª£ng Credentials t·ª´ Refresh Token
    creds = Credentials(
        token=None,
        refresh_token=GDRIVE_REFRESH_TOKEN,
        token_uri="https://oauth2.googleapis.com/token",
        client_id=client_id,
        client_secret=client_secret,
        scopes=SCOPES
    )

    # 2. L√†m m·ªõi Token
    if creds.expired and creds.refresh_token:
        try:
            st.info("ƒêang l√†m m·ªõi Access Token...")
            creds.refresh(Request())
            st.success("‚úÖ ƒê√£ l√†m m·ªõi Access Token th√†nh c√¥ng.")
        except Exception as e:
            st.error(f"‚ùå L·ªói khi l√†m m·ªõi Access Token: {e}")
            st.info("G·ª£i √Ω: Refresh Token c√≥ th·ªÉ ƒë√£ h·∫øt h·∫°n ho·∫∑c b·ªã thu h·ªìi. Vui l√≤ng ki·ªÉm tra l·∫°i token v√† quy·ªÅn truy c·∫≠p.")
            return None
    elif not creds.refresh_token:
        st.error("‚ùå L·ªói: Credentials kh√¥ng c√≥ Refresh Token.")
        return None
        
    st.success("‚úÖ Access Token ƒë√£ s·∫µn s√†ng.")
    return creds


# --- 2. H√ÄM T·∫¢I FILE ƒê∆†N L·∫∫ T·ª™ G-DRIVE (REAL) ---
# CH√ö √ù: ƒê√£ ƒë·ªïi t√™n tham s·ªë th√†nh _credentials
def download_file_from_gdrive(file_id, output_filename, _credentials):
    """ T·∫£i file t·ª´ Google Drive d√πng Google Drive API. """
    
    try:
        service = build('drive', 'v3', credentials=_credentials)
        request = service.files().get_media(fileId=file_id)
        
        with open(output_filename, 'wb') as fh:
            downloader = MediaIoBaseDownload(fh, request)
            done = False
            with st.spinner(f"ƒêang t·∫£i file {output_filename}..."):
                while done is False:
                    status, done = downloader.next_chunk()
        st.info(f"ƒê√£ t·∫£i th√†nh c√¥ng file: {output_filename}")
        return True
    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫£i file {output_filename} t·ª´ Drive: {e}")
        st.warning("G·ª£i √Ω: Ki·ªÉm tra ID file v√† quy·ªÅn truy c·∫≠p c·ªßa t√†i kho·∫£n ƒë√£ x√°c th·ª±c.")
        return False


# --- 3. H√ÄM T·∫¢I DATASET FOLDER (REAL) ---
@st.cache_resource(show_spinner="ƒêang t·∫£i Dataset Folder t·ª´ Google Drive...")
# CH√ö √ù: ƒê√£ ƒë·ªïi t√™n tham s·ªë th√†nh _credentials
def download_dataset_folder_real(folder_id, target_folder, _credentials):
    """ TH·ª∞C T·∫æ: T·∫£i to√†n b·ªô n·ªôi dung folder Drive v√†o th∆∞ m·ª•c local. """
    if os.path.isdir(target_folder) and len(os.listdir(target_folder)) > 0:
        st.success(f"Dataset folder ƒë√£ s·∫µn s√†ng t·∫°i '{target_folder}'. B·ªè qua t·∫£i xu·ªëng.")
        return True

    if not os.path.exists(target_folder):
        os.makedirs(target_folder)
        
    try:
        service = build('drive', 'v3', credentials=_credentials)
        query = f"'{folder_id}' in parents and trashed = false"
        results = service.files().list(
            q=query, 
            pageSize=1000,
            fields="nextPageToken, files(id, name)"
        ).execute()
        items = results.get('files', [])

        if not items:
            st.warning(f"Folder ID: {folder_id} tr·ªëng r·ªóng. Kh√¥ng c√≥ dataset.")
            return False

        st.info(f"T√¨m th·∫•y {len(items)} file trong dataset. ƒêang t·∫£i xu·ªëng...")
        
        for item in items:
            file_id = item['id']
            file_name = item['name']
            output_path = os.path.join(target_folder, file_name)
            
            request = service.files().get_media(fileId=file_id)
            with open(output_path, 'wb') as fh:
                downloader = MediaIoBaseDownload(fh, request)
                done = False
                while done is False:
                    status, done = downloader.next_chunk()

        st.success(f"‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng {len(items)} file ·∫£nh dataset v√†o th∆∞ m·ª•c '{target_folder}'.")
        return True
        
    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫£i Dataset Folder t·ª´ Drive: {e}")
        return False


# --- 4. H√ÄM UPLOAD FILE M·ªöI (REAL) ---
# CH√ö √ù: ƒê√£ ƒë·ªïi t√™n tham s·ªë th√†nh _credentials
def upload_to_gdrive_real(file_path, drive_folder_id, drive_filename, _credentials):
    """
    T·∫£i file l√™n Google Drive b·∫±ng Google Drive API, c·∫ßn Credential th·∫≠t.
    """
    if _credentials is None:
        st.error("‚ùå L·ªói Auth: Kh√¥ng th·ªÉ upload v√¨ kh√¥ng c√≥ Credential h·ª£p l·ªá.")
        return False
    
    try:
        service = build('drive', 'v3', credentials=_credentials)
        
        # Metadata c·ªßa file
        file_metadata = {
            'name': drive_filename,
            'parents': [drive_folder_id] 
        }
        
        # Media to upload
        media = MediaFileUpload(file_path, mimetype='image/jpeg', resumable=True)
        
        with st.spinner(f"ƒêang t·∫£i file '{drive_filename}' l√™n Drive..."):
            file = service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id'
            ).execute()

        st.success(f"‚úÖ **Upload Th√†nh C√¥ng:** File '{drive_filename}' ƒë√£ ƒë∆∞·ª£c l∆∞u v·ªõi ID: `{file.get('id')}`.")
        st.info(f"ƒê√£ l∆∞u v√†o Drive Folder ID: **{drive_folder_id}**.")
        
        return True
        
    except Exception as e:
        st.error(f"‚ùå L·ªói khi Upload file m·ªõi l√™n Drive: {e}")
        return False


# --- 5. H√ÄM T·∫¢I CHECKLIST (REAL) ---
@st.cache_data(show_spinner="ƒêang t·∫£i v√† x·ª≠ l√Ω Checklist (XLSX) t·ª´ Google Drive...")
# CH√ö √ù: ƒê√£ ƒë·ªïi t√™n tham s·ªë th√†nh _credentials
def load_checklist(file_id, filename, _credentials):
    """ T·∫£i checklist XLSX v√† ƒë·ªçc th√†nh DataFrame. """
    
    if not os.path.exists(filename):
        # Truy·ªÅn _credentials v√†o h√†m download
        download_file_from_gdrive(file_id, filename, _credentials)
        
    if os.path.exists(filename):
        try:
            # ƒê·ªåC FILE XLSX
            df = pd.read_excel(filename) 
            return df
        except Exception as e:
            st.error(f"‚ùå L·ªói khi ƒë·ªçc file checklist: {e}. ƒê·∫£m b·∫£o file c√≥ ƒë·ªãnh d·∫°ng XLSX.")
            return None
    return None

# ----------------------------------------------------------------------
#                             C√ÅC H√ÄM X·ª¨ L√ù
# ----------------------------------------------------------------------

@st.cache_resource
def load_face_cascade(url, filename):
    """ T·∫£i Haar Cascade cho OpenCV. """
    try:
        r = requests.get(url)
        if r.status_code == 200:
            with open(filename, 'wb') as f:
                f.write(r.content)
            classifier = cv2.CascadeClassifier(filename)
            if not classifier.empty():
                return classifier
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i ho·∫∑c kh·ªüi t·∫°o Haar Cascade: {e}")
        return None

face_cascade = load_face_cascade(HAAR_CASCADE_URL, CASCADE_FILENAME)


# --- H√†m Ph√°t hi·ªán Khu√¥n m·∫∑t (Gi·ªØ nguy√™n) ---
def detect_and_draw_face(image_bytes, cascade):
    """ D√πng Haar Cascade ƒë·ªÉ ph√°t hi·ªán v√† v·∫Ω khung khu√¥n m·∫∑t tr√™n ·∫£nh. """
    image_pil = Image.open(io.BytesIO(image_bytes)).convert('RGB')
    image_np = np.array(image_pil)
    image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
    
    faces = []
    if cascade is not None:
        faces = cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

    for (x, y, w, h) in faces:
        cv2.rectangle(image_bgr, (x, y), (x + w, y + h), (255, 0, 0), 2)
    
    processed_image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)

    return processed_image_rgb, len(faces) > 0, len(faces), image_bgr


# --- H√†m DeepFace Recognition (Gi·ªØ nguy√™n) ---
def verify_face_against_dataset(target_image_path, dataset_folder):
    """ S·ª≠ d·ª•ng DeepFace ƒë·ªÉ so s√°nh ·∫£nh ƒë·∫ßu v√†o v·ªõi dataset. """
    try:
        df_list = DeepFace.find(
            img_path=target_image_path, 
            db_path=dataset_folder, 
            model_name="ArcFace",
            distance_metric="cosine",
            enforce_detection=True, 
            detector_backend=DETECTOR_BACKEND 
        )
        if isinstance(df_list, list) and len(df_list) > 0 and not df_list[0].empty:
            best_match = df_list[0].iloc[0]
            identity_path = best_match['identity']
            stt_match = os.path.splitext(os.path.basename(identity_path))[0] 
            distance = best_match['ArcFace_cosine'] 
            return stt_match, distance
        return None, None
    except Exception as e:
        if "Face could not be detected" in str(e):
             st.error(f"‚ùå L·ªói DeepFace: Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t ƒë·ªÉ so kh·ªõp.")
        else:
            st.error(f"‚ùå L·ªói DeepFace: {e}")
        return None, None


# --- Logic Ghi D·ªØ Li·ªáu v√† L∆∞u ·∫¢nh M·ªõi ---
# CH√ö √ù: ƒê√£ ƒë·ªïi t√™n tham s·ªë th√†nh _credentials
def update_checklist_and_save_new_data(stt_match, session_name, image_bytes, _credentials):
    """
    C·∫≠p nh·∫≠t DataFrame checklist v√† l∆∞u ·∫£nh m·ªõi l√™n Drive.
    """
    if CHECKLIST_SESSION_KEY not in st.session_state:
        st.error("L·ªói: Kh√¥ng t√¨m th·∫•y DataFrame checklist trong Session State.")
        return

    df = st.session_state[CHECKLIST_SESSION_KEY]
    
    # 1. C·∫≠p nh·∫≠t Checklist (ƒê√°nh 'X')
    if stt_match is not None:
        try:
            stt_col = df.columns[0] 
            stt_match_str = str(stt_match).split('_')[0] 
            
            row_index = df[df[stt_col].astype(str).str.contains(stt_match_str, regex=False)].index
            
            if not row_index.empty:
                df.loc[row_index[0], session_name] = 'X'
                st.session_state[CHECKLIST_SESSION_KEY] = df 
                
                st.success(f"‚úÖ **ƒê√£ c·∫≠p nh·∫≠t ƒëi·ªÉm danh** cho STT **{df.loc[row_index[0], stt_col]}** v√†o c·ªôt **{session_name}**.")
                st.info(f"‚ö†Ô∏è **C·∫ßn th√™m ch·ª©c nƒÉng ghi ng∆∞·ª£c (Write-Back) DataFrame n√†y l√™n file XLSX Drive ID: {GDRIVE_CHECKLIST_ID}**.")
                
            else:
                st.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y STT **{stt_match_str}** trong checklist ƒë·ªÉ c·∫≠p nh·∫≠t.")
        except Exception as e:
            st.error(f"L·ªói khi c·∫≠p nh·∫≠t checklist: {e}")
            
    # 2. L∆∞u ·∫£nh m·ªõi l√™n Drive (N·∫øu kh√¥ng kh·ªõp)
    else: 
        if 'new_data_counter' not in st.session_state:
            st.session_state['new_data_counter'] = 0
            
        st.session_state['new_data_counter'] += 1
        new_counter = st.session_state['new_data_counter']
        
        session_num = session_name.replace("Bu·ªïi ", "")
        drive_filename = f"B{session_num}_{new_counter}.jpg" 
        
        # --- T·∫†O FILE T·∫†M ƒê·ªÇ UPLOAD ---
        temp_file_for_upload = tempfile.NamedTemporaryFile(suffix=".jpg", delete=False)
        TEMP_UPLOAD_PATH = temp_file_for_upload.name
        temp_file_for_upload.close()
        
        try:
            image_to_save = Image.open(io.BytesIO(image_bytes)).convert('RGB')
            image_to_save.save(TEMP_UPLOAD_PATH, format='JPEG')
            
            # 2. G·ªçi h√†m Upload Drive (REAL) - Truy·ªÅn _credentials
            upload_to_gdrive_real(TEMP_UPLOAD_PATH, GDRIVE_NEW_DATA_FOLDER_ID, drive_filename, _credentials)

        except Exception as e:
             st.error(f"‚ùå L·ªói khi t·∫°o file t·∫°m ho·∫∑c g·ªçi h√†m upload: {e}")
        finally:
            if os.path.exists(TEMP_UPLOAD_PATH):
                os.remove(TEMP_UPLOAD_PATH)


# ----------------------------------------------------------------------
#                             GIAO DI·ªÜN CH√çNH
# ----------------------------------------------------------------------

# L·∫§Y CREDENTIALS ƒê·∫¶U TI√äN
CREDENTIALS = get_valid_access_token_real(GDRIVE_CLIENT_ID, GDRIVE_CLIENT_SECRET)

if not CREDENTIALS:
    st.error("‚ùå Kh√¥ng th·ªÉ ti·∫øp t·ª•c do kh√¥ng l·∫•y ƒë∆∞·ª£c Credential h·ª£p l·ªá.")
    st.stop()


# 7.1 KH·ªûI T·∫†O V√Ä T·∫¢I DATASET & CHECKLIST
# T·∫£i Folder Dataset (REAL) - Truy·ªÅn CREDENTIALS v√†o tham s·ªë _credentials
dataset_ready = download_dataset_folder_real(GDRIVE_DATASET_FOLDER_ID, DATASET_FOLDER, CREDENTIALS) 
# T·∫£i Checklist (XLSX) - Truy·ªÅn CREDENTIALS v√†o tham s·ªë _credentials
checklist_df = load_checklist(GDRIVE_CHECKLIST_ID, CHECKLIST_FILENAME, CREDENTIALS)

if checklist_df is not None:
    st.session_state[CHECKLIST_SESSION_KEY] = checklist_df
    
st.markdown("---")

if not dataset_ready:
     st.warning("‚ö†Ô∏è L·ªói t·∫£i Dataset Folder. Vui l√≤ng ki·ªÉm tra ID Drive Folder v√† quy·ªÅn truy c·∫≠p.")
     st.stop()
     
if checklist_df is None:
     st.warning("‚ö†Ô∏è L·ªói t·∫£i ho·∫∑c ƒë·ªçc file Checklist. Vui l√≤ng ki·ªÉm tra File ID v√† quy·ªÅn truy c·∫≠p b·∫±ng token.")
     st.stop()


st.info(f"Dataset ƒë√£ s·∫µn s√†ng. Checklist c√≥ {len(checklist_df)} ng∆∞·ªùi.")


# 7.2 CH·ªåN BU·ªîI H·ªåC (Dropdown)
attendance_cols = [col for col in st.session_state[CHECKLIST_SESSION_KEY].columns if "Bu·ªïi" in col]

if not attendance_cols:
     st.error("Kh√¥ng t√¨m th·∫•y c·ªôt 'Bu·ªïi' trong checklist. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u tr√∫c file XLSX.")
     st.stop()

selected_session = st.selectbox(
    "1Ô∏è‚É£ **Ch·ªçn Bu·ªïi ƒêi·ªÉm Danh**", 
    attendance_cols, 
    index=0,
    help="Ch·ªçn bu·ªïi t∆∞∆°ng ·ª©ng ƒë·ªÉ c·∫≠p nh·∫≠t c·ªôt ƒëi·ªÉm danh trong checklist."
)
st.success(f"ƒêang ƒëi·ªÉm danh cho: **{selected_session}**")

st.markdown("---")

# 7.3 CH·ª§P ·∫¢NH V√Ä X·ª¨ L√ù
captured_file = st.camera_input("2Ô∏è‚É£ Ch·ª•p ·∫£nh ƒëi·ªÉm danh:")

if captured_file is not None:
    
    image_bytes = captured_file.getvalue()
    
    with st.spinner('ƒêang x·ª≠ l√Ω ·∫£nh v√† nh·∫≠n di·ªán khu√¥n m·∫∑t...'):
        
        processed_image_np, face_detected, num_faces, image_bgr = detect_and_draw_face(image_bytes, face_cascade)
        processed_image = Image.fromarray(processed_image_np)
        
        # L∆ØU ·∫¢NH T·∫†M TH·ªúI cho DeepFace so kh·ªõp
        temp_file = tempfile.NamedTemporaryFile(suffix=".jpg", delete=False)
        TEMP_IMAGE_PATH = temp_file.name
        temp_file.close() 
        
        cv2.imwrite(TEMP_IMAGE_PATH, image_bgr)
        
        # Th·ª±c hi·ªán so kh·ªõp DeepFace
        stt_match, distance = verify_face_against_dataset(TEMP_IMAGE_PATH, DATASET_FOLDER)

    # X√≥a file t·∫°m c·ªßa DeepFace
    if os.path.exists(TEMP_IMAGE_PATH):
        os.remove(TEMP_IMAGE_PATH)
        
    st.subheader("üñºÔ∏è ·∫¢nh ƒë√£ ch·ª•p v√† Nh·∫≠n di·ªán")
    st.image(processed_image, caption="Khu√¥n m·∫∑t ƒë√£ ph√°t hi·ªán ƒë∆∞·ª£c ƒë√°nh d·∫•u.", use_column_width=True)

    st.markdown("---")
    st.subheader("üí° K·∫øt qu·∫£ ƒêi·ªÉm danh")
    
    if stt_match:
        st.balloons()
        st.success(f"‚úÖ **ƒêI·ªÇM DANH TH√ÄNH C√îNG!**")
        st.markdown(f"""
        * **STT tr√πng kh·ªõp:** **{stt_match}**
        * **ƒê·ªô t∆∞∆°ng ƒë·ªìng (Kho·∫£ng c√°ch Cosine):** `{distance:.4f}`
        """)
        # C·∫≠p nh·∫≠t checklist (truy·ªÅn credentials)
        update_checklist_and_save_new_data(stt_match, selected_session, None, CREDENTIALS)
        
    elif face_detected and num_faces == 1:
        st.warning(f"‚ö†Ô∏è **Ph√°t hi·ªán 1 khu√¥n m·∫∑t, nh∆∞ng kh√¥ng kh·ªõp v·ªõi dataset.**")
        # L∆∞u ·∫£nh m·ªõi (truy·ªÅn image_bytes v√† credentials)
        update_checklist_and_save_new_data(None, selected_session, image_bytes, CREDENTIALS) 
        
    elif face_detected and num_faces > 1:
        st.error(f"‚ùå **Ph√°t hi·ªán nhi·ªÅu khu√¥n m·∫∑t ({num_faces}). Vui l√≤ng ch·ªâ c√≥ 1 ng∆∞·ªùi trong khung h√¨nh.**")

    else:
        st.warning("‚ö†Ô∏è **Kh√¥ng ph√°t hi·ªán th·∫•y khu√¥n m·∫∑t.**")
        st.markdown("Vui l√≤ng th·ª≠ l·∫°i. ƒê·∫£m b·∫£o khu√¥n m·∫∑t c·ªßa b·∫°n n·∫±m g·ªçn v√† r√µ r√†ng trong khung h√¨nh.")

st.markdown("---")
st.subheader("üìã Tr·∫°ng th√°i Checklist Hi·ªán t·∫°i (Trong Session)")
if CHECKLIST_SESSION_KEY in st.session_state:
    st.dataframe(st.session_state[CHECKLIST_SESSION_KEY])
