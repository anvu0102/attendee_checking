import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io
import requests
import os
import zipfile
from deepface import DeepFace
import tempfile
import time 
import pandas as pd # Th√™m th∆∞ vi·ªán pandas ƒë·ªÉ x·ª≠ l√Ω file checklist

# --- 1. Thi·∫øt l·∫≠p trang Streamlit ---
st.set_page_config(
    page_title="H·ªá th·ªëng ƒêi·ªÉm danh Khu√¥n m·∫∑t DeepFace (GDrive)",
    page_icon="üì∏",
    layout="centered"
)

st.title("üì∏ H·ªá th·ªëng ƒêi·ªÉm danh Khu√¥n m·∫∑t DeepFace")
st.caption("Dataset v√† Checklist ƒë∆∞·ª£c t·∫£i t·ª´ Google Drive c√¥ng khai.")

# --- 2. C·∫•u h√¨nh & H·∫±ng s·ªë ---
HAAR_CASCADE_URL = "https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml"
CASCADE_FILENAME = 'haarcascade_frontalface_default.xml'

# Vui l√≤ng thay th·∫ø chu·ªói n√†y b·∫±ng File ID c·ªßa file ZIP dataset c√¥ng khai c·ªßa b·∫°n.
GDRIVE_DATASET_ID = "1-yAtAUD5FY69hlLYP_O3pfqRzKgompcd"
ZIP_FILENAME = "dataset_archive.zip" 
DATASET_FOLDER = "dataset" 

# Vui l√≤ng thay th·∫ø chu·ªói n√†y b·∫±ng File ID c·ªßa file CHECKLIST c√¥ng khai c·ªßa b·∫°n.
GDRIVE_CHECKLIST_ID = "1lcVBJZ55nQVoQYi6PK0iUV5Y_cCY74lv"
CHECKLIST_FILENAME = "checklist.csv" 
CHECKLIST_SESSION_KEY = "attendance_df" # Key ƒë·ªÉ l∆∞u DataFrame trong session state

DETECTOR_BACKEND = "opencv"
NEW_DATA_FOLDER = "new_data" # Th∆∞ m·ª•c local ƒë·ªÉ l∆∞u ·∫£nh m·ªõi (m√¥ ph·ªèng)

# --- H√†m t·∫£i file t·ª´ Google Drive (T√°i s·ª≠ d·ª•ng) ---
def download_file_from_gdrive(file_id, output_filename):
    """ T·∫£i file c√¥ng khai t·ª´ Google Drive. """
    DOWNLOAD_URL = f"https://drive.google.com/uc?export=download&id={file_id}"
    try:
        response = requests.get(DOWNLOAD_URL, stream=True)
        response.raise_for_status() 
        
        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p Google Drive c·∫£nh b√°o file l·ªõn
        if "confirm" in response.headers.get("Content-Disposition", ""):
            for key, value in response.cookies.items():
                if key.startswith('download_warning'):
                    params = {'id': file_id, 'confirm': value}
                    response = requests.get(DOWNLOAD_URL, params=params, stream=True)
                    response.raise_for_status()
                    break

        with open(output_filename, "wb") as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
        return True
    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫£i file {output_filename} t·ª´ Drive: {e}")
        return False


@st.cache_resource
def load_face_cascade(url, filename):
    """ T·∫£i Haar Cascade cho OpenCV. """
    # N·ªôi dung gi·ªØ nguy√™n
    try:
        r = requests.get(url)
        if r.status_code == 200:
            with open(filename, 'wb') as f:
                f.write(r.content)
            classifier = cv2.CascadeClassifier(filename)
            if not classifier.empty():
                return classifier
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i ho·∫∑c kh·ªüi t·∫°o Haar Cascade: {e}")
        return None

face_cascade = load_face_cascade(HAAR_CASCADE_URL, CASCADE_FILENAME)


@st.cache_resource(show_spinner="ƒêang t·∫£i v√† gi·∫£i n√©n Dataset t·ª´ Google Drive (Ch·ªâ ch·∫°y l·∫ßn ƒë·∫ßu)...")
def download_and_extract_dataset(file_id, zip_name, target_folder):
    """ T·∫£i v√† gi·∫£i n√©n dataset ZIP. """
    # N·ªôi dung gi·ªØ nguy√™n, ch·ªâ thay ID
    if file_id == "YOUR_GDRIVE_FILE_ID_HERE":
        st.error("‚ùå Vui l√≤ng thay th·∫ø File ID th·ª±c t·∫ø c·ªßa file ZIP dataset.")
        return False
        
    deepface_cache = os.path.join(target_folder, 'representations_arcface.pkl')
    if os.path.exists(deepface_cache) and os.path.isdir(target_folder) and len(os.listdir(target_folder)) > 1:
         st.success(f"Dataset ƒë√£ s·∫µn s√†ng t·∫°i '{target_folder}'. B·ªè qua t·∫£i xu·ªëng.")
         return True
    
    st.info(f"ƒêang t·∫£i dataset t·ª´ Google Drive File ID: {file_id}...")
    
    if download_file_from_gdrive(file_id, zip_name):
        try:
            with zipfile.ZipFile(zip_name, 'r') as zip_ref:
                if not os.path.exists(target_folder):
                    os.makedirs(target_folder)
                zip_ref.extractall(".")
            st.success(f"Gi·∫£i n√©n th√†nh c√¥ng v√†o th∆∞ m·ª•c '{target_folder}'.")
            if os.path.exists(zip_name):
                os.remove(zip_name)
            return True
        except Exception as e:
            st.error(f"‚ùå L·ªói khi gi·∫£i n√©n: {e}")
            return False
    return False

@st.cache_data(show_spinner="ƒêang t·∫£i v√† x·ª≠ l√Ω Checklist t·ª´ Google Drive...")
def load_checklist(file_id, filename):
    """ T·∫£i checklist CSV/Excel v√† ƒë·ªçc th√†nh DataFrame. """
    if file_id == "YOUR_GDRIVE_CHECKLIST_ID_HERE":
        st.error("‚ùå Vui l√≤ng thay th·∫ø File ID th·ª±c t·∫ø c·ªßa file checklist.")
        return None
    
    if download_file_from_gdrive(file_id, filename):
        try:
            # Gi·∫£ ƒë·ªãnh file checklist l√† CSV
            df = pd.read_csv(filename)
            # Gi·∫£ ƒë·ªãnh c·ªôt ƒë·∫ßu ti√™n l√† STT, ch√∫ng ta c·∫ßn c·ªôt n√†y ƒë·ªÉ kh·ªõp v·ªõi t√™n file
            if os.path.exists(filename):
                os.remove(filename)
            return df
        except Exception as e:
            st.error(f"‚ùå L·ªói khi ƒë·ªçc file checklist: {e}. ƒê·∫£m b·∫£o file c√≥ ƒë·ªãnh d·∫°ng CSV.")
            return None
    return None

# --- 3. H√†m Ph√°t hi·ªán Khu√¥n m·∫∑t (D√πng cho hi·ªÉn th·ªã khung) ---
# Gi·ªØ nguy√™n h√†m detect_and_draw_face

# --- 4. H√†m DeepFace Recognition (S·ª≠ d·ª•ng detector_backend="opencv") ---
def verify_face_against_dataset(target_image_path, dataset_folder):
    """
    S·ª≠ d·ª•ng DeepFace ƒë·ªÉ so s√°nh ·∫£nh ƒë·∫ßu v√†o v·ªõi dataset.
    """
    try:
        # THAY ƒê·ªîI QUAN TR·ªåNG: S·ª≠ d·ª•ng detector_backend="opencv"
        df_list = DeepFace.find(
            img_path=target_image_path, 
            db_path=dataset_folder, 
            model_name="ArcFace",
            distance_metric="cosine",
            enforce_detection=True, 
            detector_backend=DETECTOR_BACKEND 
        )
        
        if isinstance(df_list, list) and len(df_list) > 0 and not df_list[0].empty:
            best_match = df_list[0].iloc[0]
            identity_path = best_match['identity']
            # L·∫•y t√™n file (STT) t·ª´ t√™n file (lo·∫°i b·ªè ph·∫ßn m·ªü r·ªông)
            stt_match = os.path.splitext(os.path.basename(identity_path))[0] 
            # L·∫•y t√™n ng∆∞·ªùi t·ª´ path (v√≠ d·ª•: dataset/111_Tr·∫ßn_Trung_Minh.jpg -> 111_Tr·∫ßn_Trung_Minh)
            person_name = os.path.basename(os.path.dirname(identity_path))
            distance = best_match['ArcFace_cosine'] 
            return stt_match, distance, person_name
        
        return None, None, None
    
    except ValueError as e:
        if "Face could not be detected" in str(e):
             st.error(f"‚ùå L·ªói DeepFace: Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t ƒë·ªÉ so kh·ªõp. Vui l√≤ng th·ª≠ l·∫°i ·∫£nh r√µ r√†ng h∆°n.")
        else:
            st.error(f"‚ùå L·ªói DeepFace: {e}")
        return None, None, None
    except Exception as e:
        st.error(f"‚ùå L·ªói trong qu√° tr√¨nh so kh·ªõp DeepFace: {e}")
        return None, None, None

# --- 5. Logic Ghi D·ªØ Li·ªáu (M√¥ ph·ªèng ghi l√™n Drive) ---

def update_checklist_and_save_new_data(stt_match, captured_image_bgr, session_name):
    """
    C·∫≠p nh·∫≠t DataFrame checklist v√† l∆∞u ·∫£nh m·ªõi (ho·∫∑c m√¥ ph·ªèng).
    """
    if CHECKLIST_SESSION_KEY not in st.session_state:
        st.error("L·ªói: Kh√¥ng t√¨m th·∫•y DataFrame checklist trong Session State.")
        return

    df = st.session_state[CHECKLIST_SESSION_KEY]
    
    # 1. C·∫≠p nh·∫≠t Checklist (ƒê√°nh 'X')
    if stt_match is not None:
        # T√¨m d√≤ng c√≥ STT t∆∞∆°ng ·ª©ng (Gi·∫£ ƒë·ªãnh c·ªôt ƒë·∫ßu ti√™n c·ªßa CSV/Excel l√† STT)
        # T√™n file trong dataset l√† STT. Ch√∫ng ta c·∫ßn t√¨m d√≤ng trong DF c√≥ STT n√†y.
        try:
            # Chuy·ªÉn STT sang string ƒë·ªÉ t√¨m ki·∫øm, n·∫øu STT trong DF l√† int/float
            stt_match_str = str(stt_match)
            # L·∫•y t√™n c·ªôt ƒë·∫ßu ti√™n (v√≠ d·ª•: 'Stt')
            stt_col = df.columns[0] 
            
            # T√¨m ch·ªâ s·ªë d√≤ng c·ªßa STT
            row_index = df[df[stt_col].astype(str).str.startswith(stt_match_str)].index
            
            if not row_index.empty:
                # C·∫≠p nh·∫≠t c·ªôt Bu·ªïi ƒë∆∞·ª£c ch·ªçn
                df.loc[row_index[0], session_name] = 'X'
                st.session_state[CHECKLIST_SESSION_KEY] = df # C·∫≠p nh·∫≠t Session State
                
                # --- M√¥ ph·ªèng ghi l√™n Drive ---
                st.success(f"‚úÖ **ƒê√£ c·∫≠p nh·∫≠t ƒëi·ªÉm danh** cho STT **{stt_match_str}** v√†o c·ªôt **{session_name}**.")
                st.info("‚ö†Ô∏è **M√¥ ph·ªèng:** Trong ·ª©ng d·ª•ng th·ª±c t·∫ø, DataFrame n√†y c·∫ßn ƒë∆∞·ª£c ghi tr·ªü l·∫°i file Drive.")
                
            else:
                st.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y STT **{stt_match_str}** trong checklist ƒë·ªÉ c·∫≠p nh·∫≠t.")
        except Exception as e:
            st.error(f"L·ªói khi c·∫≠p nh·∫≠t checklist: {e}")
            
    # 2. L∆∞u ·∫£nh m·ªõi (N·∫øu kh√¥ng kh·ªõp)
    else: 
        # N·∫øu kh√¥ng kh·ªõp (stt_match is None), ti·∫øn h√†nh l∆∞u ·∫£nh m·ªõi
        
        # T√¨m s·ªë th·ª© t·ª± ti·∫øp theo cho ·∫£nh m·ªõi
        if 'new_data_counter' not in st.session_state:
            st.session_state['new_data_counter'] = 0
            
        st.session_state['new_data_counter'] += 1
        new_counter = st.session_state['new_data_counter']
        
        # T√™n file: B<S·ªë Bu·ªïi>_<Counter> (VD: B1_1.jpg)
        session_num = session_name.replace("Bu·ªïi ", "")
        new_filename = f"B{session_num}_{new_counter}.jpg" 
        
        # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
        if not os.path.exists(NEW_DATA_FOLDER):
            os.makedirs(NEW_DATA_FOLDER)
            
        new_filepath = os.path.join(NEW_DATA_FOLDER, new_filename)
        cv2.imwrite(new_filepath, captured_image_bgr)
        
        # --- M√¥ ph·ªèng ghi l√™n Drive ---
        st.success(f"‚úÖ **ƒê√£ l∆∞u ·∫£nh m·ªõi** v√†o: **{NEW_DATA_FOLDER}/{new_filename}**")
        st.info("‚ö†Ô∏è **M√¥ ph·ªèng:** Trong ·ª©ng d·ª•ng th·ª±c t·∫ø, ·∫£nh n√†y c·∫ßn ƒë∆∞·ª£c t·∫£i l√™n th∆∞ m·ª•c Drive.")


# --- 6. Giao di·ªán v√† Lu·ªìng ·ª®ng d·ª•ng ---

# 6.1 KH·ªûI T·∫†O V√Ä T·∫¢I DATASET & CHECKLIST
dataset_ready = download_and_extract_dataset(GDRIVE_DATASET_ID, ZIP_FILENAME, DATASET_FOLDER)
checklist_df = load_checklist(GDRIVE_CHECKLIST_ID, CHECKLIST_FILENAME)

# L∆∞u checklist v√†o session state ƒë·ªÉ c√≥ th·ªÉ c·∫≠p nh·∫≠t
if checklist_df is not None:
    st.session_state[CHECKLIST_SESSION_KEY] = checklist_df
    
st.markdown("---")

if not dataset_ready or checklist_df is None:
     st.warning("‚ö†Ô∏è Vui l√≤ng c·∫•u h√¨nh ƒë√∫ng File ID ZIP Dataset v√† File ID Checklist c√¥ng khai v√† th·ª≠ l·∫°i.")
     st.stop() # D·ª´ng ·ª©ng d·ª•ng n·∫øu dataset/checklist ch∆∞a s·∫µn s√†ng

st.info(f"Dataset ƒë√£ t·∫£i xong. Checklist c√≥ {len(checklist_df)} ng∆∞·ªùi.")


# 6.2 CH·ªåN BU·ªîI H·ªåC (Dropdown)
# L·∫•y t√™n c√°c c·ªôt Bu·ªïi h·ªçc
attendance_cols = [col for col in st.session_state[CHECKLIST_SESSION_KEY].columns if "Bu·ªïi" in col]

if not attendance_cols:
     st.error("Kh√¥ng t√¨m th·∫•y c·ªôt 'Bu·ªïi' trong checklist. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u tr√∫c file.")
     st.stop()

# Dropdown ch·ªçn bu·ªïi
selected_session = st.selectbox(
    "1Ô∏è‚É£ **Ch·ªçn Bu·ªïi ƒêi·ªÉm Danh**", 
    attendance_cols, 
    index=0,
    help="Ch·ªçn bu·ªïi t∆∞∆°ng ·ª©ng ƒë·ªÉ c·∫≠p nh·∫≠t c·ªôt ƒëi·ªÉm danh trong checklist."
)
st.success(f"ƒêang ƒëi·ªÉm danh cho: **{selected_session}**")

st.markdown("---")

# 6.3 CH·ª§P ·∫¢NH V√Ä X·ª¨ L√ù
captured_file = st.camera_input("2Ô∏è‚É£ Ch·ª•p ·∫£nh ƒëi·ªÉm danh:")

if captured_file is not None:
    if face_cascade is None:
        st.error("Kh√¥ng th·ªÉ ti·∫øp t·ª•c do l·ªói t·∫£i b·ªô ph√¢n lo·∫°i khu√¥n m·∫∑t.")
    else:
        image_bytes = captured_file.getvalue()
        
        # M·ªü spinner trong l√∫c x·ª≠ l√Ω
        with st.spinner('ƒêang x·ª≠ l√Ω ·∫£nh v√† nh·∫≠n di·ªán khu√¥n m·∫∑t...'):
            
            # 1. Ph√°t hi·ªán khu√¥n m·∫∑t v√† v·∫Ω khung
            processed_image_np, face_detected, num_faces, image_bgr = detect_and_draw_face(image_bytes, face_cascade)
            processed_image = Image.fromarray(processed_image_np)
            
            # 2. L∆ØU ·∫¢NH T·∫†M TH·ªúI DUY NH·∫§T (QUAN TR·ªåNG: D√πng tempfile)
            temp_file = tempfile.NamedTemporaryFile(suffix=".jpg", delete=False)
            TEMP_IMAGE_PATH = temp_file.name
            temp_file.close() 
            
            cv2.imwrite(TEMP_IMAGE_PATH, image_bgr)
            
            # 3. Th·ª±c hi·ªán so kh·ªõp DeepFace
            # stt_match: T√™n file trong dataset (v√≠ d·ª•: '1')
            stt_match, distance, person_name = verify_face_against_dataset(TEMP_IMAGE_PATH, DATASET_FOLDER)

        # X√≥a file t·∫°m sau khi ƒë√£ x·ª≠ l√Ω xong
        if os.path.exists(TEMP_IMAGE_PATH):
            os.remove(TEMP_IMAGE_PATH)
            
        st.subheader("üñºÔ∏è ·∫¢nh ƒë√£ ch·ª•p v√† Nh·∫≠n di·ªán")
        st.image(processed_image, caption="Khu√¥n m·∫∑t ƒë√£ ph√°t hi·ªán ƒë∆∞·ª£c ƒë√°nh d·∫•u.", use_column_width=True)

        st.markdown("---")
        st.subheader("üí° K·∫øt qu·∫£ ƒêi·ªÉm danh")
        
        if stt_match:
            # 4a. Khu√¥n m·∫∑t kh·ªõp -> C·∫≠p nh·∫≠t checklist
            st.balloons()
            st.success(f"‚úÖ **ƒêI·ªÇM DANH TH√ÄNH C√îNG!**")
            st.markdown(f"""
            * **Ng∆∞·ªùi tr√πng kh·ªõp:** **{stt_match}**
            * **ƒê·ªô t∆∞∆°ng ƒë·ªìng (Kho·∫£ng c√°ch Cosine):** `{distance:.4f}`
            """)
            update_checklist_and_save_new_data(stt_match, None, selected_session)
            
        elif face_detected and num_faces == 1:
            # 4b. 1 khu√¥n m·∫∑t KH√îNG kh·ªõp -> L∆∞u ·∫£nh m·ªõi
            st.warning(f"‚ö†Ô∏è **Ph√°t hi·ªán 1 khu√¥n m·∫∑t, nh∆∞ng kh√¥ng kh·ªõp v·ªõi dataset.**")
            update_checklist_and_save_new_data(None, image_bgr, selected_session)
            
        elif face_detected and num_faces > 1:
            # 4c. Nhi·ªÅu khu√¥n m·∫∑t
            st.error(f"‚ùå **Ph√°t hi·ªán nhi·ªÅu khu√¥n m·∫∑t ({num_faces}). Vui l√≤ng ch·ªâ c√≥ 1 ng∆∞·ªùi trong khung h√¨nh.**")

        else:
            # 4d. Kh√¥ng ph√°t hi·ªán
            st.warning("‚ö†Ô∏è **Kh√¥ng ph√°t hi·ªán th·∫•y khu√¥n m·∫∑t.**")
            st.markdown("Vui l√≤ng th·ª≠ l·∫°i. ƒê·∫£m b·∫£o khu√¥n m·∫∑t c·ªßa b·∫°n n·∫±m g·ªçn v√† r√µ r√†ng trong khung h√¨nh.")

st.markdown("---")
st.subheader("üìã Tr·∫°ng th√°i Checklist Hi·ªán t·∫°i (Trong Session)")
if CHECKLIST_SESSION_KEY in st.session_state:
    st.dataframe(st.session_state[CHECKLIST_SESSION_KEY])
