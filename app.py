import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io
import requests
import os
import zipfile
from deepface import DeepFace
import tempfile
import time 
import pandas as pd # Th√™m th∆∞ vi·ªán pandas ƒë·ªÉ x·ª≠ l√Ω file checklist

# --- 1. Thi·∫øt l·∫≠p trang Streamlit ---
st.set_page_config(
    page_title="H·ªá th·ªëng ƒêi·ªÉm danh Khu√¥n m·∫∑t DeepFace (GDrive)",
    page_icon="üì∏",
    layout="centered"
)

st.title("üì∏ H·ªá th·ªëng ƒêi·ªÉm danh Khu√¥n m·∫∑t DeepFace")
st.caption("Dataset v√† Checklist ƒë∆∞·ª£c t·∫£i t·ª´ Google Drive c√¥ng khai.")

# --- 2. C·∫•u h√¨nh & H·∫±ng s·ªë ---
HAAR_CASCADE_URL = "https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml"
CASCADE_FILENAME = 'haarcascade_frontalface_default.xml'

# VUI L√íNG THAY TH·∫æ C√ÅC ID D∆Ø·ªöI ƒê√ÇY B·∫∞NG ID TH·ª∞C T·∫æ C·ª¶A B·∫†N
GDRIVE_DATASET_ID = "1-yAtAUD5FY69hlLYP_O3pfqRzKgompcd" # ID cho file ZIP dataset
ZIP_FILENAME = "dataset_archive.zip" 
DATASET_FOLDER = "dataset" 

GDRIVE_CHECKLIST_ID = "1lcVBJZ55nQVoQYi6PK0iUV5Y_cCY74lv" # ID cho file CSV checklist
CHECKLIST_FILENAME = "checklist.csv" 
CHECKLIST_SESSION_KEY = "attendance_df" 

DETECTOR_BACKEND = "opencv"
NEW_DATA_FOLDER = "new_data" # Th∆∞ m·ª•c local ƒë·ªÉ l∆∞u ·∫£nh m·ªõi


# --- H√†m t·∫£i file t·ª´ Google Drive ---
def download_file_from_gdrive(file_id, output_filename):
    """ T·∫£i file c√¥ng khai t·ª´ Google Drive. """
    DOWNLOAD_URL = f"https://drive.google.com/uc?export=download&id={file_id}"
    try:
        response = requests.get(DOWNLOAD_URL, stream=True)
        response.raise_for_status() 
        
        if "confirm" in response.headers.get("Content-Disposition", ""):
            for key, value in response.cookies.items():
                if key.startswith('download_warning'):
                    params = {'id': file_id, 'confirm': value}
                    response = requests.get(DOWNLOAD_URL, params=params, stream=True)
                    response.raise_for_status()
                    break

        with open(output_filename, "wb") as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
        return True
    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫£i file {output_filename} t·ª´ Drive: {e}")
        return False


@st.cache_resource
def load_face_cascade(url, filename):
    """ T·∫£i Haar Cascade cho OpenCV. """
    try:
        r = requests.get(url)
        if r.status_code == 200:
            with open(filename, 'wb') as f:
                f.write(r.content)
            classifier = cv2.CascadeClassifier(filename)
            if not classifier.empty():
                return classifier
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i ho·∫∑c kh·ªüi t·∫°o Haar Cascade: {e}")
        return None

face_cascade = load_face_cascade(HAAR_CASCADE_URL, CASCADE_FILENAME)


@st.cache_resource(show_spinner="ƒêang t·∫£i v√† gi·∫£i n√©n Dataset t·ª´ Google Drive (Ch·ªâ ch·∫°y l·∫ßn ƒë·∫ßu)...")
def download_and_extract_dataset(file_id, zip_name, target_folder):
    """ T·∫£i v√† gi·∫£i n√©n dataset ZIP. """
    if file_id == "YOUR_GDRIVE_FILE_ID_HERE":
        return False
        
    deepface_cache = os.path.join(target_folder, 'representations_arcface.pkl')
    if os.path.exists(deepface_cache) and os.path.isdir(target_folder) and len(os.listdir(target_folder)) > 1:
         st.success(f"Dataset ƒë√£ s·∫µn s√†ng t·∫°i '{target_folder}'. B·ªè qua t·∫£i xu·ªëng.")
         return True
    
    st.info(f"ƒêang t·∫£i dataset t·ª´ Google Drive File ID: {file_id}...")
    
    if download_file_from_gdrive(file_id, zip_name):
        try:
            with zipfile.ZipFile(zip_name, 'r') as zip_ref:
                if not os.path.exists(target_folder):
                    os.makedirs(target_folder)
                zip_ref.extractall(".")
            st.success(f"Gi·∫£i n√©n th√†nh c√¥ng v√†o th∆∞ m·ª•c '{target_folder}'.")
            if os.path.exists(zip_name):
                os.remove(zip_name)
            return True
        except Exception as e:
            st.error(f"‚ùå L·ªói khi gi·∫£i n√©n: {e}")
            return False
    return False

@st.cache_data(show_spinner="ƒêang t·∫£i v√† x·ª≠ l√Ω Checklist t·ª´ Google Drive...")
def load_checklist(file_id, filename):
    """ T·∫£i checklist CSV/Excel v√† ƒë·ªçc th√†nh DataFrame. """
    if file_id == "YOUR_GDRIVE_CHECKLIST_ID_HERE":
        return None
    
    # Ki·ªÉm tra xem file ƒë√£ ƒë∆∞·ª£c t·∫£i/t·∫°o ch∆∞a, n·∫øu kh√¥ng th√¨ t·∫£i t·ª´ Drive
    if not os.path.exists(filename):
        download_file_from_gdrive(file_id, filename)
        
    if os.path.exists(filename):
        try:
            # Gi·∫£ ƒë·ªãnh file checklist l√† CSV
            df = pd.read_csv(filename)
            # Kh√¥ng x√≥a file ƒë·ªÉ gi·ªØ l·∫°i phi√™n b·∫£n g·ªëc n·∫øu c√≥ l·ªói c·∫≠p nh·∫≠t
            return df
        except Exception as e:
            st.error(f"‚ùå L·ªói khi ƒë·ªçc file checklist: {e}. ƒê·∫£m b·∫£o file c√≥ ƒë·ªãnh d·∫°ng CSV.")
            return None
    return None

# --- 3. H√†m Ph√°t hi·ªán Khu√¥n m·∫∑t (D√πng cho hi·ªÉn th·ªã khung) ---
def detect_and_draw_face(image_bytes, cascade):
    """
    D√πng Haar Cascade ƒë·ªÉ ph√°t hi·ªán v√† v·∫Ω khung khu√¥n m·∫∑t tr√™n ·∫£nh.
    """
    image_pil = Image.open(io.BytesIO(image_bytes)).convert('RGB')
    image_np = np.array(image_pil)
    image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
    
    faces = []
    if cascade is not None:
        faces = cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

    # V·∫Ω khung vu√¥ng l√™n ·∫£nh
    for (x, y, w, h) in faces:
        cv2.rectangle(image_bgr, (x, y), (x + w, y + h), (255, 0, 0), 2)
    
    processed_image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)

    return processed_image_rgb, len(faces) > 0, len(faces), image_bgr


# --- 4. H√†m DeepFace Recognition ---
def verify_face_against_dataset(target_image_path, dataset_folder):
    """
    S·ª≠ d·ª•ng DeepFace ƒë·ªÉ so s√°nh ·∫£nh ƒë·∫ßu v√†o v·ªõi dataset.
    Tr·∫£ v·ªÅ STT kh·ªõp (t√™n file) v√† kho·∫£ng c√°ch.
    """
    try:
        df_list = DeepFace.find(
            img_path=target_image_path, 
            db_path=dataset_folder, 
            model_name="ArcFace",
            distance_metric="cosine",
            enforce_detection=True, 
            detector_backend=DETECTOR_BACKEND 
        )
        
        if isinstance(df_list, list) and len(df_list) > 0 and not df_list[0].empty:
            best_match = df_list[0].iloc[0]
            identity_path = best_match['identity']
            # L·∫•y STT (t√™n file)
            stt_match = os.path.splitext(os.path.basename(identity_path))[0] 
            distance = best_match['ArcFace_cosine'] 
            return stt_match, distance
        
        return None, None
    
    except ValueError as e:
        if "Face could not be detected" in str(e):
             # DeepFace.find() s·∫Ω n√©m ValueError n·∫øu kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t
             st.error(f"‚ùå L·ªói DeepFace: Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t ƒë·ªÉ so kh·ªõp. Vui l√≤ng th·ª≠ l·∫°i ·∫£nh r√µ r√†ng h∆°n.")
        else:
            st.error(f"‚ùå L·ªói DeepFace: {e}")
        return None, None
    except Exception as e:
        st.error(f"‚ùå L·ªói trong qu√° tr√¨nh so kh·ªõp DeepFace: {e}")
        return None, None

# --- 5. Logic Ghi D·ªØ Li·ªáu (M√¥ ph·ªèng ghi l√™n Drive) ---

def update_checklist_and_save_new_data(stt_match, captured_image_bgr, session_name, image_bytes):
    """
    C·∫≠p nh·∫≠t DataFrame checklist v√† l∆∞u ·∫£nh m·ªõi (ho·∫∑c m√¥ ph·ªèng).
    """
    if CHECKLIST_SESSION_KEY not in st.session_state:
        st.error("L·ªói: Kh√¥ng t√¨m th·∫•y DataFrame checklist trong Session State.")
        return

    df = st.session_state[CHECKLIST_SESSION_KEY]
    
    # 1. C·∫≠p nh·∫≠t Checklist (ƒê√°nh 'X')
    if stt_match is not None:
        # stt_match l√† t√™n file (v√≠ d·ª•: '111'), t∆∞∆°ng ·ª©ng v·ªõi c·ªôt STT/MSSV trong checklist
        try:
            # L·∫•y t√™n c·ªôt ƒë·∫ßu ti√™n (v√≠ d·ª•: 'Stt')
            stt_col = df.columns[0] 
            
            # Gi·∫£ ƒë·ªãnh STT/MSSV trong file name tr√πng v·ªõi STT trong file checklist (c·ªôt ƒë·∫ßu ti√™n)
            # Chuy·ªÉn sang string ƒë·ªÉ t√¨m ki·∫øm ch√≠nh x√°c
            stt_match_str = str(stt_match).split('_')[0] # L·∫•y ph·∫ßn STT tr∆∞·ªõc d·∫•u g·∫°ch d∆∞·ªõi n·∫øu c√≥ (VD: 111_ten -> 111)
            
            # T√¨m ch·ªâ s·ªë d√≤ng c·ªßa STT. S·ª≠ d·ª•ng .str.contains ƒë·ªÉ linh ho·∫°t h∆°n
            row_index = df[df[stt_col].astype(str).str.contains(stt_match_str, regex=False)].index
            
            if not row_index.empty:
                # C·∫≠p nh·∫≠t c·ªôt Bu·ªïi ƒë∆∞·ª£c ch·ªçn
                df.loc[row_index[0], session_name] = 'X'
                st.session_state[CHECKLIST_SESSION_KEY] = df # C·∫≠p nh·∫≠t Session State
                
                # --- M√¥ ph·ªèng ghi l√™n Drive ---
                st.success(f"‚úÖ **ƒê√£ c·∫≠p nh·∫≠t ƒëi·ªÉm danh** cho STT **{df.loc[row_index[0], stt_col]}** v√†o c·ªôt **{session_name}**.")
                st.info("‚ö†Ô∏è **M√¥ ph·ªèng:** Trong ·ª©ng d·ª•ng th·ª±c t·∫ø, DataFrame n√†y c·∫ßn ƒë∆∞·ª£c ghi tr·ªü l·∫°i file Drive (v√≠ d·ª•: ghi l·∫°i file CSV/Excel l√™n Drive).")
                
            else:
                st.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y STT **{stt_match_str}** trong checklist ƒë·ªÉ c·∫≠p nh·∫≠t.")
        except Exception as e:
            st.error(f"L·ªói khi c·∫≠p nh·∫≠t checklist: {e}")
            
    # 2. L∆∞u ·∫£nh m·ªõi (N·∫øu kh√¥ng kh·ªõp)
    else: 
        # N·∫øu kh√¥ng kh·ªõp (stt_match is None), ti·∫øn h√†nh l∆∞u ·∫£nh m·ªõi
        
        # T√¨m s·ªë th·ª© t·ª± ti·∫øp theo cho ·∫£nh m·ªõi
        if 'new_data_counter' not in st.session_state:
            st.session_state['new_data_counter'] = 0
            
        st.session_state['new_data_counter'] += 1
        new_counter = st.session_state['new_data_counter']
        
        # T√™n file: B<S·ªë Bu·ªïi>_<Counter> (VD: B1_1.jpg)
        session_num = session_name.replace("Bu·ªïi ", "")
        new_filename = f"B{session_num}_{new_counter}.jpg" 
        
        # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
        if not os.path.exists(NEW_DATA_FOLDER):
            os.makedirs(NEW_DATA_FOLDER)
            
        new_filepath = os.path.join(NEW_DATA_FOLDER, new_filename)
        
        # L∆∞u ·∫£nh g·ªëc d∆∞·ªõi d·∫°ng JPG
        image_to_save = Image.open(io.BytesIO(image_bytes)).convert('RGB')
        image_to_save.save(new_filepath, format='JPEG')
        
        # --- M√¥ ph·ªèng ghi l√™n Drive ---
        st.success(f"‚úÖ **ƒê√£ l∆∞u ·∫£nh m·ªõi** v√†o: **{NEW_DATA_FOLDER}/{new_filename}**")
        st.info("‚ö†Ô∏è **M√¥ ph·ªèng:** Trong ·ª©ng d·ª•ng th·ª±c t·∫ø, ·∫£nh n√†y c·∫ßn ƒë∆∞·ª£c t·∫£i l√™n th∆∞ m·ª•c Drive.")


# --- 6. Giao di·ªán v√† Lu·ªìng ·ª®ng d·ª•ng ---

# 6.1 KH·ªûI T·∫†O V√Ä T·∫¢I DATASET & CHECKLIST
dataset_ready = download_and_extract_dataset(GDRIVE_DATASET_ID, ZIP_FILENAME, DATASET_FOLDER)
checklist_df = load_checklist(GDRIVE_CHECKLIST_ID, CHECKLIST_FILENAME)

# L∆∞u checklist v√†o session state ƒë·ªÉ c√≥ th·ªÉ c·∫≠p nh·∫≠t
if checklist_df is not None:
    st.session_state[CHECKLIST_SESSION_KEY] = checklist_df
    
st.markdown("---")

if not dataset_ready:
     st.warning("‚ö†Ô∏è Vui l√≤ng c·∫•u h√¨nh ƒë√∫ng File ID ZIP Dataset v√† th·ª≠ l·∫°i.")
     st.stop()
     
if checklist_df is None:
     st.warning("‚ö†Ô∏è L·ªói t·∫£i ho·∫∑c ƒë·ªçc file Checklist. Vui l√≤ng ki·ªÉm tra File ID v√† ƒë·ªãnh d·∫°ng CSV.")
     st.stop()


st.info(f"Dataset ƒë√£ t·∫£i xong. Checklist c√≥ {len(checklist_df)} ng∆∞·ªùi.")


# 6.2 CH·ªåN BU·ªîI H·ªåC (Dropdown)
attendance_cols = [col for col in st.session_state[CHECKLIST_SESSION_KEY].columns if "Bu·ªïi" in col]

if not attendance_cols:
     st.error("Kh√¥ng t√¨m th·∫•y c·ªôt 'Bu·ªïi' trong checklist. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u tr√∫c file.")
     st.stop()

selected_session = st.selectbox(
    "1Ô∏è‚É£ **Ch·ªçn Bu·ªïi ƒêi·ªÉm Danh**", 
    attendance_cols, 
    index=0,
    help="Ch·ªçn bu·ªïi t∆∞∆°ng ·ª©ng ƒë·ªÉ c·∫≠p nh·∫≠t c·ªôt ƒëi·ªÉm danh trong checklist."
)
st.success(f"ƒêang ƒëi·ªÉm danh cho: **{selected_session}**")

st.markdown("---")

# 6.3 CH·ª§P ·∫¢NH V√Ä X·ª¨ L√ù
captured_file = st.camera_input("2Ô∏è‚É£ Ch·ª•p ·∫£nh ƒëi·ªÉm danh:")

if captured_file is not None:
    if face_cascade is None:
        st.error("Kh√¥ng th·ªÉ ti·∫øp t·ª•c do l·ªói t·∫£i b·ªô ph√¢n lo·∫°i khu√¥n m·∫∑t.")
    else:
        image_bytes = captured_file.getvalue()
        
        # M·ªü spinner trong l√∫c x·ª≠ l√Ω
        with st.spinner('ƒêang x·ª≠ l√Ω ·∫£nh v√† nh·∫≠n di·ªán khu√¥n m·∫∑t...'):
            
            # 1. Ph√°t hi·ªán khu√¥n m·∫∑t v√† v·∫Ω khung
            processed_image_np, face_detected, num_faces, image_bgr = detect_and_draw_face(image_bytes, face_cascade)
            processed_image = Image.fromarray(processed_image_np)
            
            # 2. L∆ØU ·∫¢NH T·∫†M TH·ªúI DUY NH·∫§T (QUAN TR·ªåNG: D√πng tempfile)
            temp_file = tempfile.NamedTemporaryFile(suffix=".jpg", delete=False)
            TEMP_IMAGE_PATH = temp_file.name
            temp_file.close() 
            
            # Ghi ·∫£nh BGR v√†o file t·∫°m ƒë·ªÉ DeepFace x·ª≠ l√Ω
            cv2.imwrite(TEMP_IMAGE_PATH, image_bgr)
            
            # 3. Th·ª±c hi·ªán so kh·ªõp DeepFace
            stt_match, distance = verify_face_against_dataset(TEMP_IMAGE_PATH, DATASET_FOLDER)

        # X√≥a file t·∫°m sau khi ƒë√£ x·ª≠ l√Ω xong
        if os.path.exists(TEMP_IMAGE_PATH):
            os.remove(TEMP_IMAGE_PATH)
            
        st.subheader("üñºÔ∏è ·∫¢nh ƒë√£ ch·ª•p v√† Nh·∫≠n di·ªán")
        st.image(processed_image, caption="Khu√¥n m·∫∑t ƒë√£ ph√°t hi·ªán ƒë∆∞·ª£c ƒë√°nh d·∫•u.", use_column_width=True)

        st.markdown("---")
        st.subheader("üí° K·∫øt qu·∫£ ƒêi·ªÉm danh")
        
        if stt_match:
            # 4a. Khu√¥n m·∫∑t kh·ªõp -> C·∫≠p nh·∫≠t checklist
            st.balloons()
            st.success(f"‚úÖ **ƒêI·ªÇM DANH TH√ÄNH C√îNG!**")
            st.markdown(f"""
            * **STT tr√πng kh·ªõp:** **{stt_match}**
            * **ƒê·ªô t∆∞∆°ng ƒë·ªìng (Kho·∫£ng c√°ch Cosine):** `{distance:.4f}`
            """)
            # Truy·ªÅn None cho captured_image_bgr v√¨ ƒë√¢y l√† tr∆∞·ªùng h·ª£p kh·ªõp
            update_checklist_and_save_new_data(stt_match, None, selected_session, None)
            
        elif face_detected and num_faces == 1:
            # 4b. 1 khu√¥n m·∫∑t KH√îNG kh·ªõp -> L∆∞u ·∫£nh m·ªõi
            st.warning(f"‚ö†Ô∏è **Ph√°t hi·ªán 1 khu√¥n m·∫∑t, nh∆∞ng kh√¥ng kh·ªõp v·ªõi dataset.**")
            # Truy·ªÅn image_bytes ƒë·ªÉ l∆∞u ·∫£nh g·ªëc
            update_checklist_and_save_new_data(None, image_bgr, selected_session, image_bytes) 
            
        elif face_detected and num_faces > 1:
            # 4c. Nhi·ªÅu khu√¥n m·∫∑t
            st.error(f"‚ùå **Ph√°t hi·ªán nhi·ªÅu khu√¥n m·∫∑t ({num_faces}). Vui l√≤ng ch·ªâ c√≥ 1 ng∆∞·ªùi trong khung h√¨nh.**")

        else:
            # 4d. Kh√¥ng ph√°t hi·ªán
            st.warning("‚ö†Ô∏è **Kh√¥ng ph√°t hi·ªán th·∫•y khu√¥n m·∫∑t.**")
            st.markdown("Vui l√≤ng th·ª≠ l·∫°i. ƒê·∫£m b·∫£o khu√¥n m·∫∑t c·ªßa b·∫°n n·∫±m g·ªçn v√† r√µ r√†ng trong khung h√¨nh.")

st.markdown("---")
st.subheader("üìã Tr·∫°ng th√°i Checklist Hi·ªán t·∫°i (Trong Session)")
if CHECKLIST_SESSION_KEY in st.session_state:
    st.dataframe(st.session_state[CHECKLIST_SESSION_KEY])
