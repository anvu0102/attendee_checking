import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io
import requests
import os
import zipfile
from deepface import DeepFace
import tempfile
import time 
import pandas as pd
# --- C·∫¶N TH√äM C√ÅC TH∆Ø VI·ªÜN SAU ---
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
# ---------------------------------

# --- 1. Thi·∫øt l·∫≠p trang Streamlit ---
st.set_page_config(
    page_title="H·ªá th·ªëng ƒêi·ªÉm danh Khu√¥n m·∫∑t DeepFace (GDrive)",
    page_icon="üì∏",
    layout="centered"
)

st.title("üì∏ H·ªá th·ªëng ƒêi·ªÉm danh Khu√¥n m·∫∑t DeepFace")
st.caption("S·ª≠ d·ª•ng ID Drive v√† OAuth Credentials t·ª´ st.secrets.")

# --- 2. C·∫•u h√¨nh & H·∫±ng s·ªë (T·∫¢I T·ª™ ST.SECRETS) ---
HAAR_CASCADE_URL = "https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml"
CASCADE_FILENAME = 'haarcascade_frontalface_default.xml'

# PH·∫†M VI (SCOPES) CHO GOOGLE DRIVE API
SCOPES = ['https://www.googleapis.com/auth/drive.readonly', 'https://www.googleapis.com/auth/drive.file']

# T·∫¢I C√ÅC TH√îNG TIN T·ª™ ST.SECRETS
try:
    GDRIVE_CLIENT_ID = st.secrets["GDRIVE_CLIENT_ID"]
    GDRIVE_CLIENT_SECRET = st.secrets["GDRIVE_CLIENT_SECRET"]
    GDRIVE_DATASET_FOLDER_ID = st.secrets["GDRIVE_DATASET_ID"] 
    GDRIVE_CHECKLIST_ID = st.secrets["GDRIVE_CHECKLIST_ID"]
    GDRIVE_NEW_DATA_FOLDER_ID = st.secrets["GDRIVE_NEW_DATA_ID"]
    # T√™n kh√≥a ƒë·ªÉ l∆∞u tr·ªØ credential trong session state
    CREDENTIALS_SESSION_KEY = "gdrive_credentials"
except KeyError as e:
    st.error(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y kh√≥a {e} trong st.secrets.")
    st.info("Vui l√≤ng ƒë·∫£m b·∫£o b·∫°n ƒë√£ ƒë·ªãnh nghƒ©a t·∫•t c·∫£ c√°c kh√≥a (CLIENT_ID, CLIENT_SECRET, DATASET_ID, CHECKLIST_ID, NEW_DATA_ID) trong file .streamlit/secrets.toml ho·∫∑c trong giao di·ªán Secrets c·ªßa Streamlit Cloud.")
    st.stop()

# C√°c h·∫±ng s·ªë kh√°c
DATASET_FOLDER = "dataset" 
CHECKLIST_FILENAME = "checklist.xlsx" 
CHECKLIST_SESSION_KEY = "attendance_df" 
DETECTOR_BACKEND = "opencv"


# --- 1. H√ÄM X√ÅC TH·ª∞C OAUTH (REAL) ---
@st.cache_resource(show_spinner="ƒêang th·ª±c hi·ªán quy tr√¨nh OAuth ƒë·ªÉ l·∫•y Access Token...")
def get_valid_access_token_real(client_id, client_secret):
    """ 
    TH·ª∞C T·∫æ: Th·ª±c hi·ªán lu·ªìng OAuth 2.0 ƒë·ªÉ l·∫•y v√† l√†m m·ªõi token (y√™u c·∫ßu file client_secrets.json).
    CH√ö √ù: ƒê√¢y l√† lu·ªìng OAuth Desktop/Installed App. ƒê·ªÉ d√πng tr√™n Streamlit Cloud,
    c·∫ßn thay th·∫ø b·∫±ng m·ªôt lu·ªìng web app ho·∫∑c s·ª≠ d·ª•ng c√°c kh√≥a ƒë√£ ƒë∆∞·ª£c x√°c th·ª±c tr∆∞·ªõc.
    """
    if "token" not in st.session_state:
        st.session_state.token = None

    if st.session_state.token and st.session_state.token.expired and st.session_state.token.refresh_token:
        # N·∫øu Token h·∫øt h·∫°n v√† c√≥ Refresh Token, l√†m m·ªõi
        st.info("ƒêang l√†m m·ªõi Access Token...")
        st.session_state.token.refresh(Request())
        st.success("‚úÖ ƒê√£ l√†m m·ªõi Access Token.")
        return st.session_state.token
    elif st.session_state.token and not st.session_state.token.expired:
        # N·∫øu Token c√≤n h·∫°n
        st.success("‚úÖ Access Token c√≤n hi·ªáu l·ª±c.")
        return st.session_state.token
    
    # ‚ö†Ô∏è ƒê√¢y l√† ph·∫ßn quan tr·ªçng: Lu·ªìng OAuth T∆∞∆°ng t√°c (ch·ªâ ch·∫°y t·ªët tr√™n m√¥i tr∆∞·ªùng local)
    try:
        # T·∫°o file credentials.json ·∫£o t·ª´ st.secrets ƒë·ªÉ th·ª±c hi·ªán OAuth flow
        CRED_JSON = {
            "installed": {
                "client_id": client_id,
                "client_secret": client_secret,
                "auth_uri": "https://accounts.google.com/o/oauth2/auth",
                "token_uri": "https://oauth2.googleapis.com/token",
                "redirect_uris": ["urn:ietf:wg:oauth:2.0:oob", "http://localhost"]
            }
        }
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as temp_creds_file:
            import json
            json.dump(CRED_JSON, temp_creds_file)
            CREDENTIALS_FILE = temp_creds_file.name
        
        flow = InstalledAppFlow.from_client_secrets_file(
            CREDENTIALS_FILE, SCOPES
        )
        
        # Ch·∫°y lu·ªìng OAuth. Tr√™n local s·∫Ω m·ªü tr√¨nh duy·ªát, tr√™n Cloud s·∫Ω c·∫ßn x·ª≠ l√Ω kh√°c
        st.warning("Vui l√≤ng ho√†n th√†nh qu√° tr√¨nh x√°c th·ª±c Google OAuth trong c·ª≠a s·ªï m·ªõi/terminal.")
        creds = flow.run_local_server(port=0) 
        st.session_state.token = creds
        
        os.remove(CREDENTIALS_FILE)
        st.success("‚úÖ X√°c th·ª±c Google th√†nh c√¥ng.")
        return creds
        
    except Exception as e:
        st.error(f"‚ùå L·ªói x√°c th·ª±c OAuth: {e}")
        st.error("Vui l√≤ng ki·ªÉm tra Client ID/Secret v√† ƒë·∫£m b·∫£o ·ª©ng d·ª•ng c·ªßa b·∫°n ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω.")
        return None

# --- 2. H√ÄM T·∫¢I FILE ƒê∆†N L·∫∫ T·ª™ G-DRIVE (C·∫¨P NH·∫¨T) ---
# T·∫£i checklist XLSX
def download_file_from_gdrive(file_id, output_filename, credentials):
    """ T·∫£i file t·ª´ Google Drive d√πng Google Drive API. """
    
    try:
        service = build('drive', 'v3', credentials=credentials)
        request = service.files().get_media(fileId=file_id)
        
        with open(output_filename, 'wb') as fh:
            downloader = MediaIoBaseDownload(fh, request)
            done = False
            with st.spinner(f"ƒêang t·∫£i file {output_filename}..."):
                while done is False:
                    status, done = downloader.next_chunk()
        st.info(f"ƒê√£ t·∫£i th√†nh c√¥ng file: {output_filename}")
        return True
    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫£i file {output_filename} t·ª´ Drive: {e}")
        st.warning("G·ª£i √Ω: Ki·ªÉm tra ID file v√† quy·ªÅn truy c·∫≠p c·ªßa t√†i kho·∫£n ƒë√£ x√°c th·ª±c.")
        return False


# --- 3. H√ÄM T·∫¢I DATASET FOLDER (REAL) ---
@st.cache_resource(show_spinner="ƒêang t·∫£i Dataset Folder t·ª´ Google Drive...")
def download_dataset_folder_real(folder_id, target_folder, credentials):
    """ TH·ª∞C T·∫æ: T·∫£i to√†n b·ªô n·ªôi dung folder Drive v√†o th∆∞ m·ª•c local. """
    if not os.path.exists(target_folder):
        os.makedirs(target_folder)
        
    try:
        service = build('drive', 'v3', credentials=credentials)
        # Truy v·∫•n t·∫•t c·∫£ file trong folder
        query = f"'{folder_id}' in parents and trashed = false"
        results = service.files().list(
            q=query, 
            pageSize=1000,
            fields="nextPageToken, files(id, name)"
        ).execute()
        items = results.get('files', [])

        if not items:
            st.warning(f"Folder ID: {folder_id} tr·ªëng r·ªóng. Kh√¥ng c√≥ dataset.")
            return False

        st.info(f"T√¨m th·∫•y {len(items)} file trong dataset. ƒêang t·∫£i xu·ªëng...")
        
        for item in items:
            file_id = item['id']
            file_name = item['name']
            output_path = os.path.join(target_folder, file_name)
            
            # T·∫£i t·ª´ng file
            request = service.files().get_media(fileId=file_id)
            with open(output_path, 'wb') as fh:
                downloader = MediaIoBaseDownload(fh, request)
                done = False
                while done is False:
                    status, done = downloader.next_chunk()

        st.success(f"‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng {len(items)} file ·∫£nh dataset v√†o th∆∞ m·ª•c '{target_folder}'.")
        return True
        
    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫£i Dataset Folder t·ª´ Drive: {e}")
        return False

# --- 4. H√ÄM UPLOAD FILE M·ªöI (REAL) ---
def upload_to_gdrive_real(file_path, drive_folder_id, drive_filename, credentials):
    """
    T·∫£i file l√™n Google Drive b·∫±ng Google Drive API, c·∫ßn Credential th·∫≠t.
    """
    if credentials is None:
        st.error("‚ùå L·ªói Auth: Kh√¥ng th·ªÉ upload v√¨ kh√¥ng c√≥ Credential h·ª£p l·ªá.")
        return False
    
    try:
        service = build('drive', 'v3', credentials=credentials)
        
        # Metadata c·ªßa file
        file_metadata = {
            'name': drive_filename,
            'parents': [drive_folder_id] 
        }
        
        # Media to upload
        from googleapiclient.http import MediaFileUpload
        media = MediaFileUpload(file_path, mimetype='image/jpeg', resumable=True)
        
        with st.spinner(f"ƒêang t·∫£i file '{drive_filename}' l√™n Drive..."):
            file = service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id'
            ).execute()

        st.success(f"‚úÖ **Upload Th√†nh C√¥ng:** File '{drive_filename}' ƒë√£ ƒë∆∞·ª£c l∆∞u v·ªõi ID: `{file.get('id')}`.")
        st.info(f"ƒê√£ l∆∞u v√†o Drive Folder ID: **{drive_folder_id}**.")
        
        return True
        
    except Exception as e:
        st.error(f"‚ùå L·ªói khi Upload file m·ªõi l√™n Drive: {e}")
        return False

# --- H√ÄM T·∫¢I CHECKLIST (C·∫¨P NH·∫¨T) ---
@st.cache_data(show_spinner="ƒêang t·∫£i v√† x·ª≠ l√Ω Checklist (XLSX) t·ª´ Google Drive...")
def load_checklist(file_id, filename, credentials):
    """ T·∫£i checklist XLSX v√† ƒë·ªçc th√†nh DataFrame. """
    
    if not os.path.exists(filename):
        # Truy·ªÅn credentials v√†o h√†m download
        download_file_from_gdrive(file_id, filename, credentials)
        
    if os.path.exists(filename):
        try:
            # ƒê·ªåC FILE XLSX
            df = pd.read_excel(filename) 
            return df
        except Exception as e:
            st.error(f"‚ùå L·ªói khi ƒë·ªçc file checklist: {e}. ƒê·∫£m b·∫£o file c√≥ ƒë·ªãnh d·∫°ng XLSX.")
            return None
    return None

# --- T·∫¢I CASCADE V√Ä C√ÅC H√ÄM KH√ÅC (GI·ªÆ NGUY√äN) ---
@st.cache_resource
def load_face_cascade(url, filename):
    """ T·∫£i Haar Cascade cho OpenCV. """
    try:
        r = requests.get(url)
        if r.status_code == 200:
            with open(filename, 'wb') as f:
                f.write(r.content)
            classifier = cv2.CascadeClassifier(filename)
            if not classifier.empty():
                return classifier
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i ho·∫∑c kh·ªüi t·∫°o Haar Cascade: {e}")
        return None

face_cascade = load_face_cascade(HAAR_CASCADE_URL, CASCADE_FILENAME)

# --- 3. H√†m Ph√°t hi·ªán Khu√¥n m·∫∑t (Gi·ªØ nguy√™n) ---
def detect_and_draw_face(image_bytes, cascade):
    # ... (code gi·ªØ nguy√™n) ...
    image_pil = Image.open(io.BytesIO(image_bytes)).convert('RGB')
    image_np = np.array(image_pil)
    image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
    
    faces = []
    if cascade is not None:
        faces = cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

    for (x, y, w, h) in faces:
        cv2.rectangle(image_bgr, (x, y), (x + w, y + h), (255, 0, 0), 2)
    
    processed_image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)

    return processed_image_rgb, len(faces) > 0, len(faces), image_bgr

# --- 4. H√†m DeepFace Recognition (Gi·ªØ nguy√™n) ---
def verify_face_against_dataset(target_image_path, dataset_folder):
    # ... (code gi·ªØ nguy√™n) ...
    try:
        df_list = DeepFace.find(
            img_path=target_image_path, 
            db_path=dataset_folder, 
            model_name="ArcFace",
            distance_metric="cosine",
            enforce_detection=True, 
            detector_backend=DETECTOR_BACKEND 
        )
        if isinstance(df_list, list) and len(df_list) > 0 and not df_list[0].empty:
            best_match = df_list[0].iloc[0]
            identity_path = best_match['identity']
            stt_match = os.path.splitext(os.path.basename(identity_path))[0] 
            distance = best_match['ArcFace_cosine'] 
            return stt_match, distance
        return None, None
    except Exception as e:
        if "Face could not be detected" in str(e):
             st.error(f"‚ùå L·ªói DeepFace: Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t ƒë·ªÉ so kh·ªõp.")
        else:
            st.error(f"‚ùå L·ªói DeepFace: {e}")
        return None, None

# --- 6. Logic Ghi D·ªØ Li·ªáu v√† L∆∞u ·∫¢nh M·ªõi (C·∫¨P NH·∫¨T) ---

def update_checklist_and_save_new_data(stt_match, session_name, image_bytes, credentials):
    """
    C·∫≠p nh·∫≠t DataFrame checklist v√† l∆∞u ·∫£nh m·ªõi l√™n Drive.
    """
    if CHECKLIST_SESSION_KEY not in st.session_state:
        st.error("L·ªói: Kh√¥ng t√¨m th·∫•y DataFrame checklist trong Session State.")
        return

    df = st.session_state[CHECKLIST_SESSION_KEY]
    
    # 1. C·∫≠p nh·∫≠t Checklist (ƒê√°nh 'X')
    if stt_match is not None:
        try:
            stt_col = df.columns[0] 
            stt_match_str = str(stt_match).split('_')[0] 
            
            row_index = df[df[stt_col].astype(str).str.contains(stt_match_str, regex=False)].index
            
            if not row_index.empty:
                df.loc[row_index[0], session_name] = 'X'
                st.session_state[CHECKLIST_SESSION_KEY] = df 
                
                st.success(f"‚úÖ **ƒê√£ c·∫≠p nh·∫≠t ƒëi·ªÉm danh** cho STT **{df.loc[row_index[0], stt_col]}** v√†o c·ªôt **{session_name}**.")
                st.info(f"‚ö†Ô∏è **C·∫ßn th√™m ch·ª©c nƒÉng ghi ng∆∞·ª£c (Write-Back) DataFrame n√†y l√™n file XLSX Drive ID: {GDRIVE_CHECKLIST_ID}**.")
                
            else:
                st.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y STT **{stt_match_str}** trong checklist ƒë·ªÉ c·∫≠p nh·∫≠t.")
        except Exception as e:
            st.error(f"L·ªói khi c·∫≠p nh·∫≠t checklist: {e}")
            
    # 2. L∆∞u ·∫£nh m·ªõi l√™n Drive (N·∫øu kh√¥ng kh·ªõp)
    else: 
        if 'new_data_counter' not in st.session_state:
            st.session_state['new_data_counter'] = 0
            
        st.session_state['new_data_counter'] += 1
        new_counter = st.session_state['new_data_counter']
        
        session_num = session_name.replace("Bu·ªïi ", "")
        drive_filename = f"B{session_num}_{new_counter}.jpg" 
        
        # --- T·∫†O FILE T·∫†M ƒê·ªÇ UPLOAD ---
        temp_file_for_upload = tempfile.NamedTemporaryFile(suffix=".jpg", delete=False)
        TEMP_UPLOAD_PATH = temp_file_for_upload.name
        temp_file_for_upload.close()
        
        try:
            image_to_save = Image.open(io.BytesIO(image_bytes)).convert('RGB')
            image_to_save.save(TEMP_UPLOAD_PATH, format='JPEG')
            
            # 2. G·ªçi h√†m Upload Drive (REAL)
            upload_to_gdrive_real(TEMP_UPLOAD_PATH, GDRIVE_NEW_DATA_FOLDER_ID, drive_filename, credentials)

        except Exception as e:
             st.error(f"‚ùå L·ªói khi t·∫°o file t·∫°m ho·∫∑c g·ªçi h√†m upload: {e}")
        finally:
            if os.path.exists(TEMP_UPLOAD_PATH):
                os.remove(TEMP_UPLOAD_PATH)


# --- 7. Giao di·ªán v√† Lu·ªìng ·ª®ng d·ª•ng ---

# L·∫§Y CREDENTIALS ƒê·∫¶U TI√äN
# ƒê√¢y l√† n∆°i h·ªá th·ªëng s·∫Ω c·ªë g·∫Øng th·ª±c hi·ªán lu·ªìng OAuth v√† l∆∞u v√†o st.session_state.token
CREDENTIALS = get_valid_access_token_real(GDRIVE_CLIENT_ID, GDRIVE_CLIENT_SECRET)

if not CREDENTIALS:
    st.error("‚ùå Kh√¥ng th·ªÉ ti·∫øp t·ª•c do kh√¥ng l·∫•y ƒë∆∞·ª£c Credential h·ª£p l·ªá.")
    st.stop()


# 7.1 KH·ªûI T·∫†O V√Ä T·∫¢I DATASET & CHECKLIST
# T·∫£i Folder Dataset (REAL)
dataset_ready = download_dataset_folder_real(GDRIVE_DATASET_FOLDER_ID, DATASET_FOLDER, CREDENTIALS) 
# T·∫£i Checklist (XLSX)
checklist_df = load_checklist(GDRIVE_CHECKLIST_ID, CHECKLIST_FILENAME, CREDENTIALS)

if checklist_df is not None:
    st.session_state[CHECKLIST_SESSION_KEY] = checklist_df
    
st.markdown("---")

if not dataset_ready:
     st.warning("‚ö†Ô∏è L·ªói t·∫£i Dataset Folder. Vui l√≤ng ki·ªÉm tra ID Drive Folder v√† quy·ªÅn truy c·∫≠p.")
     st.stop()
     
if checklist_df is None:
     st.warning("‚ö†Ô∏è L·ªói t·∫£i ho·∫∑c ƒë·ªçc file Checklist. Vui l√≤ng ki·ªÉm tra File ID v√† quy·ªÅn truy c·∫≠p b·∫±ng token.")
     st.stop()


st.info(f"Dataset ƒë√£ s·∫µn s√†ng. Checklist c√≥ {len(checklist_df)} ng∆∞·ªùi.")


# 7.2 CH·ªåN BU·ªîI H·ªåC (Dropdown)
attendance_cols = [col for col in st.session_state[CHECKLIST_SESSION_KEY].columns if "Bu·ªïi" in col]

if not attendance_cols:
     st.error("Kh√¥ng t√¨m th·∫•y c·ªôt 'Bu·ªïi' trong checklist. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u tr√∫c file XLSX.")
     st.stop()

selected_session = st.selectbox(
    "1Ô∏è‚É£ **Ch·ªçn Bu·ªïi ƒêi·ªÉm Danh**", 
    attendance_cols, 
    index=0,
    help="Ch·ªçn bu·ªïi t∆∞∆°ng ·ª©ng ƒë·ªÉ c·∫≠p nh·∫≠t c·ªôt ƒëi·ªÉm danh trong checklist."
)
st.success(f"ƒêang ƒëi·ªÉm danh cho: **{selected_session}**")

st.markdown("---")

# 7.3 CH·ª§P ·∫¢NH V√Ä X·ª¨ L√ù
captured_file = st.camera_input("2Ô∏è‚É£ Ch·ª•p ·∫£nh ƒëi·ªÉm danh:")

if captured_file is not None:
    
    image_bytes = captured_file.getvalue()
    
    with st.spinner('ƒêang x·ª≠ l√Ω ·∫£nh v√† nh·∫≠n di·ªán khu√¥n m·∫∑t...'):
        
        processed_image_np, face_detected, num_faces, image_bgr = detect_and_draw_face(image_bytes, face_cascade)
        processed_image = Image.fromarray(processed_image_np)
        
        # L∆ØU ·∫¢NH T·∫†M TH·ªúI cho DeepFace so kh·ªõp
        temp_file = tempfile.NamedTemporaryFile(suffix=".jpg", delete=False)
        TEMP_IMAGE_PATH = temp_file.name
        temp_file.close() 
        
        cv2.imwrite(TEMP_IMAGE_PATH, image_bgr)
        
        # Th·ª±c hi·ªán so kh·ªõp DeepFace
        stt_match, distance = verify_face_against_dataset(TEMP_IMAGE_PATH, DATASET_FOLDER)

    # X√≥a file t·∫°m c·ªßa DeepFace
    if os.path.exists(TEMP_IMAGE_PATH):
        os.remove(TEMP_IMAGE_PATH)
        
    st.subheader("üñºÔ∏è ·∫¢nh ƒë√£ ch·ª•p v√† Nh·∫≠n di·ªán")
    st.image(processed_image, caption="Khu√¥n m·∫∑t ƒë√£ ph√°t hi·ªán ƒë∆∞·ª£c ƒë√°nh d·∫•u.", use_column_width=True)

    st.markdown("---")
    st.subheader("üí° K·∫øt qu·∫£ ƒêi·ªÉm danh")
    
    if stt_match:
        st.balloons()
        st.success(f"‚úÖ **ƒêI·ªÇM DANH TH√ÄNH C√îNG!**")
        st.markdown(f"""
        * **STT tr√πng kh·ªõp:** **{stt_match}**
        * **ƒê·ªô t∆∞∆°ng ƒë·ªìng (Kho·∫£ng c√°ch Cosine):** `{distance:.4f}`
        """)
        # C·∫≠p nh·∫≠t checklist (truy·ªÅn credentials)
        update_checklist_and_save_new_data(stt_match, selected_session, None, CREDENTIALS)
        
    elif face_detected and num_faces == 1:
        st.warning(f"‚ö†Ô∏è **Ph√°t hi·ªán 1 khu√¥n m·∫∑t, nh∆∞ng kh√¥ng kh·ªõp v·ªõi dataset.**")
        # L∆∞u ·∫£nh m·ªõi (truy·ªÅn image_bytes v√† credentials)
        update_checklist_and_save_new_data(None, selected_session, image_bytes, CREDENTIALS) 
        
    elif face_detected and num_faces > 1:
        st.error(f"‚ùå **Ph√°t hi·ªán nhi·ªÅu khu√¥n m·∫∑t ({num_faces}). Vui l√≤ng ch·ªâ c√≥ 1 ng∆∞·ªùi trong khung h√¨nh.**")

    else:
        st.warning("‚ö†Ô∏è **Kh√¥ng ph√°t hi·ªán th·∫•y khu√¥n m·∫∑t.**")
        st.markdown("Vui l√≤ng th·ª≠ l·∫°i. ƒê·∫£m b·∫£o khu√¥n m·∫∑t c·ªßa b·∫°n n·∫±m g·ªçn v√† r√µ r√†ng trong khung h√¨nh.")

st.markdown("---")
st.subheader("üìã Tr·∫°ng th√°i Checklist Hi·ªán t·∫°i (Trong Session)")
if CHECKLIST_SESSION_KEY in st.session_state:
    st.dataframe(st.session_state[CHECKLIST_SESSION_KEY])
