# check.py
"""
Ch·ª©a c√°c h√†m x·ª≠ l√Ω DeepFace, OpenCV, logic c·∫≠p nh·∫≠t checklist v√† giao di·ªán Streamlit.
ƒê√É C·∫¨P NH·∫¨T: Lo·∫°i b·ªè st.camera_input, thay th·∫ø b·∫±ng streamlit_webrtc ƒë·ªÉ x·ª≠ l√Ω lu·ªìng video tr·ª±c ti·∫øp 
(Lo·∫°i b·ªè nhu c·∫ßu nh·∫•n n√∫t 'Take Photo').
"""
import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io 
import os
import tempfile
import pandas as pd
from deepface import DeepFace
import requests
import re 
import time
import datetime 
# --- TH∆Ø VI·ªÜN B·ªî SUNG CHO WEBRTC ---
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase
import av # C·∫ßn cho vi·ªác chuy·ªÉn ƒë·ªïi frame
# ------------------------------------

# TH∆Ø VI·ªÜN B·ªî SUNG CHO GOOGLE DRIVE API
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

# Import h·∫±ng s·ªë v√† h√†m t·ª´ config.py
from config import (
    HAAR_CASCADE_URL, CASCADE_FILENAME, 
    DATASET_FOLDER, CHECKLIST_FILENAME, CHECKLIST_SESSION_KEY, 
    DETECTOR_BACKEND, GDRIVE_CHECKLIST_ID, GDRIVE_NEW_DATA_FOLDER_ID,
    download_file_from_gdrive, upload_to_gdrive_real, list_files_in_gdrive_folder
)


# ----------------------------------------------------------------------
#                             C√ÅC H√ÄM X·ª¨ L√ù (GI·ªÆ NGUY√äN)
# ----------------------------------------------------------------------

@st.cache_resource(show_spinner="ƒêang t·∫£i Haar Cascade...")
def load_face_cascade(url, filename):
    """ T·∫£i Haar Cascade cho OpenCV. """
    try:
        if not os.path.exists(filename):
            r = requests.get(url)
            if r.status_code == 200:
                with open(filename, 'wb') as f:
                    f.write(r.content)
            else:
                st.error(f"L·ªói t·∫£i file Haar Cascade: HTTP status {r.status_code}")
                return None

        classifier = cv2.CascadeClassifier(filename)
        if not classifier.empty():
            return classifier
        else:
            st.error("L·ªói: Kh·ªüi t·∫°o Haar Cascade th·∫•t b·∫°i.")
            return None
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i ho·∫∑c kh·ªüi t·∫°o Haar Cascade: {e}")
        return None

# Load cascade ngay khi file ƒë∆∞·ª£c import
face_cascade = load_face_cascade(HAAR_CASCADE_URL, CASCADE_FILENAME)


def detect_and_draw_face(image_np_bgr, cascade):
    """ 
    D√πng Haar Cascade ƒë·ªÉ ph√°t hi·ªán v√† v·∫Ω khung khu√¥n m·∫∑t tr√™n ·∫£nh (BGR). 
    Tr·∫£ v·ªÅ: ·∫£nh c√≥ khung (RGB), c·ªù ph√°t hi·ªán, s·ªë l∆∞·ª£ng khu√¥n m·∫∑t, T·ªåA ƒê·ªò (x,y,w,h).
    """
    
    image_original_bgr = image_np_bgr.copy()
    image_bgr_with_frame = image_original_bgr.copy()
    
    gray = cv2.cvtColor(image_original_bgr, cv2.COLOR_BGR2GRAY)
    
    faces = []
    if cascade is not None:
        faces = cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

    for (x, y, w, h) in faces:
        cv2.rectangle(image_bgr_with_frame, (x, y), (x + w, y + h), (255, 0, 0), 2)
    
    processed_image_rgb = cv2.cvtColor(image_bgr_with_frame, cv2.COLOR_BGR2RGB)

    # TR·∫¢ V·ªÄ: (·∫£nh c√≥ khung (RGB), c·ªù ph√°t hi·ªán, s·ªë l∆∞·ª£ng khu√¥n m·∫∑t, T·ªåA ƒê·ªò KHU√îN M·∫∂T)
    return processed_image_rgb, len(faces) > 0, len(faces), faces


def verify_face_against_dataset(target_image_path, dataset_folder):
    """ 
    S·ª≠ d·ª•ng DeepFace ƒë·ªÉ so s√°nh ·∫£nh ƒë·∫ßu v√†o (ƒê√É C·∫ÆT) v·ªõi dataset. 
    """
    try:
        df_list = DeepFace.find(
            img_path=target_image_path, 
            db_path=dataset_folder, 
            model_name="ArcFace",
            distance_metric="cosine",
            enforce_detection=True, 
            detector_backend=DETECTOR_BACKEND 
        )
        
        if isinstance(df_list, list) and len(df_list) > 0 and not df_list[0].empty:
            best_match = df_list[0].iloc[0]
            identity_path = best_match['identity']
            stt_match = os.path.splitext(os.path.basename(identity_path))[0].split('_')[0]
            distance = best_match['ArcFace_cosine'] 
            
            if pd.notna(distance):
                return stt_match, float(distance)
            else:
                return None, None
                
        return None, None
    except Exception as e:
        if "Face could not be detected" not in str(e):
            # Ch·ªâ hi·ªÉn th·ªã l·ªói DeepFace n·∫øu kh√¥ng ph·∫£i l·ªói kh√¥ng ph√°t hi·ªán
            st.error(f"‚ùå L·ªói DeepFace: {e}")
        return None, None


def load_checklist(file_id, filename, _credentials):
    """ T·∫£i checklist XLSX v√† ƒë·ªçc th√†nh DataFrame. """
    download_file_from_gdrive(file_id, filename, _credentials)
        
    if os.path.exists(filename):
        try:
            df = pd.read_excel(filename) 
            stt_col = df.columns[0]
            df[stt_col] = df[stt_col].astype(str).str.strip() 
            return df
        except Exception as e:
            st.error(f"‚ùå L·ªói khi ƒë·ªçc file checklist: {e}. ƒê·∫£m b·∫£o file c√≥ ƒë·ªãnh d·∫°ng XLSX.")
            return None
    return None

# --- H√ÄM T√åM S·ªê TH·ª® T·ª∞ L·ªöN NH·∫§T V√Ä KI·ªÇM TRA T·ªíN T·∫†I (GI·ªÆ NGUY√äN) ---
def get_next_new_data_stt(_credentials):
    # ... (gi·ªØ nguy√™n h√†m)
    file_list = list_files_in_gdrive_folder(GDRIVE_NEW_DATA_FOLDER_ID, _credentials)
    max_stt = 0
    pattern = re.compile(r'B\d+_(\d+)\.jpe?g$', re.IGNORECASE)
    for filename in file_list:
        match = pattern.search(filename)
        if match:
            try:
                stt = int(match.group(1))
                if stt > max_stt:
                    max_stt = stt
            except ValueError:
                continue
    return max_stt + 1

def check_drive_file_existence(folder_id, filename, _credentials):
    # ... (gi·ªØ nguy√™n h√†m)
    try:
        service = build('drive', 'v3', credentials=_credentials)
        query = (
            f"name='{filename}' and "
            f"'{folder_id}' in parents and "
            f"trashed=false"
        )
        results = service.files().list(q=query, fields="files(id)").execute()
        items = results.get('files', [])
        return len(items) > 0
    except Exception as e:
        st.error(f"‚ùå L·ªói Drive API khi ki·ªÉm tra file t·ªìn t·∫°i: {e}")
        return False


@st.cache_resource(show_spinner="ƒêang ki·ªÉm tra/t·∫°o folder Drive...")
def get_or_create_drive_folder(parent_id, folder_name, _credentials):
    # ... (gi·ªØ nguy√™n h√†m)
    try:
        service = build('drive', 'v3', credentials=_credentials)
        query = (
            f"mimeType='application/vnd.google-apps.folder' and "
            f"name='{folder_name}' and "
            f"'{parent_id}' in parents and "
            f"trashed=false"
        )
        results = service.files().list(q=query, fields="files(id, name)").execute()
        items = results.get('files', [])
        if items:
            st.info(f"üìÅ Folder Drive: ƒê√£ t√¨m th·∫•y '{folder_name}'.")
            return items[0]['id']
        else:
            file_metadata = {
                'name': folder_name,
                'mimeType': 'application/vnd.google-apps.folder',
                'parents': [parent_id]
            }
            file = service.files().create(body=file_metadata, fields='id').execute()
            st.success(f"üìÅ Folder Drive: ƒê√£ t·∫°o folder m·ªõi '{folder_name}'.")
            return file.get('id')
    except Exception as e:
        st.error(f"‚ùå L·ªói Drive API khi ki·ªÉm tra/t·∫°o folder: {e}")
        return None
        
def load_dataset_image(stt_match, dataset_folder):
    # ... (gi·ªØ nguy√™n h√†m)
    pattern_simple = re.compile(rf'^{stt_match}\.jpe?g$', re.IGNORECASE)
    pattern_complex = re.compile(rf'^{stt_match}_.*\.jpe?g$', re.IGNORECASE)
    
    if os.path.isdir(dataset_folder):
        for filename in os.listdir(dataset_folder):
            if pattern_simple.match(filename):
                return os.path.join(dataset_folder, filename)
            if pattern_complex.match(filename):
                return os.path.join(dataset_folder, filename)
    return None

        
# --- H√ÄM C·∫¨P NH·∫¨T CHECKLIST V√Ä L∆ØU ·∫¢NH (CH·ªàNH S·ª¨A ƒê·ªÇ NH·∫¨N ·∫¢NH BGR) ---
def update_checklist_and_save_new_data(stt_match, session_name, image_np_bgr, _credentials):
    """
    C·∫≠p nh·∫≠t DataFrame checklist v√† l∆∞u ·∫£nh m·ªõi l√™n Drive.
    L∆∞u √Ω: image_np_bgr l√† m·∫£ng numpy c·ªßa ·∫£nh G·ªêC (BGR).
    """
    if CHECKLIST_SESSION_KEY not in st.session_state:
        st.error("L·ªói: Kh√¥ng t√¨m th·∫•y DataFrame checklist trong Session State.")
        return False 

    df = st.session_state[CHECKLIST_SESSION_KEY]
    updated = False 
    
    # Chuy·ªÉn ƒë·ªïi NumPy BGR sang PIL RGB ƒë·ªÉ l∆∞u v√†o BytesIO/File
    image_to_save_rgb = cv2.cvtColor(image_np_bgr, cv2.COLOR_BGR2RGB)
    image_pil = Image.fromarray(image_to_save_rgb)
    
    # Chu·∫©n b·ªã BytesIO cho ·∫£nh g·ªëc
    output = io.BytesIO()
    image_pil.save(output, format='JPEG')
    image_bytes = output.getvalue()


    # 1. C·∫≠p nh·∫≠t Checklist (ƒê√°nh 'X')
    if stt_match is not None:
        try:
            stt_col = df.columns[0] 
            row_index = df[df[stt_col] == stt_match].index
            
            if not row_index.empty:
                
                # --- L∆ØU ·∫¢NH G·ªêC V√ÄO FOLDER THEO BU·ªîI (ƒêi·ªÉm danh th√†nh c√¥ng) ---
                stt = df.loc[row_index[0], stt_col]
                session_folder_name = session_name.replace("Bu·ªïi ", "B")
                target_folder_id = get_or_create_drive_folder(
                    GDRIVE_NEW_DATA_FOLDER_ID, 
                    session_folder_name, 
                    _credentials
                )
                
                if target_folder_id:
                    base_filename = f"{session_folder_name}_{stt}.jpg" 
                    drive_filename = base_filename 

                    if check_drive_file_existence(target_folder_id, base_filename, _credentials):
                        timestamp = datetime.datetime.now().strftime("_%Y%m%d_%H%M%S")
                        drive_filename = f"{session_folder_name}_{stt}{timestamp}.jpg"
                        st.info(f"‚ö†Ô∏è File '{base_filename}' ƒë√£ t·ªìn t·∫°i. ƒêang l∆∞u v·ªõi t√™n m·ªõi: '{drive_filename}'.")
                    
                    temp_file_for_upload = tempfile.NamedTemporaryFile(suffix=".jpg", delete=False)
                    TEMP_UPLOAD_PATH = temp_file_for_upload.name
                    temp_file_for_upload.close()
                    
                    try:
                        # L∆∞u ·∫£nh t·ª´ bytes (image_bytes - L√öC N√ÄY L√Ä ·∫¢NH G·ªêC) v√†o file t·∫°m
                        image_pil.save(TEMP_UPLOAD_PATH, format='JPEG')
                        
                        upload_to_gdrive_real(TEMP_UPLOAD_PATH, target_folder_id, drive_filename, _credentials)
                        st.info(f"üñºÔ∏è ƒê√£ l∆∞u ·∫£nh th√†nh c√¥ng: {session_folder_name}/{drive_filename}")
                    
                    except Exception as e:
                        st.error(f"‚ùå L·ªói khi l∆∞u ·∫£nh ƒëi·ªÉm danh th√†nh c√¥ng: {e}")
                    finally:
                        if os.path.exists(TEMP_UPLOAD_PATH):
                            os.remove(TEMP_UPLOAD_PATH)
                else:
                    st.warning("‚ö†Ô∏è Kh√¥ng th·ªÉ x√°c ƒë·ªãnh/t·∫°o folder Drive ƒë·ªÉ l∆∞u ·∫£nh.")
                # --------------------------------------------------------------------------

                
                if df.loc[row_index[0], session_name] != 'X':
                    df.loc[row_index[0], session_name] = 'X'
                    st.session_state[CHECKLIST_SESSION_KEY] = df 
                    updated = True 
                    
                    st.success(f"‚úÖ **ƒê√£ c·∫≠p nh·∫≠t ƒëi·ªÉm danh** cho STT **{df.loc[row_index[0], stt_col]}** v√†o c·ªôt **{session_name}**.")

                else:
                    st.info(f"Ng∆∞·ªùi c√≥ STT **{df.loc[row_index[0], stt_col]}** ƒë√£ ƒë∆∞·ª£c ƒëi·ªÉm danh trong **{session_name}**.")
                
            else:
                st.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y STT **{stt_match}** trong checklist ƒë·ªÉ c·∫≠p nh·∫≠t.")
        except Exception as e:
            st.error(f"L·ªói khi c·∫≠p nh·∫≠t checklist: {e}")
            
    # 2. L∆∞u ·∫£nh m·ªõi l√™n Drive (N·∫øu kh√¥ng kh·ªõp) 
    else: 
        st.warning("‚ö†Ô∏è ƒêang l∆∞u ·∫£nh v√†o folder d·ªØ li·ªáu m·ªõi...")
        next_counter = get_next_new_data_stt(_credentials)
        session_num = session_name.replace("Bu·ªïi ", "")
        drive_filename = f"B{session_num}_{next_counter}.jpg" 
        
        temp_file_for_upload = tempfile.NamedTemporaryFile(suffix=".jpg", delete=False)
        TEMP_UPLOAD_PATH = temp_file_for_upload.name
        temp_file_for_upload.close()
        
        try:
            image_pil.save(TEMP_UPLOAD_PATH, format='JPEG')
            upload_to_gdrive_real(TEMP_UPLOAD_PATH, GDRIVE_NEW_DATA_FOLDER_ID, drive_filename, _credentials)
            st.info(f"üñºÔ∏è ƒê√£ l∆∞u ·∫£nh kh√¥ng kh·ªõp v√†o folder chung: {drive_filename}")

        except Exception as e:
             st.error(f"‚ùå L·ªói khi t·∫°o file t·∫°m ho·∫∑c g·ªçi h√†m upload: {e}")
        finally:
            if os.path.exists(TEMP_UPLOAD_PATH):
                os.remove(TEMP_UPLOAD_PATH)
                
    return updated 


# --- H√ÄM X·ª¨ L√ù FRAME S·ªêNG (LIVE FRAME PROCESSING LOGIC) ---
def process_live_frame(image_np_bgr, selected_session, credentials, show_debug_images):
    """
    H√†m x·ª≠ l√Ω DeepFace cho m·ªôt khung h√¨nh duy nh·∫•t,
    c·∫≠p nh·∫≠t checklist v√† hi·ªÉn th·ªã k·∫øt qu·∫£.
    image_np_bgr: M·∫£ng NumPy BGR c·ªßa khung h√¨nh hi·ªán t·∫°i.
    """
    stt_match = None
    distance = None
    TEMP_IMAGE_PATH = None
    
    # --- 1. PH√ÅT HI·ªÜN V√Ä C·∫ÆT KHU√îN M·∫∂T ---
    # ·∫¢nh BGR g·ªëc (ch·ªâ d√πng ƒë·ªÉ c·∫Øt)
    image_original_bgr = image_np_bgr.copy() 
    
    processed_image_rgb, face_detected, num_faces, faces = detect_and_draw_face(image_original_bgr, face_cascade)
    
    if face_detected and num_faces == 1:
        (x, y, w, h) = faces[0]
        padding = int(0.2 * w)
        x1 = max(0, x - padding)
        y1 = max(0, y - padding)
        x2 = min(image_original_bgr.shape[1], x + w + padding)
        y2 = min(image_original_bgr.shape[0], y + h + padding)

        cropped_face_bgr = image_original_bgr[y1:y2, x1:x2]
        
        # L∆ØU ·∫¢NH KHU√îN M·∫∂T ƒê√É C·∫ÆT V√ÄO FILE T·∫†M
        temp_file = tempfile.NamedTemporaryFile(suffix=".jpg", delete=False)
        TEMP_IMAGE_PATH = temp_file.name
        temp_file.close() 
        cv2.imwrite(TEMP_IMAGE_PATH, cropped_face_bgr)
        
        # --- 2. SO KH·ªöP DEEPFACE ---
        stt_match, distance = verify_face_against_dataset(TEMP_IMAGE_PATH, DATASET_FOLDER)
    
    # --- 3. HI·ªÇN TH·ªä V√Ä C·∫¨P NH·∫¨T K·∫æT QU·∫¢ ---
    
    # S·ª≠ d·ª•ng st.container() ƒë·ªÉ ch·ª©a k·∫øt qu·∫£ x·ª≠ l√Ω
    with st.container():
        st.subheader("üñºÔ∏è Khu√¥n m·∫∑t ƒë√£ ph√°t hi·ªán")
        st.image(processed_image_rgb, caption="Khu√¥n m·∫∑t ƒë∆∞·ª£c ƒë√°nh d·∫•u trong khung h√¨nh.", width='stretch')
        st.markdown("---")
        st.subheader("üí° K·∫øt qu·∫£ ƒêi·ªÉm danh")
        
        if stt_match and distance is not None: 
            st.balloons()
            st.success(f"‚úÖ **ƒêI·ªÇM DANH TH√ÄNH C√îNG!**")
            
            # --- Hi·ªÉn th·ªã ·∫£nh debug ---
            if show_debug_images: 
                dataset_image_path = load_dataset_image(stt_match, DATASET_FOLDER)
                col1, col2 = st.columns(2)
                with col1:
                    if TEMP_IMAGE_PATH:
                        st.image(TEMP_IMAGE_PATH, caption="Khu√¥n m·∫∑t ƒë√£ C·∫Øt (Cropped)", width='stretch')
                with col2:
                    if dataset_image_path:
                        st.image(dataset_image_path, caption=f"Dataset (STT: {stt_match})", width='stretch')
            
            st.markdown(f"""
            * **STT tr√πng kh·ªõp:** **{stt_match}**
            * **ƒê·ªô t∆∞∆°ng ƒë·ªìng (Kho·∫£ng c√°ch Cosine):** `{distance:.4f}`
            """)
            
            # C·∫≠p nh·∫≠t checklist V√Ä L∆ØU ·∫¢NH G·ªêC TH√ÄNH C√îNG
            updated = update_checklist_and_save_new_data(stt_match, selected_session, image_original_bgr, credentials)
            
            # Quay l·∫°i tr·∫°ng th√°i ch·ªù sau 5 gi√¢y ƒë·ªÉ tr√°nh x·ª≠ l√Ω l·∫∑p l·∫°i ngay l·∫≠p t·ª©c
            if updated:
                st.info("ƒê√£ c·∫≠p nh·∫≠t checklist th√†nh c√¥ng. T·ª± ƒë·ªông reset sau 5 gi√¢y.")
                time.sleep(5) 
            
        elif face_detected and num_faces == 1:
            st.warning(f"‚ö†Ô∏è **Ph√°t hi·ªán 1 khu√¥n m·∫∑t, nh∆∞ng kh√¥ng kh·ªõp v·ªõi dataset.**")
            if show_debug_images and TEMP_IMAGE_PATH: 
                st.image(TEMP_IMAGE_PATH, caption="Khu√¥n m·∫∑t ƒë√£ C·∫Øt (Cropped)", width='content')
            
            # L∆∞u ·∫£nh g·ªëc kh√¥ng kh·ªõp
            update_checklist_and_save_new_data(None, selected_session, image_original_bgr, credentials) 
            st.info("ƒê√£ l∆∞u ·∫£nh kh√¥ng kh·ªõp. T·ª± ƒë·ªông reset sau 5 gi√¢y.")
            time.sleep(5)

        elif face_detected and num_faces > 1:
            st.error(f"‚ùå **Ph√°t hi·ªán nhi·ªÅu khu√¥n m·∫∑t ({num_faces}). Vui l√≤ng ch·ªâ c√≥ 1 ng∆∞·ªùi trong khung h√¨nh.**")
            st.info("T·ª± ƒë·ªông reset sau 5 gi√¢y.")
            time.sleep(5)
            
        else:
            st.warning("‚ö†Ô∏è **Kh√¥ng ph√°t hi·ªán th·∫•y khu√¥n m·∫∑t.**")
            st.info("T·ª± ƒë·ªông reset sau 5 gi√¢y.")
            time.sleep(5)
            
    # X√≥a file t·∫°m sau khi ƒë√£ x·ª≠ l√Ω
    if TEMP_IMAGE_PATH and os.path.exists(TEMP_IMAGE_PATH):
        os.remove(TEMP_IMAGE_PATH)
        
    # Bu·ªôc Streamlit rerun ƒë·ªÉ x√≥a giao di·ªán k·∫øt qu·∫£ v√† quay l·∫°i tr·∫°ng th√°i ch·ªù
    st.rerun()

# --- H√ÄM C·∫¨P NH·∫¨T PLACEHOLDER CHECKLIST (GI·ªÆ NGUY√äN) ---
def update_checklist_display(checklist_placeholder, current_df):
    """C·∫≠p nh·∫≠t n·ªôi dung c·ªßa placeholder checklist."""
    with checklist_placeholder.container():
        st.subheader("üìã Tr·∫°ng th√°i Checklist Hi·ªán t·∫°i (Trong Session)")
        st.dataframe(current_df)
        
        output = io.BytesIO()
        current_df.to_excel(output, index=False, sheet_name='Checklist_Cap_Nhat')
        excel_data = output.getvalue()
        
        st.download_button(
            label="‚¨áÔ∏è T·∫£i file Excel Checklist ƒë√£ c·∫≠p nh·∫≠t",
            data=excel_data,
            file_name="Checklist_DiemDanh_CapNhat.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            help="T·∫£i v·ªÅ file Excel (XLSX) ch·ª©a d·ªØ li·ªáu ƒëi·ªÉm danh m·ªõi nh·∫•t trong phi√™n l√†m vi·ªác hi·ªán t·∫°i."
        )


# ----------------------------------------------------------------------
#                             GIAO DI·ªÜN CH√çNH (main_app)
# ----------------------------------------------------------------------

def main_app(credentials):
    """
    H√†m ch·ª©a to√†n b·ªô logic giao di·ªán Streamlit.
    """
    
    # === KH·ªûI T·∫†O KEY SESSION STATE ===
    # S·ª≠ d·ª•ng 'processing_triggered' ƒë·ªÉ theo d√µi tr·∫°ng th√°i k√≠ch ho·∫°t x·ª≠ l√Ω
    if 'processing_triggered' not in st.session_state:
        st.session_state['processing_triggered'] = False
    # S·ª≠ d·ª•ng 'webrtc_key' ƒë·ªÉ reset widget
    if 'webrtc_key' not in st.session_state:
        st.session_state['webrtc_key'] = 0
    # =================================

    # 1. T·∫£i Dataset & Checklist
    from config import GDRIVE_DATASET_FOLDER_ID, GDRIVE_CHECKLIST_ID
    from config import download_dataset_folder_real
    
    dataset_ready = download_dataset_folder_real(GDRIVE_DATASET_FOLDER_ID, DATASET_FOLDER, credentials) 
    
    if CHECKLIST_SESSION_KEY not in st.session_state:
        checklist_df = load_checklist(GDRIVE_CHECKLIST_ID, CHECKLIST_FILENAME, credentials)
        if checklist_df is not None:
            st.session_state[CHECKLIST_SESSION_KEY] = checklist_df
        else:
            st.warning("‚ö†Ô∏è L·ªói t·∫£i ho·∫∑c ƒë·ªçc file Checklist.")
            return

    checklist_df = st.session_state[CHECKLIST_SESSION_KEY]
        
    st.markdown("---")

    checklist_placeholder = st.empty()
    
    st.markdown("---") 

    if not dataset_ready:
         st.warning("‚ö†Ô∏è L·ªói t·∫£i Dataset Folder.")
         return
         
    if checklist_df is None:
         st.warning("‚ö†Ô∏è Checklist hi·ªán t·∫°i kh√¥ng h·ª£p l·ªá.")
         return

    st.info(f"Checklist c√≥ {len(checklist_df)} ng∆∞·ªùi.")

    # 2. Ch·ªçn Bu·ªïi H·ªçc (Dropdown)
    attendance_cols = [col for col in st.session_state[CHECKLIST_SESSION_KEY].columns if "Bu·ªïi" in col]

    if not attendance_cols:
         st.error("Kh√¥ng t√¨m th·∫•y c·ªôt 'Bu·ªïi' trong checklist.")
         return

    display_options = ["--- Vui l√≤ng ch·ªçn bu·ªïi ---"] + attendance_cols
    
    selected_session_display = st.selectbox(
        "Ch·ªçn Bu·ªïi ƒëi·ªÉm danh", 
        display_options, 
        index=0, 
        help="Ch·ªçn bu·ªïi t∆∞∆°ng ·ª©ng ƒë·ªÉ c·∫≠p nh·∫≠t c·ªôt ƒëi·ªÉm danh trong checklist."
    )
    
    selected_session = selected_session_display if selected_session_display != "--- Vui l√≤ng ch·ªçn bu·ªïi ---" else None

    # --- CHECKBOX HI·ªÇN TH·ªä ·∫¢NH DEBUG ---
    show_debug_images = st.checkbox(
        "Hi·ªÉn th·ªã ·∫¢nh ƒë√£ C·∫Øt v√† ·∫¢nh Dataset",
        value=True, 
        help="B·∫≠t ƒë·ªÉ xem ·∫£nh khu√¥n m·∫∑t ƒë∆∞·ª£c c·∫Øt ra v√† ·∫£nh t∆∞∆°ng ·ª©ng trong dataset (khi ƒëi·ªÉm danh th√†nh c√¥ng) ho·∫∑c ·∫£nh ƒë√£ c·∫Øt (khi kh√¥ng kh·ªõp)."
    )

    st.markdown("---")

    # 3. K√çCH HO·∫†T WEBRTC V√Ä X·ª¨ L√ù KHUNG H√åNH
    if selected_session:
        
        col_video, col_trigger = st.columns([2, 1])

        # --- VIDEO STREAM ---
        with col_video:
            st.subheader("üìπ Lu·ªìng Video Tr·ª±c ti·∫øp")
            # S·ª≠ d·ª•ng key ƒë·ªÉ c√≥ th·ªÉ reset widget
            webrtc_ctx = webrtc_streamer(
                key=f"webrtc_{st.session_state['webrtc_key']}", 
                video_transformer_factory=None, 
                media_stream_constraints={"video": True, "audio": False},
                async_transform=False # X·ª≠ l√Ω ƒë·ªìng b·ªô (m·∫∑c d√π ta kh√¥ng d√πng transformer)
            )

        # --- TRIGGER BUTTON ---
        with col_trigger:
            st.subheader("K√≠ch ho·∫°t")
            # Button ƒë·ªÉ k√≠ch ho·∫°t vi·ªác l·∫•y khung h√¨nh v√† x·ª≠ l√Ω
            if st.button("üî¥ K√≠ch ho·∫°t X·ª≠ l√Ω/ƒêi·ªÉm danh", help="Nh·∫•n ƒë·ªÉ l·∫•y khung h√¨nh hi·ªán t·∫°i v√† th·ª±c hi·ªán nh·∫≠n di·ªán.", disabled=not (webrtc_ctx and webrtc_ctx.state.playing)):
                st.session_state['processing_triggered'] = True
                # Bu·ªôc Streamlit rerun ƒë·ªÉ th·ª±c thi logic x·ª≠ l√Ω b√™n d∆∞·ªõi
                st.rerun()

        # --- LOGIC X·ª¨ L√ù SAU KHI K√çCH HO·∫†T ---
        if st.session_state['processing_triggered'] and webrtc_ctx and webrtc_ctx.state.playing:
            
            # Reset c·ªù k√≠ch ho·∫°t
            st.session_state['processing_triggered'] = False
            
            latest_frame = webrtc_ctx.get_last_frame()
            
            if latest_frame:
                with st.spinner('ƒêang x·ª≠ l√Ω ·∫£nh v√† nh·∫≠n di·ªán khu√¥n m·∫∑t...'):
                    # Chuy·ªÉn ƒë·ªïi khung h√¨nh AV (RGB) sang m·∫£ng NumPy BGR cho OpenCV
                    image_np_rgb = latest_frame.to_ndarray(format="rgb24")
                    image_np_bgr = cv2.cvtColor(image_np_rgb, cv2.COLOR_RGB2BGR)

                    # --- G·ªåI H√ÄM X·ª¨ L√ù FRAME S·ªêNG ---
                    process_live_frame(image_np_bgr, selected_session, credentials, show_debug_images)
                    
                    # N·∫øu process_live_frame g·ªçi rerun, code d∆∞·ªõi ƒë√¢y s·∫Ω kh√¥ng ch·∫°y
            else:
                st.warning("‚ö†Ô∏è Kh√¥ng th·ªÉ l·∫•y khung h√¨nh. ƒê·∫£m b·∫£o camera ƒë√£ ho·∫°t ƒë·ªông.")
                time.sleep(2)
                st.rerun()
                
    # 4. HI·ªÇN TH·ªä TR·∫†NG TH√ÅI CHECKLIST BAN ƒê·∫¶U HO·∫∂C SAU KHI RERUN
    if CHECKLIST_SESSION_KEY in st.session_state:
        update_checklist_display(checklist_placeholder, st.session_state[CHECKLIST_SESSION_KEY])
