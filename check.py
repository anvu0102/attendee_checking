# check.py
"""
Ch·ª©a c√°c h√†m x·ª≠ l√Ω DeepFace, OpenCV, logic c·∫≠p nh·∫≠t checklist v√† giao di·ªán Streamlit.
ƒê√É C·∫¢I TI·∫æN: Thay th·∫ø Haar Cascade b·∫±ng DeepFace.extract_faces (s·ª≠ d·ª•ng DETECTOR_BACKEND) 
ƒë·ªÉ tƒÉng ƒë·ªô ·ªïn ƒë·ªãnh ph√°t hi·ªán khu√¥n m·∫∑t (v√≠ d·ª•: khi nghi√™ng ƒë·∫ßu).
"""
import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io 
import os
import tempfile
import pandas as pd
from deepface import DeepFace
import requests
import re 
import time
import datetime 

# TH∆Ø VI·ªÜN B·ªî SUNG CHO GOOGLE DRIVE API
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

# Import h·∫±ng s·ªë v√† h√†m t·ª´ config.py
from config import (
    HAAR_CASCADE_URL, CASCADE_FILENAME, # Gi·ªØ l·∫°i import nh∆∞ng kh√¥ng d√πng trong logic ph√°t hi·ªán m·ªõi
    DATASET_FOLDER, CHECKLIST_FILENAME, CHECKLIST_SESSION_KEY, 
    DETECTOR_BACKEND, GDRIVE_CHECKLIST_ID, GDRIVE_NEW_DATA_FOLDER_ID,
    download_file_from_gdrive, upload_to_gdrive_real, list_files_in_gdrive_folder
)


# ----------------------------------------------------------------------
#                             C√ÅC H√ÄM X·ª¨ L√ù
# ----------------------------------------------------------------------

# --- H√ÄM M·ªöI: PH√ÅT HI·ªÜN, V·∫º KHUNG V√Ä C·∫ÆT ·∫¢NH M·∫†NH M·∫º H∆†N ---
def robust_detect_and_crop_face(image_bytes):
    """ 
    S·ª≠ d·ª•ng DeepFace.extract_faces ƒë·ªÉ ph√°t hi·ªán khu√¥n m·∫∑t, v·∫Ω khung, c·∫Øt ·∫£nh v√† l∆∞u v√†o file t·∫°m. 
    Tr·∫£ v·ªÅ: ·∫£nh c√≥ khung (RGB), c·ªù ph√°t hi·ªán, s·ªë l∆∞·ª£ng khu√¥n m·∫∑t, ƒë∆∞·ªùng d·∫´n file ·∫£nh ƒë√£ c·∫Øt (t·∫°m th·ªùi).
    """
    
    # ƒê·ªçc ·∫£nh t·ª´ bytes
    image_pil = Image.open(io.BytesIO(image_bytes)).convert('RGB')
    image_np = np.array(image_pil)
    image_original_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR) 
    image_bgr_with_frame = image_original_bgr.copy() # B·∫£n sao ƒë·ªÉ v·∫Ω khung
    
    face_detected = False
    num_faces = 0
    temp_cropped_path = None
    
    try:
        # S·ª≠ d·ª•ng DETECTOR_BACKEND (v√≠ d·ª•: MTCNN/RetinaFace) cho ƒë·ªô ·ªïn ƒë·ªãnh cao
        faces_extracted = DeepFace.extract_faces(
            img_path=image_np, # Truy·ªÅn numpy array
            detector_backend=DETECTOR_BACKEND, 
            enforce_detection=False # ƒê·ªÉ h√†m kh√¥ng n√©m ValueError khi kh√¥ng t√¨m th·∫•y
        )
        
        num_faces = len(faces_extracted)
        face_detected = num_faces > 0

        if num_faces == 1:
            # L·∫•y t·ªça ƒë·ªô khu√¥n m·∫∑t ƒë·∫ßu ti√™n
            # DeepFace tr·∫£ v·ªÅ t·ªça ƒë·ªô (x, y, w, h) trong 'facial_area'
            facial_area = faces_extracted[0]['facial_area']
            x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']
            
            # 1. V·∫Ω khung l√™n b·∫£n sao (M√†u Xanh D∆∞∆°ng cho 1 khu√¥n m·∫∑t)
            cv2.rectangle(image_bgr_with_frame, (x, y), (x + w, y + h), (255, 0, 0), 2)
            
            # 2. C·∫Øt ·∫£nh (c√≥ padding)
            padding = int(0.2 * w)
            x1 = max(0, x - padding)
            y1 = max(0, y - padding)
            x2 = min(image_original_bgr.shape[1], x + w + padding)
            y2 = min(image_original_bgr.shape[0], y + h + padding)

            cropped_face_bgr = image_original_bgr[y1:y2, x1:x2]
            
            # 3. L∆ØU ·∫¢NH KHU√îN M·∫∂T ƒê√É C·∫ÆT V√ÄO FILE T·∫†M cho DeepFace so kh·ªõp
            temp_file = tempfile.NamedTemporaryFile(suffix=".jpg", delete=False)
            temp_cropped_path = temp_file.name
            temp_file.close() 
            
            cv2.imwrite(temp_cropped_path, cropped_face_bgr)
            
        elif num_faces > 1:
            # V·∫´n v·∫Ω khung cho t·∫•t c·∫£ c√°c khu√¥n m·∫∑t ƒë·ªÉ ng∆∞·ªùi d√πng th·∫•y l·ªói (M√†u ƒê·ªè cho > 1 khu√¥n m·∫∑t)
            for face_data in faces_extracted:
                facial_area = face_data['facial_area']
                x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']
                cv2.rectangle(image_bgr_with_frame, (x, y), (x + w, y + h), (0, 0, 255), 2) 

    except Exception as e:
        # st.error(f"‚ùå L·ªói trong qu√° tr√¨nh ph√°t hi·ªán khu√¥n m·∫∑t: {e}")
        pass # B·ªè qua l·ªói nh·ªè ƒë·ªÉ lu·ªìng ch√≠nh x·ª≠ l√Ω
        
    processed_image_rgb = cv2.cvtColor(image_bgr_with_frame, cv2.COLOR_BGR2RGB)
    
    # TR·∫¢ V·ªÄ: (·∫£nh c√≥ khung (RGB), c·ªù ph√°t hi·ªán, s·ªë l∆∞·ª£ng khu√¥n m·∫∑t, ƒë∆∞·ªùng d·∫´n file ƒë√£ c·∫Øt)
    return processed_image_rgb, face_detected, num_faces, temp_cropped_path


def verify_face_against_dataset(target_image_path, dataset_folder):
    """ 
    S·ª≠ d·ª•ng DeepFace ƒë·ªÉ so s√°nh ·∫£nh ƒë·∫ßu v√†o (ƒê√É C·∫ÆT) v·ªõi dataset. 
    """
    try:
        # DeepFace.find tr·∫£ v·ªÅ danh s√°ch DataFrame, th∆∞·ªùng ch·ªâ c√≥ 1
        df_list = DeepFace.find(
            img_path=target_image_path, 
            db_path=dataset_folder, 
            model_name="ArcFace",
            distance_metric="cosine",
            enforce_detection=True, 
            detector_backend=DETECTOR_BACKEND 
        )
        
        # Ki·ªÉm tra n·∫øu c√≥ k·∫øt qu·∫£ v√† DataFrame ƒë·∫ßu ti√™n kh√¥ng r·ªóng
        if isinstance(df_list, list) and len(df_list) > 0 and not df_list[0].empty:
            best_match = df_list[0].iloc[0]
            identity_path = best_match['identity']
            
            # L·∫•y STT t·ª´ t√™n file (vd: 1_001.jpg -> 1)
            stt_match = os.path.splitext(os.path.basename(identity_path))[0].split('_')[0]
            distance = best_match['ArcFace_cosine'] 
            
            if pd.notna(distance):
                return stt_match, float(distance)
            else:
                st.error("‚ùå DeepFace kh√¥ng tr·∫£ v·ªÅ ƒë·ªô t∆∞∆°ng ƒë·ªìng (distance) h·ª£p l·ªá.")
                return None, None
                
        return None, None
    except Exception as e:
        # Ch·ªâ in l·ªói DeepFace n·∫øu kh√¥ng ph·∫£i l·ªói kh√¥ng ph√°t hi·ªán
        if "Face could not be detected" in str(e):
             st.error(f"‚ùå L·ªói DeepFace: Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t ƒë·ªÉ so kh·ªõp. (Ki·ªÉm tra ch·∫•t l∆∞·ª£ng ·∫£nh)")
        else:
            st.error(f"‚ùå L·ªói DeepFace: {e}")
        return None, None


# B·ªé DECORATOR @st.cache_data ƒë·ªÉ bu·ªôc t·∫£i l·∫°i checklist m·ªói khi app load
def load_checklist(file_id, filename, _credentials):
    """ 
    T·∫£i checklist XLSX v√† ƒë·ªçc th√†nh DataFrame. 
    H√†m n√†y **lu√¥n** t·∫£i l·∫°i file t·ª´ Drive ƒë·ªÉ l·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t.
    """
    
    # 1. T·∫£i file checklist m·ªõi nh·∫•t t·ª´ Drive (ghi ƒë√® l√™n file local n·∫øu c√≥)
    download_file_from_gdrive(file_id, filename, _credentials)
        
    # 2. ƒê·ªçc file local v·ª´a t·∫£i
    if os.path.exists(filename):
        try:
            # ƒê·ªåC FILE XLSX
            df = pd.read_excel(filename) 
            
            # === FIX L·ªñI PYARROW (ArrowTypeError): Chu·∫©n h√≥a c·ªôt STT th√†nh STRING ===
            # Gi·∫£ ƒë·ªãnh c·ªôt STT l√† c·ªôt ƒë·∫ßu ti√™n
            stt_col = df.columns[0]
            # Chuy·ªÉn ƒë·ªïi th√†nh chu·ªói v√† lo·∫°i b·ªè kho·∫£ng tr·∫Øng d∆∞ th·ª´a
            df[stt_col] = df[stt_col].astype(str).str.strip() 
            # =======================================================================
            
            return df
        except Exception as e:
            st.error(f"‚ùå L·ªói khi ƒë·ªçc file checklist: {e}. ƒê·∫£m b·∫£o file c√≥ ƒë·ªãnh d·∫°ng XLSX.")
            return None
    return None

# --- H√ÄM T√åM S·ªê TH·ª® T·ª∞ L·ªöN NH·∫§T TRONG FOLDER NEW DATA ---
def get_next_new_data_stt(_credentials):
    """
    T√¨m s·ªë th·ª© t·ª± l·ªõn nh·∫•t trong folder NEW_DATA_FOLDER_ID tr√™n Drive
    ƒë·ªÉ ƒë·∫∑t t√™n cho file m·ªõi (v√≠ d·ª•: B1_1.jpg, B1_2.jpg, ...).
    Tr·∫£ v·ªÅ s·ªë th·ª© t·ª± ti·∫øp theo (integer).
    """
    
    # 1. L·∫•y danh s√°ch t√™n file t·ª´ Drive
    file_list = list_files_in_gdrive_folder(GDRIVE_NEW_DATA_FOLDER_ID, _credentials)
    
    max_stt = 0
    # Bi·ªÉu th·ª©c ch√≠nh quy ƒë·ªÉ t√¨m s·ªë sau d·∫•u g·∫°ch d∆∞·ªõi (v√≠ d·ª•: BX_123.jpg -> 123)
    # Pattern: [Bu·ªïi]<s·ªë>_<s·ªë>.jpg
    pattern = re.compile(r'B\d+_(\d+)\.jpe?g$', re.IGNORECASE)
    
    for filename in file_list:
        match = pattern.search(filename)
        if match:
            try:
                # L·∫•y s·ªë th·ª© t·ª± (group 1)
                stt = int(match.group(1))
                if stt > max_stt:
                    max_stt = stt
            except ValueError:
                continue

    # Tr·∫£ v·ªÅ s·ªë th·ª© t·ª± ti·∫øp theo
    return max_stt + 1

# --- H√ÄM: KI·ªÇM TRA T√äN FILE T·ªíN T·∫†I TRONG FOLDER DRIVE ---
def check_drive_file_existence(folder_id, filename, _credentials):
    """
    Ki·ªÉm tra xem file c√≥ t√™n filename ƒë√£ t·ªìn t·∫°i trong folder_id tr√™n Drive hay ch∆∞a.
    Tr·∫£ v·ªÅ True n·∫øu t·ªìn t·∫°i, False n·∫øu ch∆∞a.
    """
    try:
        service = build('drive', 'v3', credentials=_credentials)
        query = (
            f"name='{filename}' and "
            f"'{folder_id}' in parents and "
            f"trashed=false"
        )
        
        results = service.files().list(q=query, fields="files(id)").execute()
        items = results.get('files', [])
        return len(items) > 0
    except Exception as e:
        st.error(f"‚ùå L·ªói Drive API khi ki·ªÉm tra file t·ªìn t·∫°i: {e}")
        return False


# --- H√ÄM: T√åM HO·∫∂C T·∫†O FOLDER CON TR√äN DRIVE ---
@st.cache_resource(show_spinner="ƒêang ki·ªÉm tra/t·∫°o folder Drive...")
def get_or_create_drive_folder(parent_id, folder_name, _credentials):
    """
    T√¨m ID c·ªßa folder con trong parent_id. N·∫øu ch∆∞a t·ªìn t·∫°i, t·∫°o m·ªõi.
    Tr·∫£ v·ªÅ ID c·ªßa folder con.
    """
    try:
        service = build('drive', 'v3', credentials=_credentials)
        
        # 1. T√¨m ki·∫øm folder
        query = (
            f"mimeType='application/vnd.google-apps.folder' and "
            f"name='{folder_name}' and "
            f"'{parent_id}' in parents and "
            f"trashed=false"
        )
        
        results = service.files().list(q=query, fields="files(id, name)").execute()
        items = results.get('files', [])
        
        if items:
            st.info(f"üìÅ Folder Drive: ƒê√£ t√¨m th·∫•y '{folder_name}'.")
            return items[0]['id']
        else:
            # 2. T·∫°o folder m·ªõi n·∫øu ch∆∞a t·ªìn t·∫°i
            file_metadata = {
                'name': folder_name,
                'mimeType': 'application/vnd.google-apps.folder',
                'parents': [parent_id]
            }
            file = service.files().create(body=file_metadata, fields='id').execute()
            st.success(f"üìÅ Folder Drive: ƒê√£ t·∫°o folder m·ªõi '{folder_name}'.")
            return file.get('id')

    except Exception as e:
        st.error(f"‚ùå L·ªói Drive API khi ki·ªÉm tra/t·∫°o folder: {e}")
        return None
        
# --- H√ÄM H·ªñ TR·ª¢ HI·ªÇN TH·ªä ·∫¢NH DATASET (ƒê√É TH√äM) ---
def load_dataset_image(stt_match, dataset_folder):
    """
    T√¨m v√† tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n c·ªßa ·∫£nh dataset t∆∞∆°ng ·ª©ng v·ªõi STT match ƒë·∫ßu ti√™n.
    """
    pattern_simple = re.compile(rf'^{stt_match}\.jpe?g$', re.IGNORECASE)
    pattern_complex = re.compile(rf'^{stt_match}_.*\.jpe?g$', re.IGNORECASE)
    
    if os.path.isdir(dataset_folder):
        for filename in os.listdir(dataset_folder):
            
            if pattern_simple.match(filename) or pattern_complex.match(filename):
                return os.path.join(dataset_folder, filename)
                
    return None
        
# --- LOGIC GHI D·ªÆ LI·ªÜU V√Ä L∆ØU ·∫¢NH M·ªöI ---
def update_checklist_and_save_new_data(stt_match, session_name, image_bytes, _credentials):
    """
    C·∫≠p nh·∫≠t DataFrame checklist v√† l∆∞u ·∫£nh m·ªõi l√™n Drive.
    """
    if CHECKLIST_SESSION_KEY not in st.session_state:
        st.error("L·ªói: Kh√¥ng t√¨m th·∫•y DataFrame checklist trong Session State.")
        return False 

    df = st.session_state[CHECKLIST_SESSION_KEY]
    updated = False 
    
    # 1. C·∫≠p nh·∫≠t Checklist (ƒê√°nh 'X')
    if stt_match is not None:
        try:
            stt_col = df.columns[0] 
            
            row_index = df[df[stt_col] == stt_match].index
            
            if not row_index.empty:
                
                # --- L∆ØU ·∫¢NH G·ªêC V√ÄO FOLDER THEO BU·ªîI (ƒêi·ªÉm danh th√†nh c√¥ng) ---
                stt = df.loc[row_index[0], stt_col]
                session_folder_name = session_name.replace("Bu·ªïi ", "B")
                
                target_folder_id = get_or_create_drive_folder(
                    GDRIVE_NEW_DATA_FOLDER_ID, 
                    session_folder_name, 
                    _credentials
                )
                
                if target_folder_id:
                    base_filename = f"{session_folder_name}_{stt}.jpg" 
                    drive_filename = base_filename 

                    if check_drive_file_existence(target_folder_id, base_filename, _credentials):
                        timestamp = datetime.datetime.now().strftime("_%Y%m%d_%H%M%S")
                        drive_filename = f"{session_folder_name}_{stt}{timestamp}.jpg"
                        st.info(f"‚ö†Ô∏è File '{base_filename}' ƒë√£ t·ªìn t·∫°i. ƒêang l∆∞u v·ªõi t√™n m·ªõi: '{drive_filename}'.")
                    
                    temp_file_for_upload = tempfile.NamedTemporaryFile(suffix=".jpg", delete=False)
                    TEMP_UPLOAD_PATH = temp_file_for_upload.name
                    temp_file_for_upload.close()
                    
                    try:
                        image_to_save = Image.open(io.BytesIO(image_bytes)).convert('RGB')
                        image_to_save.save(TEMP_UPLOAD_PATH, format='JPEG')
                        
                        upload_to_gdrive_real(TEMP_UPLOAD_PATH, target_folder_id, drive_filename, _credentials)
                        st.info(f"üñºÔ∏è ƒê√£ l∆∞u ·∫£nh th√†nh c√¥ng: {session_folder_name}/{drive_filename}")
                    
                    except Exception as e:
                        st.error(f"‚ùå L·ªói khi l∆∞u ·∫£nh ƒëi·ªÉm danh th√†nh c√¥ng: {e}")
                    finally:
                        if os.path.exists(TEMP_UPLOAD_PATH):
                            os.remove(TEMP_UPLOAD_PATH)
                else:
                    st.warning("‚ö†Ô∏è Kh√¥ng th·ªÉ x√°c ƒë·ªãnh/t·∫°o folder Drive ƒë·ªÉ l∆∞u ·∫£nh.")
                # --------------------------------------------------------------------------

                
                if df.loc[row_index[0], session_name] != 'X':
                    df.loc[row_index[0], session_name] = 'X'
                    st.session_state[CHECKLIST_SESSION_KEY] = df 
                    updated = True 
                    
                    st.success(f"‚úÖ **ƒê√£ c·∫≠p nh·∫≠t ƒëi·ªÉm danh** cho STT **{df.loc[row_index[0], stt_col]}** v√†o c·ªôt **{session_name}**.")

                else:
                    st.info(f"Ng∆∞·ªùi c√≥ STT **{df.loc[row_index[0], stt_col]}** ƒë√£ ƒë∆∞·ª£c ƒëi·ªÉm danh trong **{session_name}**.")
                
            else:
                st.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y STT **{stt_match}** trong checklist ƒë·ªÉ c·∫≠p nh·∫≠t.")
        except Exception as e:
            st.error(f"L·ªói khi c·∫≠p nh·∫≠t checklist: {e}")
            
    # 2. L∆∞u ·∫£nh m·ªõi l√™n Drive (N·∫øu kh√¥ng kh·ªõp) - S·ª¨ D·ª§NG ·∫¢NH G·ªêC
    else: 
        st.warning("‚ö†Ô∏è ƒêang l∆∞u ·∫£nh v√†o folder d·ªØ li·ªáu m·ªõi...")
        
        # --- LOGIC L∆ØU ·∫¢NH G·ªêC KH√îNG KH·ªöP (GI·ªÆ NGUY√äN) ---
        next_counter = get_next_new_data_stt(_credentials)
        
        session_num = session_name.replace("Bu·ªïi ", "")
        drive_filename = f"B{session_num}_{next_counter}.jpg" 
        
        temp_file_for_upload = tempfile.NamedTemporaryFile(suffix=".jpg", delete=False)
        TEMP_UPLOAD_PATH = temp_file_for_upload.name
        temp_file_for_upload.close()
        
        try:
            image_to_save = Image.open(io.BytesIO(image_bytes)).convert('RGB')
            image_to_save.save(TEMP_UPLOAD_PATH, format='JPEG')
            
            upload_to_gdrive_real(TEMP_UPLOAD_PATH, GDRIVE_NEW_DATA_FOLDER_ID, drive_filename, _credentials)
            st.info(f"üñºÔ∏è ƒê√£ l∆∞u ·∫£nh kh√¥ng kh·ªõp v√†o folder chung: {drive_filename}")

        except Exception as e:
             st.error(f"‚ùå L·ªói khi t·∫°o file t·∫°m ho·∫∑c g·ªçi h√†m upload: {e}")
        finally:
            if os.path.exists(TEMP_UPLOAD_PATH):
                os.remove(TEMP_UPLOAD_PATH)
        # ----------------------------------------------------------
                
    return updated 


# --- H√ÄM: C·∫¨P NH·∫¨T PLACEHOLDER CHECKLIST ---
def update_checklist_display(checklist_placeholder, current_df):
    """C·∫≠p nh·∫≠t n·ªôi dung c·ªßa placeholder checklist."""
    with checklist_placeholder.container():
        st.subheader("üìã Tr·∫°ng th√°i Checklist Hi·ªán t·∫°i (Trong Session)")
        st.dataframe(current_df)
        
        output = io.BytesIO()
        current_df.to_excel(output, index=False, sheet_name='Checklist_Cap_Nhat')
        excel_data = output.getvalue()
        
        st.download_button(
            label="‚¨áÔ∏è T·∫£i file Excel Checklist ƒë√£ c·∫≠p nh·∫≠t",
            data=excel_data,
            file_name="Checklist_DiemDanh_CapNhat.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            help="T·∫£i v·ªÅ file Excel (XLSX) ch·ª©a d·ªØ li·ªáu ƒëi·ªÉm danh m·ªõi nh·∫•t trong phi√™n l√†m vi·ªác hi·ªán t·∫°i."
        )
# -----------------------------------------------


# ----------------------------------------------------------------------
#                             GIAO DI·ªÜN CH√çNH (main_app)
# ----------------------------------------------------------------------

def main_app(credentials):
    """
    H√†m ch·ª©a to√†n b·ªô logic giao di·ªán Streamlit.
    """
    
    # === KH·ªûI T·∫†O KEY SESSION STATE ===
    if 'camera_input_key' not in st.session_state:
        st.session_state['camera_input_key'] = 0
    # =================================

    # 1. T·∫£i Dataset & Checklist
    from config import GDRIVE_DATASET_FOLDER_ID
    from config import download_dataset_folder_real
    
    dataset_ready = download_dataset_folder_real(GDRIVE_DATASET_FOLDER_ID, DATASET_FOLDER, credentials) 
    
    if CHECKLIST_SESSION_KEY not in st.session_state:
        checklist_df = load_checklist(GDRIVE_CHECKLIST_ID, CHECKLIST_FILENAME, credentials)

        if checklist_df is not None:
            st.session_state[CHECKLIST_SESSION_KEY] = checklist_df
        else:
            st.warning("‚ö†Ô∏è L·ªói t·∫£i ho·∫∑c ƒë·ªçc file Checklist. Vui l√≤ng ki·ªÉm tra File ID v√† quy·ªÅn truy c·∫≠p b·∫±ng token.")
            return

    checklist_df = st.session_state[CHECKLIST_SESSION_KEY]
        
    st.markdown("---")

    checklist_placeholder = st.empty()
    
    st.markdown("---") 

    if not dataset_ready:
         st.warning("‚ö†Ô∏è L·ªói t·∫£i Dataset Folder. Vui l√≤ng ki·ªÉm tra ID Drive Folder v√† quy·ªÅn truy c·∫≠p.")
         return
         
    if checklist_df is None:
         st.warning("‚ö†Ô∏è Checklist hi·ªán t·∫°i kh√¥ng h·ª£p l·ªá (Ki·ªÉm tra l·ªói t·∫£i l·∫ßn ƒë·∫ßu).")
         return

    st.info(f"Checklist c√≥ {len(checklist_df)} ng∆∞·ªùi.")

    # 2. Ch·ªçn Bu·ªïi H·ªçc (Dropdown)
    attendance_cols = [col for col in st.session_state[CHECKLIST_SESSION_KEY].columns if "Bu·ªïi" in col]

    if not attendance_cols:
         st.error("Kh√¥ng t√¨m th·∫•y c·ªôt 'Bu·ªïi' trong checklist. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u tr√∫c file XLSX.")
         return

    display_options = ["--- Vui l√≤ng ch·ªçn bu·ªïi ---"] + attendance_cols
    
    selected_session_display = st.selectbox(
        "Ch·ªçn Bu·ªïi ƒëi·ªÉm danh", 
        display_options, 
        index=0, 
        help="Ch·ªçn bu·ªïi t∆∞∆°ng ·ª©ng ƒë·ªÉ c·∫≠p nh·∫≠t c·ªôt ƒëi·ªÉm danh trong checklist."
    )
    
    selected_session = selected_session_display if selected_session_display != "--- Vui l√≤ng ch·ªçn bu·ªïi ---" else None

    # --- B·ªî SUNG: CHECKBOX HI·ªÇN TH·ªä ·∫¢NH DEBUG ---
    show_debug_images = st.checkbox(
        "Hi·ªÉn th·ªã ·∫¢nh ƒë√£ C·∫Øt v√† ·∫¢nh Dataset",
        value=True, 
        help="B·∫≠t ƒë·ªÉ xem ·∫£nh khu√¥n m·∫∑t ƒë∆∞·ª£c c·∫Øt ra v√† ·∫£nh t∆∞∆°ng ·ª©ng trong dataset (khi ƒëi·ªÉm danh th√†nh c√¥ng) ho·∫∑c ·∫£nh ƒë√£ c·∫Øt (khi kh√¥ng kh·ªõp)."
    )
    # ---------------------------------------------

    st.markdown("---")

    # 3. Ch·ª•p ·∫¢nh v√† X·ª≠ L√Ω
    if selected_session:
        
        # T·∫†O C·ªòT M·ªöI: [T·ªâ l·ªá 1, T·ªâ l·ªá 2] => Camera chi·∫øm 1/3 chi·ªÅu r·ªông
        col_camera, col_spacer = st.columns([1, 1])
        
        with col_camera:
            # ƒê·∫∂T CAMERA INPUT V√ÄO C·ªòT C√ì K√çCH TH∆Ø·ªöC GI·ªöI H·∫†N
            captured_file = st.camera_input(
                "Ch·ª•p ·∫£nh ƒëi·ªÉm danh", 
                key=f"camera_input_{st.session_state['camera_input_key']}" 
            )
        
        # T·∫°o placeholder cho k·∫øt qu·∫£ (ƒê·∫£m b·∫£o n√≥ v·∫´n n·∫±m ngo√†i col_camera)
        result_placeholder = st.empty()
        
        TEMP_IMAGE_PATH = None

        if captured_file is not None:
            
            image_bytes_original = captured_file.getvalue() 
            
            stt_match = None
            distance = None
            

            with st.spinner('ƒêang x·ª≠ l√Ω ·∫£nh v√† nh·∫≠n di·ªán khu√¥n m·∫∑t...'):
                
                # --- S·ª¨ D·ª§NG H√ÄM PH√ÅT HI·ªÜN M·∫†NH M·∫º M·ªöI (DeepFace) ---
                processed_image_np, face_detected, num_faces, TEMP_IMAGE_PATH = robust_detect_and_crop_face(image_bytes_original)
                processed_image = Image.fromarray(processed_image_np)
                
                # Ki·ªÉm tra ch·ªâ c√≥ 1 khu√¥n m·∫∑t v√† ti·∫øn h√†nh so kh·ªõp
                if face_detected and num_faces == 1 and TEMP_IMAGE_PATH:
                    
                    stt_match, distance = verify_face_against_dataset(TEMP_IMAGE_PATH, DATASET_FOLDER)
                
                # --- End If face_detected and num_faces == 1 ---
                
            # HI·ªÇN TH·ªä K·∫æT QU·∫¢ TRONG PLACEHOLDER
            with result_placeholder.container():
                st.subheader("üñºÔ∏è ·∫¢nh ƒë√£ ch·ª•p v√† Nh·∫≠n di·ªán")
                st.image(processed_image, caption="Khu√¥n m·∫∑t ƒë√£ ph√°t hi·ªán ƒë∆∞·ª£c ƒë√°nh d·∫•u (Xanh: 1 khu√¥n m·∫∑t; ƒê·ªè: >1 khu√¥n m·∫∑t).", width='stretch')

                st.markdown("---")
                st.subheader("üí° K·∫øt qu·∫£ ƒêi·ªÉm danh")
                
                if stt_match and distance is not None: 
                    st.balloons()
                    st.success(f"‚úÖ **ƒêI·ªÇM DANH TH√ÄNH C√îNG!**")
                    
                    # --- HI·ªÇN TH·ªä ·∫¢NH DEBUG (C√ì ƒêI·ªÄU KI·ªÜN) ---
                    if show_debug_images: 
                        dataset_image_path = load_dataset_image(stt_match, DATASET_FOLDER)
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            if TEMP_IMAGE_PATH and os.path.exists(TEMP_IMAGE_PATH):
                                st.image(TEMP_IMAGE_PATH, caption="Khu√¥n m·∫∑t ƒë√£ C·∫Øt (Cropped)", width='stretch')
                            
                        with col2:
                            if dataset_image_path:
                                st.image(dataset_image_path, caption=f"Dataset (STT: {stt_match})", width='stretch')
                            else:
                                st.warning("Kh√¥ng t√¨m th·∫•y ·∫£nh dataset ƒë·ªÉ hi·ªÉn th·ªã.")
                    # ----------------------------------------------------------------------------
                    
                    st.markdown(f"""
                    * **STT tr√πng kh·ªõp:** **{stt_match}**
                    * **ƒê·ªô t∆∞∆°ng ƒë·ªìng (Kho·∫£ng c√°ch Cosine):** `{distance:.4f}`
                    """)
                    
                    # C·∫≠p nh·∫≠t checklist V√Ä L∆ØU ·∫¢NH G·ªêC TH√ÄNH C√îNG
                    updated = update_checklist_and_save_new_data(stt_match, selected_session, image_bytes_original, credentials)
                    
                    if updated and CHECKLIST_SESSION_KEY in st.session_state:
                         update_checklist_display(checklist_placeholder, st.session_state[CHECKLIST_SESSION_KEY])
                    
                    if TEMP_IMAGE_PATH and os.path.exists(TEMP_IMAGE_PATH):
                        os.remove(TEMP_IMAGE_PATH)
                        
                    st.session_state['camera_input_key'] += 1 
                    st.rerun() 
                    return 
                    
                elif face_detected and num_faces == 1:
                    st.warning(f"‚ö†Ô∏è **Ph√°t hi·ªán 1 khu√¥n m·∫∑t, nh∆∞ng kh√¥ng kh·ªõp v·ªõi dataset.**")
                    
                    if show_debug_images: 
                        if TEMP_IMAGE_PATH and os.path.exists(TEMP_IMAGE_PATH):
                            st.image(TEMP_IMAGE_PATH, caption="Khu√¥n m·∫∑t ƒë√£ C·∫Øt (Cropped)", width='content')
                    
                    update_checklist_and_save_new_data(None, selected_session, image_bytes_original, credentials) 
                    
                elif face_detected and num_faces > 1:
                    st.error(f"‚ùå **Ph√°t hi·ªán nhi·ªÅu khu√¥n m·∫∑t ({num_faces}). Vui l√≤ng ch·ªâ c√≥ 1 ng∆∞·ªùi trong khung h√¨nh.**")

                else:
                    st.warning("‚ö†Ô∏è **Kh√¥ng ph√°t hi·ªán th·∫•y khu√¥n m·∫∑t.**")
                    st.markdown("Vui l√≤ng th·ª≠ l·∫°i. ƒê·∫£m b·∫£o khu√¥n m·∫∑t c·ªßa b·∫°n n·∫±m g·ªçn v√† r√µ r√†ng trong khung h√¨nh.")

            if TEMP_IMAGE_PATH and os.path.exists(TEMP_IMAGE_PATH):
                os.remove(TEMP_IMAGE_PATH)
                
    # 4. HI·ªÇN TH·ªä TR·∫†NG TH√ÅI CHECKLIST BAN ƒê·∫¶U HO·∫∂C SAU KHI RERUN
    if CHECKLIST_SESSION_KEY in st.session_state:
        update_checklist_display(checklist_placeholder, st.session_state[CHECKLIST_SESSION_KEY])
