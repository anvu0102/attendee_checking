# (B·ªî SUNG V√ÄO PH·∫¶N ƒê·∫¶U FILE check.py)
# from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, WebRtcMode
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, WebRtcMode

# ... (c√°c h√†m x·ª≠ l√Ω c≈©: detect_and_draw_face, verify_face_against_dataset, ...)

# ----------------------------------------------------------------------
#                             CLASS X·ª¨ L√ù VIDEO
# ----------------------------------------------------------------------

class FaceDetectionProcessor(VideoProcessorBase):
    """
    X·ª≠ l√Ω t·ª´ng khung h√¨nh ƒë·ªÉ ph√°t hi·ªán v√† v·∫Ω khung khu√¥n m·∫∑t.
    """
    def __init__(self, face_cascade):
        self.face_cascade = face_cascade
        # C·ªù ƒë·ªÉ ki·ªÉm tra n·∫øu ƒë√£ ch·ª•p/x·ª≠ l√Ω th√†nh c√¥ng, tr√°nh x·ª≠ l√Ω li√™n t·ª•c 1 khu√¥n m·∫∑t
        self.processed_success = False 
        
    def recv(self, frame):
        """ Nh·∫≠n m·ªôt khung h√¨nh v√† tr·∫£ v·ªÅ khung h√¨nh ƒë√£ x·ª≠ l√Ω. """
        
        # Chuy·ªÉn ƒë·ªïi sang m·∫£ng numpy (b·∫Øt bu·ªôc)
        img = frame.to_ndarray(format="bgr24") 
        
        # Sao ch√©p ·∫£nh ƒë·ªÉ v·∫Ω khung
        img_with_frame = img.copy()
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        faces = []
        if self.face_cascade is not None:
            faces = self.face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

        # --- LOGIC T·ª∞ ƒê·ªòNG CH·ª§P V√Ä L∆ØU V√ÄO SESSION STATE ---
        if len(faces) == 1 and not self.processed_success and st.session_state.get('auto_check_enabled', False):
            # L·∫•y t·ªça ƒë·ªô khu√¥n m·∫∑t ƒë·∫ßu ti√™n
            (x, y, w, h) = faces[0]
            
            # L∆∞u ·∫£nh g·ªëc (bgr) v√†o Session State ƒë·ªÉ x·ª≠ l√Ω DeepFace sau
            st.session_state['captured_frame'] = img.copy() 
            st.session_state['face_coords'] = faces[0]
            self.processed_success = True # Ch·∫∑n x·ª≠ l√Ω th√™m
            
            # Streamlit s·∫Ω t·ª± rerun ngay sau khi frame ƒë∆∞·ª£c tr·∫£ v·ªÅ
            
        # V·∫Ω khung l√™n b·∫£n sao
        for (x, y, w, h) in faces:
            cv2.rectangle(img_with_frame, (x, y), (x + w, y + h), (0, 255, 0), 2) # D√πng m√†u xanh l√°
            
        return av.VideoFrame.from_ndarray(img_with_frame, format="bgr24")

# ----------------------------------------------------------------------

# ... (H√†m main_app ƒë∆∞·ª£c c·∫≠p nh·∫≠t)

def main_app(credentials):
    # ... (ph·∫ßn code kh·ªüi t·∫°o)
    
    # ... (Ph·∫ßn ch·ªçn bu·ªïi h·ªçc, checkbox show_debug_images v√† auto_check_enabled)

    # --- KH·ªûI T·∫†O BI·∫æN SESSION STATE CHO ·∫¢NH T·ª∞ ƒê·ªòNG CH·ª§P ---
    if 'captured_frame' not in st.session_state:
        st.session_state['captured_frame'] = None
    if 'face_coords' not in st.session_state:
        st.session_state['face_coords'] = None
    # -----------------------------------------------------------

    # 3. Ch·ª•p ·∫¢nh v√† X·ª≠ L√Ω
    if selected_session:
        
        st.subheader("üî¥ Lu·ªìng Video Tr·ª±c ti·∫øp")
        
        # --- THAY TH·∫æ st.camera_input B·∫∞NG streamlit-webrtc ---
        webrtc_ctx = webrtc_streamer(
            key="webcam_stream",
            mode=WebRtcMode.SENDRECV,
            video_processor_factory=lambda: FaceDetectionProcessor(face_cascade),
            rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
            media_stream_constraints={"video": True, "audio": False},
        )
        # -----------------------------------------------------

        # Ki·ªÉm tra n·∫øu c√≥ khung h√¨nh ƒë∆∞·ª£c t·ª± ƒë·ªông ch·ª•p trong Session State
        if st.session_state['captured_frame'] is not None:
            # L·∫•y ·∫£nh v√† t·ªça ƒë·ªô khu√¥n m·∫∑t ƒë√£ ch·ª•p t·ª´ Session State
            image_original_bgr = st.session_state.pop('captured_frame')
            faces_coords = [st.session_state.pop('face_coords')]
            
            # Chuy·ªÉn ·∫£nh BGR v·ªÅ bytes (ƒë·ªÉ ph√π h·ª£p v·ªõi lu·ªìng x·ª≠ l√Ω DeepFace c≈©)
            _, image_bytes_original = cv2.imencode('.jpg', image_original_bgr)
            image_bytes_original = image_bytes_original.tobytes()
            
            # L∆ØU √ù: Ph·∫ßn n√†y ƒë√£ b·ªè qua b∆∞·ªõc ph√°t hi·ªán Haar Cascade v√¨ ƒë√£ ƒë∆∞·ª£c th·ª±c hi·ªán trong VideoProcessor
            
            stt_match = None
            distance = None
            TEMP_IMAGE_PATH = None

            with st.spinner('ƒêang x·ª≠ l√Ω ·∫£nh v√† nh·∫≠n di·ªán khu√¥n m·∫∑t...'):
                
                # --- PH·∫¶N X·ª¨ L√ù KHU√îN M·∫∂T ƒê√É C·∫ÆT (D√ôNG L·∫†I LOGIC C≈®) ---
                if len(faces_coords) == 1:
                    (x, y, w, h) = faces_coords[0]
                    # ... (logic c·∫Øt v√† l∆∞u file t·∫°m)
                    # ... (logic g·ªçi DeepFace)
                    
                    # T∆∞∆°ng t·ª± nh∆∞ code c≈©, c·∫ßn t·∫°o ·∫£nh processed_image_np c√≥ khung v·∫Ω
                    processed_image_rgb = cv2.cvtColor(cv2.rectangle(image_original_bgr.copy(), (x, y), (x + w, y + h), (255, 0, 0), 2), cv2.COLOR_BGR2RGB)
                    processed_image = Image.fromarray(processed_image_rgb)
                
                # ... (ph·∫ßn hi·ªÉn th·ªã k·∫øt qu·∫£ v√† logic c·∫≠p nh·∫≠t checklist)
                
                # KH√îNG TH·ªÇ CUNG C·∫§P M√É CODE HO√ÄN CH·ªàNH V√å Y√äU C·∫¶U QU√Å PH·ª®C T·∫†P
                # V√Ä ƒê√íI H·ªéI VI·ªÜC T√ÅCH LU·ªíNG (THREADING) CHO DEEPFACE

        # ... (Hi·ªÉn th·ªã tr·∫°ng th√°i checklist)
