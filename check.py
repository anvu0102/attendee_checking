# check.py
"""
Ch·ª©a c√°c h√†m x·ª≠ l√Ω DeepFace, OpenCV, logic c·∫≠p nh·∫≠t checklist v√† giao di·ªán Streamlit.
ƒê√£ chuy·ªÉn ƒë·ªïi sang s·ª≠ d·ª•ng streamlit-webrtc ƒë·ªÉ h·ªó tr·ª£ Real-time Face Detection v√† Auto-Capture.
"""
import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io 
import os
import tempfile
import pandas as pd
from deepface import DeepFace
import requests
import re 
import time
import datetime 

# B·ªî SUNG TH∆Ø VI·ªÜN CHO REAL-TIME VIDEO STREAM
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, WebRtcMode
import av # C·∫ßn thi·∫øt cho vi·ªác x·ª≠ l√Ω khung h√¨nh video

# TH∆Ø VI·ªÜN B·ªî SUNG CHO GOOGLE DRIVE API
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

# Import h·∫±ng s·ªë v√† h√†m t·ª´ config.py
from config import (
    HAAR_CASCADE_URL, CASCADE_FILENAME, 
    DATASET_FOLDER, CHECKLIST_FILENAME, CHECKLIST_SESSION_KEY, 
    DETECTOR_BACKEND, GDRIVE_CHECKLIST_ID, GDRIVE_NEW_DATA_FOLDER_ID,
    download_file_from_gdrive, upload_to_gdrive_real, list_files_in_gdrive_folder
)


# ----------------------------------------------------------------------
#                             C√ÅC H√ÄM X·ª¨ L√ù
# ----------------------------------------------------------------------

@st.cache_resource(show_spinner="ƒêang t·∫£i Haar Cascade...")
def load_face_cascade(url, filename):
    """ T·∫£i Haar Cascade cho OpenCV. """
    try:
        if not os.path.exists(filename):
            r = requests.get(url)
            if r.status_code == 200:
                with open(filename, 'wb') as f:
                    f.write(r.content)
            else:
                st.error(f"L·ªói t·∫£i file Haar Cascade: HTTP status {r.status_code}")
                return None

        classifier = cv2.CascadeClassifier(filename)
        if not classifier.empty():
            return classifier
        else:
            st.error("L·ªói: Kh·ªüi t·∫°o Haar Cascade th·∫•t b·∫°i.")
            return None
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i ho·∫∑c kh·ªüi t·∫°o Haar Cascade: {e}")
        return None

# Load cascade ngay khi file ƒë∆∞·ª£c import
face_cascade = load_face_cascade(HAAR_CASCADE_URL, CASCADE_FILENAME)


# B·ªé H√ÄM detect_and_draw_face C≈® V√å LOGIC ƒê∆Ø·ª¢C CHUY·ªÇN V√ÄO CLASS FaceDetectionProcessor

def verify_face_against_dataset(target_image_path, dataset_folder):
    """ 
    S·ª≠ d·ª•ng DeepFace ƒë·ªÉ so s√°nh ·∫£nh ƒë·∫ßu v√†o (ƒê√É C·∫ÆT) v·ªõi dataset. 
    """
    try:
        df_list = DeepFace.find(
            img_path=target_image_path, 
            db_path=dataset_folder, 
            model_name="ArcFace",
            distance_metric="cosine",
            enforce_detection=True, 
            detector_backend=DETECTOR_BACKEND 
        )
        
        if isinstance(df_list, list) and len(df_list) > 0 and not df_list[0].empty:
            best_match = df_list[0].iloc[0]
            identity_path = best_match['identity']
            stt_match = os.path.splitext(os.path.basename(identity_path))[0].split('_')[0]
            distance = best_match['ArcFace_cosine'] 
            
            if pd.notna(distance):
                return stt_match, float(distance)
            else:
                st.error("‚ùå DeepFace kh√¥ng tr·∫£ v·ªÅ ƒë·ªô t∆∞∆°ng ƒë·ªìng (distance) h·ª£p l·ªá.")
                return None, None
                
        return None, None
    except Exception as e:
        if "Face could not be detected" in str(e):
             # L·ªói n√†y c√≥ th·ªÉ x·∫£y ra do ·∫£nh c·∫Øt ch·∫•t l∆∞·ª£ng k√©m
             st.error(f"‚ùå L·ªói DeepFace: Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t ƒë·ªÉ so kh·ªõp. (Ki·ªÉm tra ch·∫•t l∆∞·ª£ng ·∫£nh)")
        else:
            st.error(f"‚ùå L·ªói DeepFace: {e}")
        return None, None


def load_checklist(file_id, filename, _credentials):
    """ T·∫£i checklist XLSX v√† ƒë·ªçc th√†nh DataFrame t·ª´ Drive. """
    
    download_file_from_gdrive(file_id, filename, _credentials)
        
    if os.path.exists(filename):
        try:
            df = pd.read_excel(filename) 
            return df
        except Exception as e:
            st.error(f"‚ùå L·ªói khi ƒë·ªçc file checklist: {e}. ƒê·∫£m b·∫£o file c√≥ ƒë·ªãnh d·∫°ng XLSX.")
            return None
    return None

def get_next_new_data_stt(_credentials):
    """ T√¨m s·ªë th·ª© t·ª± l·ªõn nh·∫•t trong folder NEW_DATA_FOLDER_ID tr√™n Drive. """
    
    file_list = list_files_in_gdrive_folder(GDRIVE_NEW_DATA_FOLDER_ID, _credentials)
    max_stt = 0
    pattern = re.compile(r'B\d+_(\d+)\.jpe?g$', re.IGNORECASE)
    
    for filename in file_list:
        match = pattern.search(filename)
        if match:
            try:
                stt = int(match.group(1))
                if stt > max_stt:
                    max_stt = stt
            except ValueError:
                continue
    return max_stt + 1

def check_drive_file_existence(folder_id, filename, _credentials):
    """ Ki·ªÉm tra xem file c√≥ t√™n filename ƒë√£ t·ªìn t·∫°i trong folder_id tr√™n Drive hay ch∆∞a. """
    try:
        service = build('drive', 'v3', credentials=_credentials)
        query = (
            f"name='{filename}' and "
            f"'{folder_id}' in parents and "
            f"trashed=false"
        )
        results = service.files().list(q=query, fields="files(id)").execute()
        items = results.get('files', [])
        return len(items) > 0
    except Exception as e:
        st.error(f"‚ùå L·ªói Drive API khi ki·ªÉm tra file t·ªìn t·∫°i: {e}")
        return False


@st.cache_resource(show_spinner="ƒêang ki·ªÉm tra/t·∫°o folder Drive...")
def get_or_create_drive_folder(parent_id, folder_name, _credentials):
    """ T√¨m ID c·ªßa folder con trong parent_id. N·∫øu ch∆∞a t·ªìn t·∫°i, t·∫°o m·ªõi. """
    try:
        service = build('drive', 'v3', credentials=_credentials)
        
        query = (
            f"mimeType='application/vnd.google-apps.folder' and "
            f"name='{folder_name}' and "
            f"'{parent_id}' in parents and "
            f"trashed=false"
        )
        
        results = service.files().list(q=query, fields="files(id, name)").execute()
        items = results.get('files', [])
        
        if items:
            st.info(f"üìÅ Folder Drive: ƒê√£ t√¨m th·∫•y '{folder_name}'.")
            return items[0]['id']
        else:
            file_metadata = {
                'name': folder_name,
                'mimeType': 'application/vnd.google-apps.folder',
                'parents': [parent_id]
            }
            file = service.files().create(body=file_metadata, fields='id').execute()
            st.success(f"üìÅ Folder Drive: ƒê√£ t·∫°o folder m·ªõi '{folder_name}'.")
            return file.get('id')

    except Exception as e:
        st.error(f"‚ùå L·ªói Drive API khi ki·ªÉm tra/t·∫°o folder: {e}")
        return None
        
def load_dataset_image(stt_match, dataset_folder):
    """ T√¨m v√† tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n c·ªßa ·∫£nh dataset t∆∞∆°ng ·ª©ng v·ªõi STT match ƒë·∫ßu ti√™n. """
    pattern_simple = re.compile(rf'^{stt_match}\.jpe?g$', re.IGNORECASE)
    pattern_complex = re.compile(rf'^{stt_match}_.*\.jpe?g$', re.IGNORECASE)
    
    if os.path.isdir(dataset_folder):
        for filename in os.listdir(dataset_folder):
            
            if pattern_simple.match(filename):
                return os.path.join(dataset_folder, filename)
                
            if pattern_complex.match(filename):
                return os.path.join(dataset_folder, filename)
                
    return None
        
def update_checklist_and_save_new_data(stt_match, session_name, image_bytes, _credentials):
    """
    C·∫≠p nh·∫≠t DataFrame checklist v√† l∆∞u ·∫£nh m·ªõi l√™n Drive.
    """
    if CHECKLIST_SESSION_KEY not in st.session_state:
        st.error("L·ªói: Kh√¥ng t√¨m th·∫•y DataFrame checklist trong Session State.")
        return False 

    df = st.session_state[CHECKLIST_SESSION_KEY]
    updated = False 
    
    # 1. C·∫≠p nh·∫≠t Checklist (ƒê√°nh 'X')
    if stt_match is not None:
        try:
            stt_col = df.columns[0] 
            row_index = df[df[stt_col].astype(str).str.contains(stt_match, regex=False)].index
            
            if not row_index.empty:
                
                # --- L∆ØU ·∫¢NH G·ªêC V√ÄO FOLDER THEO BU·ªîI (ƒêi·ªÉm danh th√†nh c√¥ng) ---
                stt = df.loc[row_index[0], stt_col]
                session_folder_name = session_name.replace("Bu·ªïi ", "B")
                
                target_folder_id = get_or_create_drive_folder(
                    GDRIVE_NEW_DATA_FOLDER_ID, 
                    session_folder_name, 
                    _credentials
                )
                
                if target_folder_id:
                    base_filename = f"{session_folder_name}_{stt}.jpg" 
                    drive_filename = base_filename 

                    if check_drive_file_existence(target_folder_id, base_filename, _credentials):
                        timestamp = datetime.datetime.now().strftime("_%Y%m%d_%H%M%S")
                        drive_filename = f"{session_folder_name}_{stt}{timestamp}.jpg"
                        st.info(f"‚ö†Ô∏è File '{base_filename}' ƒë√£ t·ªìn t·∫°i. ƒêang l∆∞u v·ªõi t√™n m·ªõi: '{drive_filename}'.")
                    
                    temp_file_for_upload = tempfile.NamedTemporaryFile(suffix=".jpg", delete=False)
                    TEMP_UPLOAD_PATH = temp_file_for_upload.name
                    temp_file_for_upload.close()
                    
                    try:
                        # L∆∞u ·∫£nh t·ª´ bytes (image_bytes - L√öC N√ÄY L√Ä ·∫¢NH G·ªêC) v√†o file t·∫°m
                        image_to_save = Image.open(io.BytesIO(image_bytes)).convert('RGB')
                        image_to_save.save(TEMP_UPLOAD_PATH, format='JPEG')
                        
                        upload_to_gdrive_real(TEMP_UPLOAD_PATH, target_folder_id, drive_filename, _credentials)
                        st.info(f"üñºÔ∏è ƒê√£ l∆∞u ·∫£nh th√†nh c√¥ng: {session_folder_name}/{drive_filename}")
                    
                    except Exception as e:
                        st.error(f"‚ùå L·ªói khi l∆∞u ·∫£nh ƒëi·ªÉm danh th√†nh c√¥ng: {e}")
                    finally:
                        if os.path.exists(TEMP_UPLOAD_PATH):
                            os.remove(TEMP_UPLOAD_PATH)
                else:
                    st.warning("‚ö†Ô∏è Kh√¥ng th·ªÉ x√°c ƒë·ªãnh/t·∫°o folder Drive ƒë·ªÉ l∆∞u ·∫£nh.")
                # --------------------------------------------------------------------------

                
                # Ki·ªÉm tra n·∫øu ch∆∞a ƒëi·ªÉm danh th√¨ m·ªõi c·∫≠p nh·∫≠t (NGƒÇN TR√ôNG L·∫∂P)
                if df.loc[row_index[0], session_name] != 'X':
                    df.loc[row_index[0], session_name] = 'X'
                    st.session_state[CHECKLIST_SESSION_KEY] = df 
                    updated = True 
                    
                    st.success(f"‚úÖ **ƒê√£ c·∫≠p nh·∫≠t ƒëi·ªÉm danh** cho STT **{df.loc[row_index[0], stt_col]}** v√†o c·ªôt **{session_name}**.")

                else:
                    st.info(f"Ng∆∞·ªùi c√≥ STT **{df.loc[row_index[0], stt_col]}** ƒë√£ ƒë∆∞·ª£c ƒëi·ªÉm danh trong **{session_name}**.")
                
            else:
                st.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y STT **{stt_match}** trong checklist ƒë·ªÉ c·∫≠p nh·∫≠t.")
        except Exception as e:
            st.error(f"L·ªói khi c·∫≠p nh·∫≠t checklist: {e}")
            
    # 2. L∆∞u ·∫£nh m·ªõi l√™n Drive (N·∫øu kh√¥ng kh·ªõp) - S·ª¨ D·ª§NG ·∫¢NH G·ªêC
    else: 
        st.warning("‚ö†Ô∏è ƒêang l∆∞u ·∫£nh v√†o folder d·ªØ li·ªáu m·ªõi...")
        
        # --- LOGIC L∆ØU ·∫¢NH G·ªêC KH√îNG KH·ªöP (GI·ªÆ NGUY√äN) ---
        next_counter = get_next_new_data_stt(_credentials)
        
        session_num = session_name.replace("Bu·ªïi ", "")
        drive_filename = f"B{session_num}_{next_counter}.jpg" 
        
        temp_file_for_upload = tempfile.NamedTemporaryFile(suffix=".jpg", delete=False)
        TEMP_UPLOAD_PATH = temp_file_for_upload.name
        temp_file_for_upload.close()
        
        try:
            image_to_save = Image.open(io.BytesIO(image_bytes)).convert('RGB')
            image_to_save.save(TEMP_UPLOAD_PATH, format='JPEG')
            
            upload_to_gdrive_real(TEMP_UPLOAD_PATH, GDRIVE_NEW_DATA_FOLDER_ID, drive_filename, _credentials)
            st.info(f"üñºÔ∏è ƒê√£ l∆∞u ·∫£nh kh√¥ng kh·ªõp v√†o folder chung: {drive_filename}")

        except Exception as e:
             st.error(f"‚ùå L·ªói khi t·∫°o file t·∫°m ho·∫∑c g·ªçi h√†m upload: {e}")
        finally:
            if os.path.exists(TEMP_UPLOAD_PATH):
                os.remove(TEMP_UPLOAD_PATH)
        # ----------------------------------------------------------
                
    return updated 


def update_checklist_display(checklist_placeholder, current_df):
    """C·∫≠p nh·∫≠t n·ªôi dung c·ªßa placeholder checklist."""
    with checklist_placeholder.container():
        st.subheader("üìã Tr·∫°ng th√°i Checklist Hi·ªán t·∫°i (Trong Session)")
        st.dataframe(current_df)
        
        output = io.BytesIO()
        current_df.to_excel(output, index=False, sheet_name='Checklist_Cap_Nhat')
        excel_data = output.getvalue()
        
        st.download_button(
            label="‚¨áÔ∏è T·∫£i file Excel Checklist ƒë√£ c·∫≠p nh·∫≠t",
            data=excel_data,
            file_name="Checklist_DiemDanh_CapNhat.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            help="T·∫£i v·ªÅ file Excel (XLSX) ch·ª©a d·ªØ li·ªáu ƒëi·ªÉm danh m·ªõi nh·∫•t trong phi√™n l√†m vi·ªác hi·ªán t·∫°i."
        )
# -----------------------------------------------

# ----------------------------------------------------------------------
#                             CLASS X·ª¨ L√ù VIDEO REAL-TIME
# ----------------------------------------------------------------------

class FaceDetectionProcessor(VideoProcessorBase):
    """
    X·ª≠ l√Ω t·ª´ng khung h√¨nh ƒë·ªÉ ph√°t hi·ªán v√† v·∫Ω khung khu√¥n m·∫∑t. 
    N·∫øu ph√°t hi·ªán 1 khu√¥n m·∫∑t, l∆∞u khung h√¨nh v√†o Session State ƒë·ªÉ k√≠ch ho·∫°t logic DeepFace.
    """
    def __init__(self, face_cascade):
        self.face_cascade = face_cascade
        
    def recv(self, frame):
        """ Nh·∫≠n m·ªôt khung h√¨nh v√† tr·∫£ v·ªÅ khung h√¨nh ƒë√£ x·ª≠ l√Ω. """
        
        img = frame.to_ndarray(format="bgr24") 
        
        # Sao ch√©p ·∫£nh ƒë·ªÉ v·∫Ω khung
        img_with_frame = img.copy()
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        faces = []
        if self.face_cascade is not None:
            faces = self.face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

        # --- LOGIC T·ª∞ ƒê·ªòNG CH·ª§P V√Ä L∆ØU V√ÄO SESSION STATE ---
        # Ki·ªÉm tra n·∫øu ch∆∞a c√≥ ·∫£nh n√†o ƒëang ch·ªù x·ª≠ l√Ω v√† c√≥ ƒë√∫ng 1 khu√¥n m·∫∑t
        if len(faces) == 1 and st.session_state.get('processing_frame', False) == False:
            
            # L∆∞u ·∫£nh g·ªëc (bgr) v√† t·ªça ƒë·ªô khu√¥n m·∫∑t v√†o Session State
            st.session_state['captured_frame'] = img.copy() 
            st.session_state['face_coords'] = faces[0]
            st.session_state['processing_frame'] = True # ƒê√°nh d·∫•u ƒëang ch·ªù x·ª≠ l√Ω
            
            # V·∫Ω khung m√†u ƒë·ªè ƒë·ªÉ b√°o hi·ªáu ƒë√£ ch·ª•p/ch·ªù x·ª≠ l√Ω
            (x, y, w, h) = faces[0]
            cv2.rectangle(img_with_frame, (x, y), (x + w, y + h), (0, 0, 255), 2)
            
            # Sau khi l∆∞u v√†o Session State, Streamlit s·∫Ω t·ª± ƒë·ªông rerun khi lu·ªìng video tr·∫£ v·ªÅ.
            # Kh√¥ng c·∫ßn g·ªçi st.rerun() tr·ª±c ti·∫øp t·ª´ ƒë√¢y.
            
        else:
            # V·∫Ω khung m√†u xanh l√° n·∫øu c√≥ khu√¥n m·∫∑t
            for (x, y, w, h) in faces:
                cv2.rectangle(img_with_frame, (x, y), (x + w, y + h), (0, 255, 0), 2) 
            
        return av.VideoFrame.from_ndarray(img_with_frame, format="bgr24")

# ----------------------------------------------------------------------


# ----------------------------------------------------------------------
#                             GIAO DI·ªÜN CH√çNH (main_app)
# ----------------------------------------------------------------------

def main_app(credentials):
    """
    H√†m ch·ª©a to√†n b·ªô logic giao di·ªán Streamlit.
    """
    
    # === KH·ªûI T·∫†O KEY SESSION STATE ===
    # Kh·ªüi t·∫°o key cho camera input n·∫øu ch∆∞a c√≥ (D√πng cho logic DeepFace)
    if 'processing_frame' not in st.session_state:
        st.session_state['processing_frame'] = False # C·ªù ki·ªÉm tra ·∫£nh ƒëang ch·ªù x·ª≠ l√Ω
    if 'captured_frame' not in st.session_state:
        st.session_state['captured_frame'] = None
    if 'face_coords' not in st.session_state:
        st.session_state['face_coords'] = None
    # =================================

    # 1. T·∫£i Dataset & Checklist
    from config import GDRIVE_DATASET_FOLDER_ID, GDRIVE_CHECKLIST_ID
    from config import download_dataset_folder_real
    
    dataset_ready = download_dataset_folder_real(GDRIVE_DATASET_FOLDER_ID, DATASET_FOLDER, credentials) 
    
    if CHECKLIST_SESSION_KEY not in st.session_state:
        checklist_df = load_checklist(GDRIVE_CHECKLIST_ID, CHECKLIST_FILENAME, credentials)

        if checklist_df is not None:
            st.session_state[CHECKLIST_SESSION_KEY] = checklist_df
        else:
            st.warning("‚ö†Ô∏è L·ªói t·∫£i ho·∫∑c ƒë·ªçc file Checklist. Vui l√≤ng ki·ªÉm tra File ID v√† quy·ªÅn truy c·∫≠p b·∫±ng token.")
            return

    checklist_df = st.session_state[CHECKLIST_SESSION_KEY]
        
    st.markdown("---")

    # Khai b√°o Placeholder cho checklist
    checklist_placeholder = st.empty()
    
    st.markdown("---") 

    if not dataset_ready:
         st.warning("‚ö†Ô∏è L·ªói t·∫£i Dataset Folder. Vui l√≤ng ki·ªÉm tra ID Drive Folder v√† quy·ªÅn truy c·∫≠p.")
         return
         
    if checklist_df is None:
         st.warning("‚ö†Ô∏è Checklist hi·ªán t·∫°i kh√¥ng h·ª£p l·ªá (Ki·ªÉm tra l·ªói t·∫£i l·∫ßn ƒë·∫ßu).")
         return

    st.info(f"Checklist c√≥ {len(checklist_df)} ng∆∞·ªùi.")

    # 2. Ch·ªçn Bu·ªïi H·ªçc (Dropdown)
    attendance_cols = [col for col in st.session_state[CHECKLIST_SESSION_KEY].columns if "Bu·ªïi" in col]

    if not attendance_cols:
         st.error("Kh√¥ng t√¨m th·∫•y c·ªôt 'Bu·ªïi' trong checklist. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u tr√∫c file XLSX.")
         return
    
    display_options = ["--- Vui l√≤ng ch·ªçn bu·ªïi ---"] + attendance_cols
    
    selected_session_display = st.selectbox(
        "Ch·ªçn Bu·ªïi ƒëi·ªÉm danh", 
        display_options, 
        index=0, 
        help="Ch·ªçn bu·ªïi t∆∞∆°ng ·ª©ng ƒë·ªÉ c·∫≠p nh·∫≠t c·ªôt ƒëi·ªÉm danh trong checklist."
    )
    
    selected_session = selected_session_display if selected_session_display != "--- Vui l√≤ng ch·ªçn bu·ªïi ---" else None

    # --- B·ªî SUNG: CHECKBOX HI·ªÇN TH·ªä ·∫¢NH DEBUG V√Ä AUTO CHECK ---
    col_debug, col_auto = st.columns(2) 
    
    with col_debug:
        show_debug_images = st.checkbox(
            "Hi·ªÉn th·ªã ·∫¢nh ƒë√£ C·∫Øt v√† ·∫¢nh Dataset",
            value=True, 
            help="B·∫≠t ƒë·ªÉ xem ·∫£nh khu√¥n m·∫∑t ƒë∆∞·ª£c c·∫Øt ra v√† ·∫£nh t∆∞∆°ng ·ª©ng trong dataset (khi ƒëi·ªÉm danh th√†nh c√¥ng) ho·∫∑c ·∫£nh ƒë√£ c·∫Øt (khi kh√¥ng kh·ªõp)."
        )

    with col_auto: 
        auto_check_enabled = st.checkbox(
            "T·ª± ƒë·ªông clear & ti·∫øp t·ª•c (Auto Check)",
            value=False, 
            help="N·∫øu ƒë∆∞·ª£c b·∫≠t, sau khi ƒëi·ªÉm danh th√†nh c√¥ng, m√†n h√¨nh s·∫Ω t·ª± ƒë·ªông clear v√† chu·∫©n b·ªã cho l·∫ßn ch·ª•p ti·∫øp theo sau 2 gi√¢y."
        )
        st.session_state['auto_check_enabled'] = auto_check_enabled # L∆∞u c·ªù v√†o Session State ƒë·ªÉ VideoProcessor truy c·∫≠p
    # ---------------------------------------------

    st.markdown("---")

    # 3. K√çCH HO·∫†T LU·ªíNG VIDEO & X·ª¨ L√ù ·∫¢NH ƒê√É T·ª∞ ƒê·ªòNG CH·ª§P
    if selected_session:
        
        st.subheader("üî¥ Lu·ªìng Video Tr·ª±c ti·∫øp (T·ª± ƒë·ªông ch·ª•p khi ph√°t hi·ªán 1 khu√¥n m·∫∑t)")
        
        # --- STREAMLIT-WEBRTC WIDGET ---
        webrtc_ctx = webrtc_streamer(
            key="webcam_stream",
            mode=WebRtcMode.SENDRECV,
            video_processor_factory=lambda: FaceDetectionProcessor(face_cascade),
            rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
            media_stream_constraints={"video": True, "audio": False},
        )
        # ------------------------------
        
        # S·ª≠ d·ª•ng placeholder ƒë·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£ (N·∫øu c√≥ ·∫£nh ƒë∆∞·ª£c ch·ª•p)
        result_placeholder = st.empty()

        # --- LOGIC X·ª¨ L√ù H·∫¨U K·ª≤ (DEEPFACE) KHI C√ì KHUNG H√åNH ƒê∆Ø·ª¢C CH·ª§P ---
        # N·∫øu c√≥ khung h√¨nh ƒë∆∞·ª£c t·ª± ƒë·ªông ch·ª•p trong Session State (do VideoProcessor k√≠ch ho·∫°t)
        if st.session_state['captured_frame'] is not None and st.session_state.get('processing_frame', False) == True:
            
            # L·∫•y d·ªØ li·ªáu v√† d·ªçn d·∫πp Session State (tr·ª´ c·ªù processing_frame ƒë·ªÉ gi·ªØ lu·ªìng video t·∫°m ngh·ªâ)
            image_original_bgr = st.session_state.pop('captured_frame')
            faces_coords = [st.session_state.pop('face_coords')]
            
            # Chuy·ªÉn ·∫£nh BGR v·ªÅ bytes (ph√π h·ª£p v·ªõi update_checklist_and_save_new_data)
            _, image_bytes_original = cv2.imencode('.jpg', image_original_bgr)
            image_bytes_original = image_bytes_original.tobytes()
            
            stt_match = None
            distance = None
            TEMP_IMAGE_PATH = None
            face_detected = True
            num_faces = 1
            
            with st.spinner('ƒêang x·ª≠ l√Ω ·∫£nh v√† nh·∫≠n di·ªán khu√¥n m·∫∑t...'):
                
                # CH·ªà X·ª¨ L√ù TI·∫æP N·∫æU C√ì ƒê√öNG 1 KHU√îN M·∫∂T ƒê√É ƒê∆Ø·ª¢C CH·ª§P (ƒê√£ ki·ªÉm tra trong VideoProcessor)
                if num_faces == 1:
                    
                    (x, y, w, h) = faces_coords[0]
                    
                    # TƒÇNG K√çCH TH∆Ø·ªöC KHUNG (Padding 20%)
                    padding = int(0.2 * w)
                    x1 = max(0, x - padding)
                    y1 = max(0, y - padding)
                    x2 = min(image_original_bgr.shape[1], x + w + padding)
                    y2 = min(image_original_bgr.shape[0], y + h + padding)

                    # C·∫ÆT ·∫¢NH KHU√îN M·∫∂T
                    cropped_face_bgr = image_original_bgr[y1:y2, x1:x2]
                    
                    # L∆ØU ·∫¢NH KHU√îN M·∫∂T ƒê√É C·∫ÆT V√ÄO FILE T·∫†M cho DeepFace so kh·ªõp
                    temp_file = tempfile.NamedTemporaryFile(suffix=".jpg", delete=False)
                    TEMP_IMAGE_PATH = temp_file.name
                    temp_file.close() 
                    
                    cv2.imwrite(TEMP_IMAGE_PATH, cropped_face_bgr)
                    
                    # Th·ª±c hi·ªán so kh·ªõp DeepFace tr√™n ·∫£nh ƒë√£ c·∫Øt
                    stt_match, distance = verify_face_against_dataset(TEMP_IMAGE_PATH, DATASET_FOLDER)
                
                # --- V·∫º ·∫¢NH ƒê√É CH·ª§P (C√ì KHUNG) ---
                processed_image_rgb = cv2.cvtColor(cv2.rectangle(image_original_bgr.copy(), (x, y), (x + w, y + h), (255, 0, 0), 2), cv2.COLOR_BGR2RGB)
                processed_image = Image.fromarray(processed_image_rgb)
                
            # HI·ªÇN TH·ªä K·∫æT QU·∫¢ TRONG PLACEHOLDER
            with result_placeholder.container():
                st.subheader("üñºÔ∏è ·∫¢nh ƒë√£ T·ª± ƒë·ªông Ch·ª•p v√† Nh·∫≠n di·ªán")
                st.image(processed_image, caption="Khu√¥n m·∫∑t ƒë√£ ph√°t hi·ªán ƒë∆∞·ª£c ƒë√°nh d·∫•u.", use_column_width=True)

                st.markdown("---")
                st.subheader("üí° K·∫øt qu·∫£ ƒêi·ªÉm danh")
                
                if stt_match and distance is not None: 
                    st.balloons()
                    st.success(f"‚úÖ **ƒêI·ªÇM DANH TH√ÄNH C√îNG!**")
                    
                    if show_debug_images: 
                        dataset_image_path = load_dataset_image(stt_match, DATASET_FOLDER)
                        col1, col2 = st.columns(2)
                        with col1:
                            if TEMP_IMAGE_PATH:
                                st.image(TEMP_IMAGE_PATH, caption="Khu√¥n m·∫∑t ƒë√£ C·∫Øt (Cropped)", use_column_width=True)
                        with col2:
                            if dataset_image_path:
                                st.image(dataset_image_path, caption=f"Dataset (STT: {stt_match})", use_column_width=True)
                            else:
                                st.warning("Kh√¥ng t√¨m th·∫•y ·∫£nh dataset ƒë·ªÉ hi·ªÉn th·ªã.")
                    
                    st.markdown(f"""
                    * **STT tr√πng kh·ªõp:** **{stt_match}**
                    * **ƒê·ªô t∆∞∆°ng ƒë·ªìng (Kho·∫£ng c√°ch Cosine):** `{distance:.4f}`
                    """)
                    
                    updated = update_checklist_and_save_new_data(stt_match, selected_session, image_bytes_original, credentials)
                    
                    if updated and CHECKLIST_SESSION_KEY in st.session_state:
                         update_checklist_display(checklist_placeholder, st.session_state[CHECKLIST_SESSION_KEY])
                    
                    # --- LOGIC T·ª∞ ƒê·ªòNG CLEAR ---
                    if auto_check_enabled: 
                        time.sleep(2) 
                        
                        if TEMP_IMAGE_PATH and os.path.exists(TEMP_IMAGE_PATH):
                            os.remove(TEMP_IMAGE_PATH)
                            
                        # QUAN TR·ªåNG: G·ª° c·ªù x·ª≠ l√Ω ƒë·ªÉ VideoProcessor c√≥ th·ªÉ ch·ª•p khung h√¨nh m·ªõi
                        st.session_state['processing_frame'] = False 
                        st.rerun() 
                        return 
                    
                elif face_detected and num_faces == 1:
                    st.warning(f"‚ö†Ô∏è **Ph√°t hi·ªán 1 khu√¥n m·∫∑t, nh∆∞ng kh√¥ng kh·ªõp v·ªõi dataset.**")
                    
                    if show_debug_images: 
                        if TEMP_IMAGE_PATH:
                            st.image(TEMP_IMAGE_PATH, caption="Khu√¥n m·∫∑t ƒë√£ C·∫Øt (Cropped)", use_column_width=False)
                    
                    update_checklist_and_save_new_data(None, selected_session, image_bytes_original, credentials) 
                
                # KH√îNG BAO G·ªíM C√ÅC TR∆Ø·ªúNG H·ª¢P NHI·ªÄU KHU√îN M·∫∂T/KH√îNG KHU√îN M·∫∂T V√å ƒê√É L·ªåC TRONG VIDEO PROCESSOR

            # --- D·ªçn d·∫πp file t·∫°m v√† c·ªù (N·∫øu kh√¥ng t·ª± ƒë·ªông rerun) ---
            if TEMP_IMAGE_PATH and os.path.exists(TEMP_IMAGE_PATH):
                os.remove(TEMP_IMAGE_PATH)
            
            # G·ª° c·ªù x·ª≠ l√Ω ƒë·ªÉ VideoProcessor c√≥ th·ªÉ ch·ª•p khung h√¨nh m·ªõi (n·∫øu kh√¥ng auto check)
            st.session_state['processing_frame'] = False 

    # 4. HI·ªÇN TH·ªä TR·∫†NG TH√ÅI CHECKLIST BAN ƒê·∫¶U HO·∫∂C SAU KHI RERUN
    if CHECKLIST_SESSION_KEY in st.session_state:
        update_checklist_display(checklist_placeholder, st.session_state[CHECKLIST_SESSION_KEY])
